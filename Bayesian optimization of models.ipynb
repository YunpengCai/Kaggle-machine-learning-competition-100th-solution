{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if c not in ['ID_code', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['target']\n",
    "X = train.drop(['target', 'ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test.drop(['ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_small=y[:100000]\n",
    "X_small=X[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_small, y_small, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use bayesian optimization to accelerate the tuning of hyperparameters, extra tree, random forest, KNN, SVM and logistic regression are optimized with this approach. The stacking and blending of models can be found in `Ensemble stacking` jupyter file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best = 0\n",
    "\n",
    "def hyperopt_train_test(params):\n",
    "    clf = ExtraTreesClassifier(**params)\n",
    "    return cross_val_score(clf, X_small, y_small,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n",
    "\n",
    "def loss(params):\n",
    "    global best\n",
    "    roc = hyperopt_train_test(params)\n",
    "    if roc > best:\n",
    "        best = roc\n",
    "        print ('new best:', best, params)\n",
    "    return {'loss': -roc, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4et = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,20)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(200,2000,50)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', np.arange(10,300,10)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(2,200,2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best:                                                                                                              \n",
      "0.8753833455343675                                                                                                     \n",
      "{'criterion': 'gini', 'max_depth': 12, 'max_features': 5, 'min_samples_leaf': 120, 'min_samples_split': 90, 'n_estimators': 550}\n",
      "new best:                                                                                                              \n",
      "0.881036953424576                                                                                                      \n",
      "{'criterion': 'gini', 'max_depth': 8, 'max_features': 2, 'min_samples_leaf': 192, 'min_samples_split': 110, 'n_estimators': 1550}\n",
      "new best:                                                                                                              \n",
      "0.8813784377440751                                                                                                     \n",
      "{'criterion': 'gini', 'max_depth': 5, 'max_features': 4, 'min_samples_leaf': 56, 'min_samples_split': 90, 'n_estimators': 1550}\n",
      "new best:                                                                                                              \n",
      "0.8842611817316753                                                                                                     \n",
      "{'criterion': 'gini', 'max_depth': 17, 'max_features': 2, 'min_samples_leaf': 56, 'min_samples_split': 280, 'n_estimators': 1700}\n",
      "new best:                                                                                                              \n",
      "0.8851381151938482                                                                                                     \n",
      "{'criterion': 'entropy', 'max_depth': 9, 'max_features': 2, 'min_samples_leaf': 38, 'min_samples_split': 210, 'n_estimators': 1900}\n",
      "new best:                                                                                                              \n",
      "0.8852135734051877                                                                                                     \n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': 2, 'min_samples_leaf': 12, 'min_samples_split': 120, 'n_estimators': 1900}\n",
      "new best:                                                                                                              \n",
      "0.8853343949771603                                                                                                     \n",
      "{'criterion': 'entropy', 'max_depth': 8, 'max_features': 2, 'min_samples_leaf': 12, 'min_samples_split': 120, 'n_estimators': 1900}\n",
      "100%|██████████████████████████████████████████████| 300/300 [7:11:17<00:00, 73.82s/it, best loss: -0.8853343949771603]\n"
     ]
    }
   ],
   "source": [
    "best_cv = fmin(loss, space4et, algo=tpe.suggest, max_evals=300, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 n_estimators\n",
      "1 max_depth\n",
      "2 max_features\n",
      "3 criterion\n",
      "4 min_samples_split\n",
      "5 min_samples_leaf\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = ['n_estimators', 'max_depth', 'max_features', 'criterion', 'min_samples_split', 'min_samples_leaf']\n",
    "\n",
    "f, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "for i, val in enumerate(parameters):\n",
    "    print (i, val)\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
    "    ys = [-t['result']['loss'] for t in trials.trials]\n",
    "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
    "    ys = np.array(ys)\n",
    "    axes[i//3,i%3].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i//3,i%3].set_title(val)\n",
    "    #axes[i/3,i%3].set_ylim([0.9,1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best1 = 0\n",
    "\n",
    "def hyperopt_train_test1(params):\n",
    "    clf = RandomForestClassifier(**params)\n",
    "    return cross_val_score(clf, X_small, y_small,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n",
    "\n",
    "def loss1(params):\n",
    "    global best1\n",
    "    roc = hyperopt_train_test1(params)\n",
    "    if roc > best1:\n",
    "        best1 = roc\n",
    "        print ('new best:', best1, params)\n",
    "    return {'loss': -roc, 'status': STATUS_OK}\n",
    "\n",
    "trials1 = Trials()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4rf = {\n",
    "    'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "    'max_features': hp.choice('max_features', range(1,15)),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(800,2000,100)),\n",
    "    'criterion': hp.choice('criterion', [\"gini\", \"entropy\"]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', np.arange(10,300,10)),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', np.arange(2,200,2)),\n",
    "    'class_weight': hp.choice('class_weight', [None, \"balanced\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best:                                                                                                              \n",
      "0.8556224908164277                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 15, 'max_features': 8, 'min_samples_leaf': 22, 'min_samples_split': 210, 'n_estimators': 800}\n",
      "new best:                                                                                                              \n",
      "0.862567005964468                                                                                                      \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 15, 'max_features': 6, 'min_samples_leaf': 78, 'min_samples_split': 270, 'n_estimators': 1000}\n",
      "new best:                                                                                                              \n",
      "0.8687916208101907                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 17, 'max_features': 5, 'min_samples_leaf': 126, 'min_samples_split': 250, 'n_estimators': 1900}\n",
      "new best:                                                                                                              \n",
      "0.8819727874011786                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 7, 'max_features': 1, 'min_samples_leaf': 24, 'min_samples_split': 270, 'n_estimators': 1400}\n",
      "new best:                                                                                                              \n",
      "0.8835838477418759                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 7, 'max_features': 1, 'min_samples_leaf': 120, 'min_samples_split': 270, 'n_estimators': 1900}\n",
      "new best:                                                                                                              \n",
      "0.8846773350260779                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 12, 'max_features': 2, 'min_samples_leaf': 120, 'min_samples_split': 220, 'n_estimators': 1300}\n",
      "new best:                                                                                                              \n",
      "0.8854131008320286                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 14, 'max_features': 2, 'min_samples_leaf': 136, 'min_samples_split': 220, 'n_estimators': 1700}\n",
      "new best:                                                                                                              \n",
      "0.8868314715296477                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 19, 'max_features': 1, 'min_samples_leaf': 176, 'min_samples_split': 230, 'n_estimators': 1300}\n",
      "new best:                                                                                                              \n",
      "0.8876590468047868                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 19, 'max_features': 1, 'min_samples_leaf': 110, 'min_samples_split': 230, 'n_estimators': 1600}\n",
      "new best:                                                                                                              \n",
      "0.8877308444306631                                                                                                     \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 19, 'max_features': 1, 'min_samples_leaf': 110, 'min_samples_split': 230, 'n_estimators': 1600}\n",
      "new best:                                                                                                              \n",
      "0.888057565235974                                                                                                      \n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 19, 'max_features': 1, 'min_samples_leaf': 110, 'min_samples_split': 230, 'n_estimators': 1600}\n",
      " 36%|███████████████▎                          | 109/300 [20:43:08<46:42:01, 880.22s/it, best loss: -0.888057565235974]"
     ]
    }
   ],
   "source": [
    "best_cv1 = fmin(loss1, space4rf, algo=tpe.suggest, max_evals=300, trials=trials1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x,y,t=2):\n",
    "    # Shuffle positive samples twice and added to the existing \n",
    "    pos_shuffle=[]\n",
    "    neg_shuffle=[]\n",
    "    for i in range(t):\n",
    "        mask=y==1\n",
    "        x1=x[mask].copy()\n",
    "        rows=np.arange(x1.shape[0])\n",
    "        for col in range(x1.shape[1]):\n",
    "            np.random.seed(1111)\n",
    "            np.random.shuffle(rows) # shuffle rows in each column\n",
    "            x1[:,col]=x1[rows][:,col]\n",
    "        pos_shuffle.append(x1)\n",
    "    for i in range(t//2):\n",
    "        mask=y==0\n",
    "        x1=x[mask].copy()\n",
    "        rows=np.arange(x1.shape[0])\n",
    "        for col in range(x1.shape[1]):\n",
    "            np.random.seed(1111)\n",
    "            np.random.shuffle(rows) # shuffle rows in each column\n",
    "            x1[:,col]=x1[rows][:,col]\n",
    "        neg_shuffle.append(x1)\n",
    "    pos_shuffle=np.vstack(pos_shuffle)  #stack the dataframe, maybe do contatenate is better\n",
    "    neg_shuffle=np.vstack(neg_shuffle)\n",
    "    pos_y = np.ones(pos_shuffle.shape[0]) # make labels for the shuffled results\n",
    "    neg_y = np.zeros(neg_shuffle.shape[0])\n",
    "    x = np.vstack([x,pos_shuffle]) #augmented data. As pos target is around 0.1, pos_s is 0.2x, neg_s is 0.9x, 2.1x size in total\n",
    "    y = np.concatenate([y,pos_y])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = np.array(X_small)\n",
    "y_small = np.array(y_small)\n",
    "X_t, y_t = shuffle(X_small, y_small)\n",
    "X_t = pd.DataFrame(X_t)\n",
    "X_t = X_t.add_prefix('var_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "X= sc.fit_transform(X)\n",
    "#X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid=X[50000:100000]\n",
    "y_valid=y[50000:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid= sc.fit_transform(X_valid)\n",
    "X_test= sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5 # Number of K-fold Splits\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True,random_state=1111).split(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "oof=np.zeros(len(X))\n",
    "#pred=np.zeros(len(X_test))\n",
    "for i, (train_idx, valid_idx) in enumerate(splits):  \n",
    "    print (i+1)\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    x_train=X[train_idx]\n",
    "    y_train=y[train_idx]\n",
    "    X_t, y_t = shuffle(x_train, y_train)\n",
    "    X_t = pd.DataFrame(X_t)\n",
    "    X_t = X_t.add_prefix('var_')\n",
    "    X_t=np.array(X_t)\n",
    "    y_t=np.array(y_t)\n",
    "    x_valid=X[valid_idx]\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=6000, weights='uniform',algorithm='kd_tree', n_jobs=-1)\n",
    "\n",
    "    knn_clf.fit(X_t, y_t)\n",
    "    oof[valid_idx]=knn_clf.predict_proba(x_valid)[:,1]\n",
    "    #pred+=knn_clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8693447589905814"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645750310809028"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neighbors 4096\n",
    "roc_auc_score(y, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8555858852406302"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neighbors 2048\n",
    "roc_auc_score(y, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8426325811861972"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred=knn_clf.predict_proba(X_test)[:,1]/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best2 = 0\n",
    "\n",
    "def hyperopt_train_test2(params):\n",
    "    clf = KNeighborsClassifier(**params)\n",
    "    return cross_val_score(clf, X_t, y_t,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n",
    "\n",
    "def loss2(params):\n",
    "    global best2\n",
    "    roc = hyperopt_train_test2(params)\n",
    "    if roc > best2:\n",
    "        best2 = roc\n",
    "        print ('new best:', best2, params)\n",
    "    return {'loss': -roc, 'status': STATUS_OK}\n",
    "\n",
    "trials2 = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4knn = {\n",
    "    'n_neighbors': hp.choice('n_neighbors', [1024,2048,4096,9192,16384]),\n",
    "    'weights': hp.choice('weights', [\"uniform\",\"distance\"]),\n",
    "    'algorithm': hp.choice('algorithm', [\"kd_tree\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/10 [00:00<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nD:\\Anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nD:\\Anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C908DE0540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001C908DE0540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    500         if self.poller is not None:\n    501             self.poller.start()\n    502         self.kernel.start()\n    503         self.io_loop = ioloop.IOLoop.current()\n    504         try:\n--> 505             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    506         except KeyboardInterrupt:\n    507             pass\n    508 \n    509 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nD:\\Anaconda\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    534         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    535                                finalizer=self._asyncgen_finalizer_hook)\n    536         try:\n    537             events._set_running_loop(self)\n    538             while True:\n--> 539                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    540                 if self._stopping:\n    541                     break\n    542         finally:\n    543             self._stopping = False\n\n...........................................................................\nD:\\Anaconda\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1770                         logger.warning('Executing %s took %.3f seconds',\n   1771                                        _format_handle(handle), dt)\n   1772                 finally:\n   1773                     self._current_handle = None\n   1774             else:\n-> 1775                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...8E8>, ...]))>))>>\n   1776         handle = None  # Needed to break cycles when an exception occurs.\n   1777 \n   1778     def _set_coroutine_origin_tracking(self, enabled):\n   1779         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\nD:\\Anaconda\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...8E8>, ...]))>))>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_w...B2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>),)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_w...B2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>))\n    753         \"\"\"Runs a callback with error handling.\n    754 \n    755         For use in subclasses.\n    756         \"\"\"\n    757         try:\n--> 758             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_w...B2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>)\n    759             if ret is not None:\n    760                 from tornado import gen\n    761                 # Functions that return Futures typically swallow all\n    762                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<Future finished result=(10, 15, <bound method.....EB2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>,), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<Future finished result=(10, 15, <bound method.....EB2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>,)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in inner(f=None)\n   1228             return False\n   1229         elif not self.future.done():\n   1230             def inner(f):\n   1231                 # Break a reference cycle to speed GC.\n   1232                 f = None  # noqa\n-> 1233                 self.run()\n   1234             self.io_loop.add_future(\n   1235                 self.future, inner)\n   1236             return False\n   1237         return True\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in run(self=<tornado.gen.Runner object>)\n   1142                         finally:\n   1143                             # Break up a reference to itself\n   1144                             # for faster GC on CPython.\n   1145                             exc_info = None\n   1146                     else:\n-> 1147                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 15, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n   1148 \n   1149                     if stack_context._state.contexts is not orig_stack_contexts:\n   1150                         self.gen.throw(\n   1151                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    352         else:\n    353             try:\n    354                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    355             except QueueEmpty:\n    356                 return None\n--> 357         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    358 \n    359     @gen.coroutine\n    360     def dispatch_queue(self):\n    361         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object Kernel.dispatch_shell>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}})\n    262             try:\n    263                 self.pre_handler_hook()\n    264             except Exception:\n    265                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    266             try:\n--> 267                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1c7b9fbdbafd40cd8ea3937b9654399c']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}}\n    268             except Exception:\n    269                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    270             finally:\n    271                 try:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'1c7b9fbdbafd40cd8ea3937b9654399c'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object Kernel.execute_request>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1c7b9fbdbafd40cd8ea3937b9654399c'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}})\n    529             self._publish_execute_input(code, parent, self.execution_count)\n    530 \n    531         reply_content = yield gen.maybe_future(\n    532             self.do_execute(\n    533                 code, silent, store_history,\n--> 534                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    535             )\n    536         )\n    537 \n    538         # Flush output before sending the reply.\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', False, True, {}, True), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object IPythonKernel.do_execute>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    289                     res = yield coro_future\n    290             else:\n    291                 # runner isn't already running,\n    292                 # make synchronous call,\n    293                 # letting shell dispatch to loop runners\n--> 294                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'\n        store_history = True\n        silent = False\n    295         finally:\n    296             self._restore_input()\n    297 \n    298         if res.error_before_exec is not None:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)',), **kwargs={'silent': False, 'store_history': True})\n    531             )\n    532         self.payload_manager.write_payload(payload)\n    533 \n    534     def run_cell(self, *args, **kwargs):\n    535         self._last_traceback = None\n--> 536         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)',)\n        kwargs = {'silent': False, 'store_history': True}\n    537 \n    538     def _showtraceback(self, etype, evalue, stb):\n    539         # try to preserve ordering of tracebacks and print statements\n    540         sys.stdout.flush()\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', store_history=True, silent=False, shell_futures=True)\n   2814         result : :class:`ExecutionResult`\n   2815         \"\"\"\n   2816         result = None\n   2817         try:\n   2818             result = self._run_cell(\n-> 2819                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2820         finally:\n   2821             self.events.trigger('post_execute')\n   2822             if not silent:\n   2823                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', store_history=True, silent=False, shell_futures=True)\n   2840             runner = self.loop_runner\n   2841         else:\n   2842             runner = _pseudo_sync_runner\n   2843 \n   2844         try:\n-> 2845             return runner(coro)\n        runner = <function _pseudo_sync_runner>\n        coro = <generator object InteractiveShell.run_cell_async>\n   2846         except BaseException as e:\n   2847             info = ExecutionInfo(raw_cell, store_history, silent, shell_futures)\n   2848             result = ExecutionResult(info)\n   2849             result.error_in_exec = e\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py in _pseudo_sync_runner(coro=<generator object InteractiveShell.run_cell_async>)\n     62 \n     63     Credit to Nathaniel Smith\n     64 \n     65     \"\"\"\n     66     try:\n---> 67         coro.send(None)\n        coro.send = <built-in method send of generator object>\n     68     except StopIteration as exc:\n     69         return exc.value\n     70     else:\n     71         # TODO: do not raise but return an execution result with the right info.\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_async(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', store_history=True, silent=False, shell_futures=True)\n   3015                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   3016                 if _run_async:\n   3017                     interactivity = 'async'\n   3018 \n   3019                 has_raised = yield from self.run_ast_nodes(code_ast.body, cell_name,\n-> 3020                        interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   3021 \n   3022                 self.last_execution_succeeded = not has_raised\n   3023                 self.last_execution_result = result\n   3024 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-13-fc0163bbce31>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c91023ae10, executio...rue silent=False shell_futures=True> result=None>)\n   3180                     return True\n   3181             else:\n   3182                 for i, node in enumerate(to_run_exec):\n   3183                     mod = ast.Module([node])\n   3184                     code = compiler(mod, cell_name, \"exec\")\n-> 3185                     if (yield from self.run_code(code, result)):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001C9101E5C90, file \"<ipython-input-13-fc0163bbce31>\", line 1>\n        result = <ExecutionResult object at 1c91023ae10, executio...rue silent=False shell_futures=True> result=None>\n   3186                         return True\n   3187 \n   3188                 for i, node in enumerate(to_run_interactive):\n   3189                     mod = ast.Interactive([node])\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C9101E5C90, file \"<ipython-input-13-fc0163bbce31>\", line 1>, result=<ExecutionResult object at 1c91023ae10, executio...rue silent=False shell_futures=True> result=None>, async_=False)\n   3262                 if async_:\n   3263                     last_expr = (yield from self._async_exec(code_obj, self.user_ns))\n   3264                     code = compile('last_expr', 'fake', \"single\")\n   3265                     exec(code, {'last_expr': last_expr})\n   3266                 else:\n-> 3267                     exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001C9101E5C90, file \"<ipython-input-13-fc0163bbce31>\", line 1>\n        self.user_global_ns = {'In': ['', 'import numpy as np\\nimport matplotlib.pyplot as p...dScaler\\nfrom sklearn.metrics import roc_auc_score', \"train=pd.read_csv('data/train.csv')\", \"y=train['target']\\nX = train.drop(['target', 'ID_code'], axis=1)\", 'from hyperopt import fmin, tpe, hp, STATUS_OK, T...om sklearn.model_selection import cross_val_score', 'y_small=y[:50000]\\nX_small=X[:50000]', 'from sklearn.neighbors import KNeighborsClassifier', 'def shuffle(x,y,t=4):\\n    # Shuffle positive sam...\\n    y = np.concatenate([y,pos_y])\\n    return x,y', \"X_small = np.array(X_small)\\ny_small = np.array(y... = pd.DataFrame(X_t)\\nX_t = X_t.add_prefix('var_')\", 'X_t.shape', 'sc=StandardScaler()\\nX_t= sc.fit_transform(X_t)', \"best2 = 0\\n\\ndef hyperopt_train_test2(params):\\n   ...': -roc, 'status': STATUS_OK}\\n\\ntrials2 = Trials()\", 'space4knn = {\\n    \\'n_neighbors\\': hp.choice(\\'n_ne...algorithm\\': hp.choice(\\'algorithm\\', [\"kd_tree\"])\\n}', 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {9: (69832, 200)}, 'STATUS_OK': 'ok', 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, 'Trials': <class 'hyperopt.base.Trials'>, 'X':           var_0   var_1    var_2    var_3    var...  12.1284   0.1385  \n\n[200000 rows x 200 columns], 'X_small': array([[  8.9255,  -6.7863,  11.9081, ...,   8.5... ,   9.4139, ...,   9.4495,  14.644 , -12.8522]]), 'X_t': array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), ...}\n        self.user_ns = {'In': ['', 'import numpy as np\\nimport matplotlib.pyplot as p...dScaler\\nfrom sklearn.metrics import roc_auc_score', \"train=pd.read_csv('data/train.csv')\", \"y=train['target']\\nX = train.drop(['target', 'ID_code'], axis=1)\", 'from hyperopt import fmin, tpe, hp, STATUS_OK, T...om sklearn.model_selection import cross_val_score', 'y_small=y[:50000]\\nX_small=X[:50000]', 'from sklearn.neighbors import KNeighborsClassifier', 'def shuffle(x,y,t=4):\\n    # Shuffle positive sam...\\n    y = np.concatenate([y,pos_y])\\n    return x,y', \"X_small = np.array(X_small)\\ny_small = np.array(y... = pd.DataFrame(X_t)\\nX_t = X_t.add_prefix('var_')\", 'X_t.shape', 'sc=StandardScaler()\\nX_t= sc.fit_transform(X_t)', \"best2 = 0\\n\\ndef hyperopt_train_test2(params):\\n   ...': -roc, 'status': STATUS_OK}\\n\\ntrials2 = Trials()\", 'space4knn = {\\n    \\'n_neighbors\\': hp.choice(\\'n_ne...algorithm\\': hp.choice(\\'algorithm\\', [\"kd_tree\"])\\n}', 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {9: (69832, 200)}, 'STATUS_OK': 'ok', 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, 'Trials': <class 'hyperopt.base.Trials'>, 'X':           var_0   var_1    var_2    var_3    var...  12.1284   0.1385  \n\n[200000 rows x 200 columns], 'X_small': array([[  8.9255,  -6.7863,  11.9081, ...,   8.5... ,   9.4139, ...,   9.4495,  14.644 , -12.8522]]), 'X_t': array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), ...}\n   3268             finally:\n   3269                 # Reset our crash handler in place\n   3270                 sys.excepthook = old_excepthook\n   3271         except SystemExit as e:\n\n...........................................................................\nD:\\udacity-git-course\\Machine_learning\\Kaggle\\<ipython-input-13-fc0163bbce31> in <module>()\n----> 1 best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn=<function loss2>, space={'algorithm': <hyperopt.pyll.base.Apply object>, 'n_neighbors': <hyperopt.pyll.base.Apply object>, 'weights': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=10, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=True)\n    383             rstate=rstate,\n    384             pass_expr_memo_ctrl=pass_expr_memo_ctrl,\n    385             verbose=verbose,\n    386             catch_eval_exceptions=catch_eval_exceptions,\n    387             return_argmin=return_argmin,\n--> 388             show_progressbar=show_progressbar,\n        show_progressbar = True\n    389         )\n    390 \n    391     if trials is None:\n    392         if points_to_evaluate is None:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\base.py in fmin(self=<hyperopt.base.Trials object>, fn=<function loss2>, space={'algorithm': <hyperopt.pyll.base.Apply object>, 'n_neighbors': <hyperopt.pyll.base.Apply object>, 'weights': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=10, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=True)\n    634             verbose=verbose,\n    635             allow_trials_fmin=False,  # -- prevent recursion\n    636             pass_expr_memo_ctrl=pass_expr_memo_ctrl,\n    637             catch_eval_exceptions=catch_eval_exceptions,\n    638             return_argmin=return_argmin,\n--> 639             show_progressbar=show_progressbar)\n        show_progressbar = True\n    640 \n    641 \n    642 def trials_from_docs(docs, validate=True, **kwargs):\n    643     \"\"\"Construct a Trials base class instance from a list of trials documents\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn=<function loss2>, space={'algorithm': <hyperopt.pyll.base.Apply object>, 'n_neighbors': <hyperopt.pyll.base.Apply object>, 'weights': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=10, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=True)\n    402                     rstate=rstate,\n    403                     verbose=verbose,\n    404                     max_queue_len=max_queue_len,\n    405                     show_progressbar=show_progressbar)\n    406     rval.catch_eval_exceptions = catch_eval_exceptions\n--> 407     rval.exhaust()\n        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>\n    408     if return_argmin:\n    409         return trials.argmin\n    410     elif len(trials) > 0:\n    411         # Only if there are some succesfull trail runs, return the best point in the evaluation space\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)\n    257             raise StopIteration()\n    258         return self.trials\n    259 \n    260     def exhaust(self):\n    261         n_done = len(self.trials)\n--> 262         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>\n        self.max_evals = 10\n        n_done = 0\n        self.asynchronous = False\n    263         self.trials.refresh()\n    264         return self\n    265 \n    266 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=10, block_until_done=False)\n    222                     if self.asynchronous:\n    223                         # -- wait for workers to fill in the trials\n    224                         time.sleep(self.poll_interval_secs)\n    225                     else:\n    226                         # -- loop over trials and do the jobs directly\n--> 227                         self.serial_evaluate()\n        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>\n    228 \n    229                     try:\n    230                         best_loss = min([d['result']['loss'] for d in\n    231                                          self.trials.trials if\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)\n    136                 trial['book_time'] = now\n    137                 trial['refresh_time'] = now\n    138                 spec = base.spec_from_misc(trial['misc'])\n    139                 ctrl = base.Ctrl(self.trials, current_trial=trial)\n    140                 try:\n--> 141                     result = self.domain.evaluate(spec, ctrl)\n        result = undefined\n        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>\n        spec = {'algorithm': 0, 'n_neighbors': 4, 'weights': 0}\n        ctrl = <hyperopt.base.Ctrl object>\n    142                 except Exception as e:\n    143                     logger.info('job exception: %s' % str(e))\n    144                     trial['state'] = base.JOB_STATE_ERROR\n    145                     trial['misc']['error'] = (str(type(e)), str(e))\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\base.py in evaluate(self=<hyperopt.base.Domain object>, config={'algorithm': 0, 'n_neighbors': 4, 'weights': 0}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)\n    839             #    or the normal Python part (self.fn)\n    840             pyll_rval = pyll.rec_eval(\n    841                 self.expr,\n    842                 memo=memo,\n    843                 print_node_on_error=self.rec_eval_print_node_on_error)\n--> 844             rval = self.fn(pyll_rval)\n        rval = undefined\n        self.fn = <function loss2>\n        pyll_rval = {'algorithm': 'kd_tree', 'n_neighbors': 16384, 'weights': 'uniform'}\n    845 \n    846         if isinstance(rval, (float, int, np.number)):\n    847             dict_rval = {'loss': float(rval), 'status': STATUS_OK}\n    848         else:\n\n...........................................................................\nD:\\udacity-git-course\\Machine_learning\\Kaggle\\<ipython-input-11-418ae89fd4e3> in loss2(params={'algorithm': 'kd_tree', 'n_neighbors': 16384, 'weights': 'uniform'})\n      4     clf = KNeighborsClassifier(**params)\n      5     return cross_val_score(clf, X_t, y_t,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n      6 \n      7 def loss2(params):\n      8     global best2\n----> 9     roc = hyperopt_train_test2(params)\n     10     if roc > best2:\n     11         best2 = roc\n     12         print ('new best:', best2, params)\n     13     return {'loss': -roc, 'status': STATUS_OK}\n\n...........................................................................\nD:\\udacity-git-course\\Machine_learning\\Kaggle\\<ipython-input-11-418ae89fd4e3> in hyperopt_train_test2(params={'algorithm': 'kd_tree', 'n_neighbors': 16384, 'weights': 'uniform'})\n      1 best2 = 0\n      2 \n      3 def hyperopt_train_test2(params):\n      4     clf = KNeighborsClassifier(**params)\n----> 5     return cross_val_score(clf, X_t, y_t,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n      6 \n      7 def loss2(params):\n      8     global best2\n      9     roc = hyperopt_train_test2(params)\n     10     if roc > best2:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), groups=None, scoring='roc_auc', cv=3, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]])\n        y = array([0., 0., 0., ..., 1., 1., 1.])\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Thu Mar 28 16:07:56 2019\nPID: 15956                             Python 3.7.2: D:\\Anaconda\\python.exe\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([16635, 16636, 16637, ..., 69829, 69830, 69831]), test=array([    0,     1,     2, ..., 53303, 53304, 53305]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorers={'score': make_scorer(roc_auc_score, needs_threshold=True)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y=array([0., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    189                 # For multi-output multi-class estimator\n    190                 if isinstance(y_pred, list):\n    191                     y_pred = np.vstack(p for p in y_pred).T\n    192 \n    193             except (NotImplementedError, AttributeError):\n--> 194                 y_pred = clf.predict_proba(X)\n        y_pred = undefined\n        clf.predict_proba = <bound method KNeighborsClassifier.predict_proba...ghbors=16384, p=2,\n           weights='uniform')>\n        X = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n    195 \n    196                 if y_type == \"binary\":\n    197                     y_pred = y_pred[:, 1]\n    198                 elif isinstance(y_pred, list):\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict_proba(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]))\n    185             The class probabilities of the input samples. Classes are ordered\n    186             by lexicographic order.\n    187         \"\"\"\n    188         X = check_array(X, accept_sparse='csr')\n    189 \n--> 190         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei...ghbors=16384, p=2,\n           weights='uniform')>\n        X = array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]])\n    191 \n    192         classes_ = self.classes_\n    193         _y = self._y\n    194         if not self.outputs_2d_:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]), n_neighbors=16384, return_distance=True)\n    384                     X[s], n_neighbors, return_distance)\n    385                 for s in gen_even_slices(X.shape[0], n_jobs)\n    386             )\n    387             if return_distance:\n    388                 dist, neigh_ind = tuple(zip(*result))\n--> 389                 result = np.vstack(dist), np.vstack(neigh_ind)\n        result = [(array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]), array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64))]\n        dist = (array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]),)\n        neigh_ind = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    390             else:\n    391                 result = np.vstack(result)\n    392         else:\n    393             raise ValueError(\"internal: _fit_method not recognized\")\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py in vstack(tup=(array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),))\n    278            [3],\n    279            [4]])\n    280 \n    281     \"\"\"\n    282     _warn_for_nonsequence(tup)\n--> 283     return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)\n        tup = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    284 \n    285 \n    286 @array_function_dispatch(_vhstack_dispatcher)\n    287 def hstack(tup):\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 187, in __call__\n    y_pred = clf.decision_function(X)\nAttributeError: 'KNeighborsClassifier' object has no attribute 'decision_function'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 488, in _fit_and_score\n    test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 523, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 553, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 194, in __call__\n    y_pred = clf.predict_proba(X)\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\classification.py\", line 190, in predict_proba\n    neigh_dist, neigh_ind = self.kneighbors(X)\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\base.py\", line 389, in kneighbors\n    result = np.vstack(dist), np.vstack(neigh_ind)\n  File \"D:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 283, in vstack\n    return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"D:\\Anaconda\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"D:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Thu Mar 28 16:07:56 2019\nPID: 15956                             Python 3.7.2: D:\\Anaconda\\python.exe\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([16635, 16636, 16637, ..., 69829, 69830, 69831]), test=array([    0,     1,     2, ..., 53303, 53304, 53305]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorers={'score': make_scorer(roc_auc_score, needs_threshold=True)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y=array([0., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    189                 # For multi-output multi-class estimator\n    190                 if isinstance(y_pred, list):\n    191                     y_pred = np.vstack(p for p in y_pred).T\n    192 \n    193             except (NotImplementedError, AttributeError):\n--> 194                 y_pred = clf.predict_proba(X)\n        y_pred = undefined\n        clf.predict_proba = <bound method KNeighborsClassifier.predict_proba...ghbors=16384, p=2,\n           weights='uniform')>\n        X = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n    195 \n    196                 if y_type == \"binary\":\n    197                     y_pred = y_pred[:, 1]\n    198                 elif isinstance(y_pred, list):\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict_proba(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]))\n    185             The class probabilities of the input samples. Classes are ordered\n    186             by lexicographic order.\n    187         \"\"\"\n    188         X = check_array(X, accept_sparse='csr')\n    189 \n--> 190         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei...ghbors=16384, p=2,\n           weights='uniform')>\n        X = array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]])\n    191 \n    192         classes_ = self.classes_\n    193         _y = self._y\n    194         if not self.outputs_2d_:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]), n_neighbors=16384, return_distance=True)\n    384                     X[s], n_neighbors, return_distance)\n    385                 for s in gen_even_slices(X.shape[0], n_jobs)\n    386             )\n    387             if return_distance:\n    388                 dist, neigh_ind = tuple(zip(*result))\n--> 389                 result = np.vstack(dist), np.vstack(neigh_ind)\n        result = [(array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]), array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64))]\n        dist = (array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]),)\n        neigh_ind = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    390             else:\n    391                 result = np.vstack(result)\n    392         else:\n    393             raise ValueError(\"internal: _fit_method not recognized\")\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py in vstack(tup=(array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),))\n    278            [3],\n    279            [4]])\n    280 \n    281     \"\"\"\n    282     _warn_for_nonsequence(tup)\n--> 283     return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)\n        tup = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    284 \n    285 \n    286 @array_function_dispatch(_vhstack_dispatcher)\n    287 def hstack(tup):\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Thu Mar 28 16:07:56 2019\nPID: 15956                             Python 3.7.2: D:\\Anaconda\\python.exe\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([16635, 16636, 16637, ..., 69829, 69830, 69831]), test=array([    0,     1,     2, ..., 53303, 53304, 53305]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorers={'score': make_scorer(roc_auc_score, needs_threshold=True)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y=array([0., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    189                 # For multi-output multi-class estimator\n    190                 if isinstance(y_pred, list):\n    191                     y_pred = np.vstack(p for p in y_pred).T\n    192 \n    193             except (NotImplementedError, AttributeError):\n--> 194                 y_pred = clf.predict_proba(X)\n        y_pred = undefined\n        clf.predict_proba = <bound method KNeighborsClassifier.predict_proba...ghbors=16384, p=2,\n           weights='uniform')>\n        X = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n    195 \n    196                 if y_type == \"binary\":\n    197                     y_pred = y_pred[:, 1]\n    198                 elif isinstance(y_pred, list):\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict_proba(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]))\n    185             The class probabilities of the input samples. Classes are ordered\n    186             by lexicographic order.\n    187         \"\"\"\n    188         X = check_array(X, accept_sparse='csr')\n    189 \n--> 190         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei...ghbors=16384, p=2,\n           weights='uniform')>\n        X = array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]])\n    191 \n    192         classes_ = self.classes_\n    193         _y = self._y\n    194         if not self.outputs_2d_:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]), n_neighbors=16384, return_distance=True)\n    384                     X[s], n_neighbors, return_distance)\n    385                 for s in gen_even_slices(X.shape[0], n_jobs)\n    386             )\n    387             if return_distance:\n    388                 dist, neigh_ind = tuple(zip(*result))\n--> 389                 result = np.vstack(dist), np.vstack(neigh_ind)\n        result = [(array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]), array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64))]\n        dist = (array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]),)\n        neigh_ind = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    390             else:\n    391                 result = np.vstack(result)\n    392         else:\n    393             raise ValueError(\"internal: _fit_method not recognized\")\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py in vstack(tup=(array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),))\n    278            [3],\n    279            [4]])\n    280 \n    281     \"\"\"\n    282     _warn_for_nonsequence(tup)\n--> 283     return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)\n        tup = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    284 \n    285 \n    286 @array_function_dispatch(_vhstack_dispatcher)\n    287 def hstack(tup):\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fc0163bbce31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbest_cv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace4knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         )\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-418ae89fd4e3>\u001b[0m in \u001b[0;36mloss2\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mbest2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mroc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhyperopt_train_test2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mroc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mbest2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-418ae89fd4e3>\u001b[0m in \u001b[0;36mhyperopt_train_test2\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhyperopt_train_test2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nD:\\Anaconda\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nD:\\Anaconda\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C908DE0540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001C908DE0540, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'D:\\Anaconda\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...onda\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'D:\\\\Anaconda\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    500         if self.poller is not None:\n    501             self.poller.start()\n    502         self.kernel.start()\n    503         self.io_loop = ioloop.IOLoop.current()\n    504         try:\n--> 505             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    506         except KeyboardInterrupt:\n    507             pass\n    508 \n    509 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nD:\\Anaconda\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    534         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    535                                finalizer=self._asyncgen_finalizer_hook)\n    536         try:\n    537             events._set_running_loop(self)\n    538             while True:\n--> 539                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    540                 if self._stopping:\n    541                     break\n    542         finally:\n    543             self._stopping = False\n\n...........................................................................\nD:\\Anaconda\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1770                         logger.warning('Executing %s took %.3f seconds',\n   1771                                        _format_handle(handle), dt)\n   1772                 finally:\n   1773                     self._current_handle = None\n   1774             else:\n-> 1775                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...8E8>, ...]))>))>>\n   1776         handle = None  # Needed to break cycles when an exception occurs.\n   1777 \n   1778     def _set_coroutine_origin_tracking(self, enabled):\n   1779         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\nD:\\Anaconda\\lib\\asyncio\\events.py in _run(self=<Handle IOLoop._run_callback(functools.par...8E8>, ...]))>))>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_w...B2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>),)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_w...B2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>))\n    753         \"\"\"Runs a callback with error handling.\n    754 \n    755         For use in subclasses.\n    756         \"\"\"\n    757         try:\n--> 758             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_w...B2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>)\n    759             if ret is not None:\n    760                 from tornado import gen\n    761                 # Functions that return Futures typically swallow all\n    762                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<Future finished result=(10, 15, <bound method.....EB2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>,), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<Future finished result=(10, 15, <bound method.....EB2E830>, <zmq.sugar.fr...001C90EB2E8E8>, ...]))>,)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in inner(f=None)\n   1228             return False\n   1229         elif not self.future.done():\n   1230             def inner(f):\n   1231                 # Break a reference cycle to speed GC.\n   1232                 f = None  # noqa\n-> 1233                 self.run()\n   1234             self.io_loop.add_future(\n   1235                 self.future, inner)\n   1236             return False\n   1237         return True\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in run(self=<tornado.gen.Runner object>)\n   1142                         finally:\n   1143                             # Break up a reference to itself\n   1144                             # for faster GC on CPython.\n   1145                             exc_info = None\n   1146                     else:\n-> 1147                         yielded = self.gen.send(value)\n        yielded = undefined\n        self.gen.send = <built-in method send of generator object>\n        value = (10, 15, <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>, (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]))\n   1148 \n   1149                     if stack_context._state.contexts is not orig_stack_contexts:\n   1150                         self.gen.throw(\n   1151                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in process_one(self=<ipykernel.ipkernel.IPythonKernel object>, wait=True)\n    352         else:\n    353             try:\n    354                 priority, t, dispatch, args = self.msg_queue.get_nowait()\n    355             except QueueEmpty:\n    356                 return None\n--> 357         yield gen.maybe_future(dispatch(*args))\n        dispatch = <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object>>\n        args = (<zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    358 \n    359     @gen.coroutine\n    360     def dispatch_queue(self):\n    361         \"\"\"Coroutine to preserve order of message handling\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object Kernel.dispatch_shell>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}})\n    262             try:\n    263                 self.pre_handler_hook()\n    264             except Exception:\n    265                 self.log.debug(\"Unable to signal in pre_handler_hook:\", exc_info=True)\n    266             try:\n--> 267                 yield gen.maybe_future(handler(stream, idents, msg))\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'1c7b9fbdbafd40cd8ea3937b9654399c']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}}\n    268             except Exception:\n    269                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    270             finally:\n    271                 try:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, <zmq.eventloop.zmqstream.ZMQStream object>, [b'1c7b9fbdbafd40cd8ea3937b9654399c'], {'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}}), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object Kernel.execute_request>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'1c7b9fbdbafd40cd8ea3937b9654399c'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 14, 53, 4, 619876, tzinfo=tzutc()), 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'session': '1c7b9fbdbafd40cd8ea3937b9654399c', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '7c309707b54a45b7843694ed957142cd', 'msg_type': 'execute_request', 'parent_header': {}})\n    529             self._publish_execute_input(code, parent, self.execution_count)\n    530 \n    531         reply_content = yield gen.maybe_future(\n    532             self.do_execute(\n    533                 code, silent, store_history,\n--> 534                 user_expressions, allow_stdin,\n        user_expressions = {}\n        allow_stdin = True\n    535             )\n    536         )\n    537 \n    538         # Flush output before sending the reply.\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\tornado\\gen.py in wrapper(*args=(<ipykernel.ipkernel.IPythonKernel object>, 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', False, True, {}, True), **kwargs={})\n    321                 # never actually yields, which in turn allows us to\n    322                 # use \"optional\" coroutines in critical path code without\n    323                 # performance penalty for the synchronous case.\n    324                 try:\n    325                     orig_stack_contexts = stack_context._state.contexts\n--> 326                     yielded = next(result)\n        yielded = undefined\n        result = <generator object IPythonKernel.do_execute>\n    327                     if stack_context._state.contexts is not orig_stack_contexts:\n    328                         yielded = _create_future()\n    329                         yielded.set_exception(\n    330                             stack_context.StackContextInconsistentError(\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    289                     res = yield coro_future\n    290             else:\n    291                 # runner isn't already running,\n    292                 # make synchronous call,\n    293                 # letting shell dispatch to loop runners\n--> 294                 res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        code = 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'\n        store_history = True\n        silent = False\n    295         finally:\n    296             self._restore_input()\n    297 \n    298         if res.error_before_exec is not None:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)',), **kwargs={'silent': False, 'store_history': True})\n    531             )\n    532         self.payload_manager.write_payload(payload)\n    533 \n    534     def run_cell(self, *args, **kwargs):\n    535         self._last_traceback = None\n--> 536         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)',)\n        kwargs = {'silent': False, 'store_history': True}\n    537 \n    538     def _showtraceback(self, etype, evalue, stb):\n    539         # try to preserve ordering of tracebacks and print statements\n    540         sys.stdout.flush()\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', store_history=True, silent=False, shell_futures=True)\n   2814         result : :class:`ExecutionResult`\n   2815         \"\"\"\n   2816         result = None\n   2817         try:\n   2818             result = self._run_cell(\n-> 2819                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2820         finally:\n   2821             self.events.trigger('post_execute')\n   2822             if not silent:\n   2823                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', store_history=True, silent=False, shell_futures=True)\n   2840             runner = self.loop_runner\n   2841         else:\n   2842             runner = _pseudo_sync_runner\n   2843 \n   2844         try:\n-> 2845             return runner(coro)\n        runner = <function _pseudo_sync_runner>\n        coro = <generator object InteractiveShell.run_cell_async>\n   2846         except BaseException as e:\n   2847             info = ExecutionInfo(raw_cell, store_history, silent, shell_futures)\n   2848             result = ExecutionResult(info)\n   2849             result.error_in_exec = e\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\async_helpers.py in _pseudo_sync_runner(coro=<generator object InteractiveShell.run_cell_async>)\n     62 \n     63     Credit to Nathaniel Smith\n     64 \n     65     \"\"\"\n     66     try:\n---> 67         coro.send(None)\n        coro.send = <built-in method send of generator object>\n     68     except StopIteration as exc:\n     69         return exc.value\n     70     else:\n     71         # TODO: do not raise but return an execution result with the right info.\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_async(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)', store_history=True, silent=False, shell_futures=True)\n   3015                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   3016                 if _run_async:\n   3017                     interactivity = 'async'\n   3018 \n   3019                 has_raised = yield from self.run_ast_nodes(code_ast.body, cell_name,\n-> 3020                        interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   3021 \n   3022                 self.last_execution_succeeded = not has_raised\n   3023                 self.last_execution_result = result\n   3024 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>], cell_name='<ipython-input-13-fc0163bbce31>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c91023ae10, executio...rue silent=False shell_futures=True> result=None>)\n   3180                     return True\n   3181             else:\n   3182                 for i, node in enumerate(to_run_exec):\n   3183                     mod = ast.Module([node])\n   3184                     code = compiler(mod, cell_name, \"exec\")\n-> 3185                     if (yield from self.run_code(code, result)):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001C9101E5C90, file \"<ipython-input-13-fc0163bbce31>\", line 1>\n        result = <ExecutionResult object at 1c91023ae10, executio...rue silent=False shell_futures=True> result=None>\n   3186                         return True\n   3187 \n   3188                 for i, node in enumerate(to_run_interactive):\n   3189                     mod = ast.Interactive([node])\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C9101E5C90, file \"<ipython-input-13-fc0163bbce31>\", line 1>, result=<ExecutionResult object at 1c91023ae10, executio...rue silent=False shell_futures=True> result=None>, async_=False)\n   3262                 if async_:\n   3263                     last_expr = (yield from self._async_exec(code_obj, self.user_ns))\n   3264                     code = compile('last_expr', 'fake', \"single\")\n   3265                     exec(code, {'last_expr': last_expr})\n   3266                 else:\n-> 3267                     exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001C9101E5C90, file \"<ipython-input-13-fc0163bbce31>\", line 1>\n        self.user_global_ns = {'In': ['', 'import numpy as np\\nimport matplotlib.pyplot as p...dScaler\\nfrom sklearn.metrics import roc_auc_score', \"train=pd.read_csv('data/train.csv')\", \"y=train['target']\\nX = train.drop(['target', 'ID_code'], axis=1)\", 'from hyperopt import fmin, tpe, hp, STATUS_OK, T...om sklearn.model_selection import cross_val_score', 'y_small=y[:50000]\\nX_small=X[:50000]', 'from sklearn.neighbors import KNeighborsClassifier', 'def shuffle(x,y,t=4):\\n    # Shuffle positive sam...\\n    y = np.concatenate([y,pos_y])\\n    return x,y', \"X_small = np.array(X_small)\\ny_small = np.array(y... = pd.DataFrame(X_t)\\nX_t = X_t.add_prefix('var_')\", 'X_t.shape', 'sc=StandardScaler()\\nX_t= sc.fit_transform(X_t)', \"best2 = 0\\n\\ndef hyperopt_train_test2(params):\\n   ...': -roc, 'status': STATUS_OK}\\n\\ntrials2 = Trials()\", 'space4knn = {\\n    \\'n_neighbors\\': hp.choice(\\'n_ne...algorithm\\': hp.choice(\\'algorithm\\', [\"kd_tree\"])\\n}', 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {9: (69832, 200)}, 'STATUS_OK': 'ok', 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, 'Trials': <class 'hyperopt.base.Trials'>, 'X':           var_0   var_1    var_2    var_3    var...  12.1284   0.1385  \n\n[200000 rows x 200 columns], 'X_small': array([[  8.9255,  -6.7863,  11.9081, ...,   8.5... ,   9.4139, ...,   9.4495,  14.644 , -12.8522]]), 'X_t': array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), ...}\n        self.user_ns = {'In': ['', 'import numpy as np\\nimport matplotlib.pyplot as p...dScaler\\nfrom sklearn.metrics import roc_auc_score', \"train=pd.read_csv('data/train.csv')\", \"y=train['target']\\nX = train.drop(['target', 'ID_code'], axis=1)\", 'from hyperopt import fmin, tpe, hp, STATUS_OK, T...om sklearn.model_selection import cross_val_score', 'y_small=y[:50000]\\nX_small=X[:50000]', 'from sklearn.neighbors import KNeighborsClassifier', 'def shuffle(x,y,t=4):\\n    # Shuffle positive sam...\\n    y = np.concatenate([y,pos_y])\\n    return x,y', \"X_small = np.array(X_small)\\ny_small = np.array(y... = pd.DataFrame(X_t)\\nX_t = X_t.add_prefix('var_')\", 'X_t.shape', 'sc=StandardScaler()\\nX_t= sc.fit_transform(X_t)', \"best2 = 0\\n\\ndef hyperopt_train_test2(params):\\n   ...': -roc, 'status': STATUS_OK}\\n\\ntrials2 = Trials()\", 'space4knn = {\\n    \\'n_neighbors\\': hp.choice(\\'n_ne...algorithm\\': hp.choice(\\'algorithm\\', [\"kd_tree\"])\\n}', 'best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)'], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Out': {9: (69832, 200)}, 'STATUS_OK': 'ok', 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'StratifiedKFold': <class 'sklearn.model_selection._split.StratifiedKFold'>, 'Trials': <class 'hyperopt.base.Trials'>, 'X':           var_0   var_1    var_2    var_3    var...  12.1284   0.1385  \n\n[200000 rows x 200 columns], 'X_small': array([[  8.9255,  -6.7863,  11.9081, ...,   8.5... ,   9.4139, ...,   9.4495,  14.644 , -12.8522]]), 'X_t': array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), ...}\n   3268             finally:\n   3269                 # Reset our crash handler in place\n   3270                 sys.excepthook = old_excepthook\n   3271         except SystemExit as e:\n\n...........................................................................\nD:\\udacity-git-course\\Machine_learning\\Kaggle\\<ipython-input-13-fc0163bbce31> in <module>()\n----> 1 best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn=<function loss2>, space={'algorithm': <hyperopt.pyll.base.Apply object>, 'n_neighbors': <hyperopt.pyll.base.Apply object>, 'weights': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=10, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=True, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=True)\n    383             rstate=rstate,\n    384             pass_expr_memo_ctrl=pass_expr_memo_ctrl,\n    385             verbose=verbose,\n    386             catch_eval_exceptions=catch_eval_exceptions,\n    387             return_argmin=return_argmin,\n--> 388             show_progressbar=show_progressbar,\n        show_progressbar = True\n    389         )\n    390 \n    391     if trials is None:\n    392         if points_to_evaluate is None:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\base.py in fmin(self=<hyperopt.base.Trials object>, fn=<function loss2>, space={'algorithm': <hyperopt.pyll.base.Apply object>, 'n_neighbors': <hyperopt.pyll.base.Apply object>, 'weights': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=10, rstate=<mtrand.RandomState object>, verbose=0, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, return_argmin=True, show_progressbar=True)\n    634             verbose=verbose,\n    635             allow_trials_fmin=False,  # -- prevent recursion\n    636             pass_expr_memo_ctrl=pass_expr_memo_ctrl,\n    637             catch_eval_exceptions=catch_eval_exceptions,\n    638             return_argmin=return_argmin,\n--> 639             show_progressbar=show_progressbar)\n        show_progressbar = True\n    640 \n    641 \n    642 def trials_from_docs(docs, validate=True, **kwargs):\n    643     \"\"\"Construct a Trials base class instance from a list of trials documents\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in fmin(fn=<function loss2>, space={'algorithm': <hyperopt.pyll.base.Apply object>, 'n_neighbors': <hyperopt.pyll.base.Apply object>, 'weights': <hyperopt.pyll.base.Apply object>}, algo=<function suggest>, max_evals=10, trials=<hyperopt.base.Trials object>, rstate=<mtrand.RandomState object>, allow_trials_fmin=False, pass_expr_memo_ctrl=None, catch_eval_exceptions=False, verbose=0, return_argmin=True, points_to_evaluate=None, max_queue_len=1, show_progressbar=True)\n    402                     rstate=rstate,\n    403                     verbose=verbose,\n    404                     max_queue_len=max_queue_len,\n    405                     show_progressbar=show_progressbar)\n    406     rval.catch_eval_exceptions = catch_eval_exceptions\n--> 407     rval.exhaust()\n        rval.exhaust = <bound method FMinIter.exhaust of <hyperopt.fmin.FMinIter object>>\n    408     if return_argmin:\n    409         return trials.argmin\n    410     elif len(trials) > 0:\n    411         # Only if there are some succesfull trail runs, return the best point in the evaluation space\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in exhaust(self=<hyperopt.fmin.FMinIter object>)\n    257             raise StopIteration()\n    258         return self.trials\n    259 \n    260     def exhaust(self):\n    261         n_done = len(self.trials)\n--> 262         self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n        self.run = <bound method FMinIter.run of <hyperopt.fmin.FMinIter object>>\n        self.max_evals = 10\n        n_done = 0\n        self.asynchronous = False\n    263         self.trials.refresh()\n    264         return self\n    265 \n    266 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in run(self=<hyperopt.fmin.FMinIter object>, N=10, block_until_done=False)\n    222                     if self.asynchronous:\n    223                         # -- wait for workers to fill in the trials\n    224                         time.sleep(self.poll_interval_secs)\n    225                     else:\n    226                         # -- loop over trials and do the jobs directly\n--> 227                         self.serial_evaluate()\n        self.serial_evaluate = <bound method FMinIter.serial_evaluate of <hyperopt.fmin.FMinIter object>>\n    228 \n    229                     try:\n    230                         best_loss = min([d['result']['loss'] for d in\n    231                                          self.trials.trials if\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\fmin.py in serial_evaluate(self=<hyperopt.fmin.FMinIter object>, N=-1)\n    136                 trial['book_time'] = now\n    137                 trial['refresh_time'] = now\n    138                 spec = base.spec_from_misc(trial['misc'])\n    139                 ctrl = base.Ctrl(self.trials, current_trial=trial)\n    140                 try:\n--> 141                     result = self.domain.evaluate(spec, ctrl)\n        result = undefined\n        self.domain.evaluate = <bound method Domain.evaluate of <hyperopt.base.Domain object>>\n        spec = {'algorithm': 0, 'n_neighbors': 4, 'weights': 0}\n        ctrl = <hyperopt.base.Ctrl object>\n    142                 except Exception as e:\n    143                     logger.info('job exception: %s' % str(e))\n    144                     trial['state'] = base.JOB_STATE_ERROR\n    145                     trial['misc']['error'] = (str(type(e)), str(e))\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\hyperopt\\base.py in evaluate(self=<hyperopt.base.Domain object>, config={'algorithm': 0, 'n_neighbors': 4, 'weights': 0}, ctrl=<hyperopt.base.Ctrl object>, attach_attachments=True)\n    839             #    or the normal Python part (self.fn)\n    840             pyll_rval = pyll.rec_eval(\n    841                 self.expr,\n    842                 memo=memo,\n    843                 print_node_on_error=self.rec_eval_print_node_on_error)\n--> 844             rval = self.fn(pyll_rval)\n        rval = undefined\n        self.fn = <function loss2>\n        pyll_rval = {'algorithm': 'kd_tree', 'n_neighbors': 16384, 'weights': 'uniform'}\n    845 \n    846         if isinstance(rval, (float, int, np.number)):\n    847             dict_rval = {'loss': float(rval), 'status': STATUS_OK}\n    848         else:\n\n...........................................................................\nD:\\udacity-git-course\\Machine_learning\\Kaggle\\<ipython-input-11-418ae89fd4e3> in loss2(params={'algorithm': 'kd_tree', 'n_neighbors': 16384, 'weights': 'uniform'})\n      4     clf = KNeighborsClassifier(**params)\n      5     return cross_val_score(clf, X_t, y_t,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n      6 \n      7 def loss2(params):\n      8     global best2\n----> 9     roc = hyperopt_train_test2(params)\n     10     if roc > best2:\n     11         best2 = roc\n     12         print ('new best:', best2, params)\n     13     return {'loss': -roc, 'status': STATUS_OK}\n\n...........................................................................\nD:\\udacity-git-course\\Machine_learning\\Kaggle\\<ipython-input-11-418ae89fd4e3> in hyperopt_train_test2(params={'algorithm': 'kd_tree', 'n_neighbors': 16384, 'weights': 'uniform'})\n      1 best2 = 0\n      2 \n      3 def hyperopt_train_test2(params):\n      4     clf = KNeighborsClassifier(**params)\n----> 5     return cross_val_score(clf, X_t, y_t,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n      6 \n      7 def loss2(params):\n      8     global best2\n      9     roc = hyperopt_train_test2(params)\n     10     if roc > best2:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), groups=None, scoring='roc_auc', cv=3, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_validate(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), groups=None, scoring={'score': make_scorer(roc_auc_score, needs_threshold=True)}, cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[-0.59672478, -1.29139677,  0.41000273, .... -1.53337143,\n         1.57010542, -0.14259955]])\n        y = array([0., 0., 0., ..., 1., 1., 1.])\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Thu Mar 28 16:07:56 2019\nPID: 15956                             Python 3.7.2: D:\\Anaconda\\python.exe\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), array([0., 0., 0., ..., 1., 1., 1.]), {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([16635, 16636, 16637, ..., 69829, 69830, 69831]), array([    0,     1,     2, ..., 53303, 53304, 53305]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-1.53337143,\n          1.57010542, -0.14259955]]), y=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([16635, 16636, 16637, ..., 69829, 69830, 69831]), test=array([    0,     1,     2, ..., 53303, 53304, 53305]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    483                              \" make sure that it has been spelled correctly.)\")\n    484 \n    485     else:\n    486         fit_time = time.time() - start_time\n    487         # _score will return dict if is_multimetric is True\n--> 488         test_scores = _score(estimator, X_test, y_test, scorer, is_multimetric)\n        test_scores = {}\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n        is_multimetric = True\n    489         score_time = time.time() - start_time - fit_time\n    490         if return_train_score:\n    491             train_scores = _score(estimator, X_train, y_train, scorer,\n    492                                   is_multimetric)\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, is_multimetric=True)\n    518 \n    519     Will return a single float if is_multimetric is False and a dict of floats,\n    520     if is_multimetric is True\n    521     \"\"\"\n    522     if is_multimetric:\n--> 523         return _multimetric_score(estimator, X_test, y_test, scorer)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n        scorer = {'score': make_scorer(roc_auc_score, needs_threshold=True)}\n    524     else:\n    525         if y_test is None:\n    526             score = scorer(estimator, X_test)\n    527         else:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _multimetric_score(estimator=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X_test=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y_test=array([0., 0., 0., ..., 1., 1., 1.]), scorers={'score': make_scorer(roc_auc_score, needs_threshold=True)})\n    548 \n    549     for name, scorer in scorers.items():\n    550         if y_test is None:\n    551             score = scorer(estimator, X_test)\n    552         else:\n--> 553             score = scorer(estimator, X_test, y_test)\n        score = undefined\n        scorer = make_scorer(roc_auc_score, needs_threshold=True)\n        estimator = KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform')\n        X_test = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n        y_test = array([0., 0., 0., ..., 1., 1., 1.])\n    554 \n    555         if hasattr(score, 'item'):\n    556             try:\n    557                 # e.g. unwrap memmapped scalars\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\scorer.py in __call__(self=make_scorer(roc_auc_score, needs_threshold=True), clf=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]]), y=array([0., 0., 0., ..., 1., 1., 1.]), sample_weight=None)\n    189                 # For multi-output multi-class estimator\n    190                 if isinstance(y_pred, list):\n    191                     y_pred = np.vstack(p for p in y_pred).T\n    192 \n    193             except (NotImplementedError, AttributeError):\n--> 194                 y_pred = clf.predict_proba(X)\n        y_pred = undefined\n        clf.predict_proba = <bound method KNeighborsClassifier.predict_proba...ghbors=16384, p=2,\n           weights='uniform')>\n        X = memmap([[-0.59672478, -1.29139677,  0.41000273, ...-2.07288258,\n         -2.46637397,  1.63867457]])\n    195 \n    196                 if y_type == \"binary\":\n    197                     y_pred = y_pred[:, 1]\n    198                 elif isinstance(y_pred, list):\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\classification.py in predict_proba(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]))\n    185             The class probabilities of the input samples. Classes are ordered\n    186             by lexicographic order.\n    187         \"\"\"\n    188         X = check_array(X, accept_sparse='csr')\n    189 \n--> 190         neigh_dist, neigh_ind = self.kneighbors(X)\n        neigh_dist = undefined\n        neigh_ind = undefined\n        self.kneighbors = <bound method KNeighborsMixin.kneighbors of KNei...ghbors=16384, p=2,\n           weights='uniform')>\n        X = array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]])\n    191 \n    192         classes_ = self.classes_\n    193         _y = self._y\n    194         if not self.outputs_2d_:\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\sklearn\\neighbors\\base.py in kneighbors(self=KNeighborsClassifier(algorithm='kd_tree', leaf_s...ighbors=16384, p=2,\n           weights='uniform'), X=array([[-0.59672478, -1.29139677,  0.41000273, .... -2.07288258,\n        -2.46637397,  1.63867457]]), n_neighbors=16384, return_distance=True)\n    384                     X[s], n_neighbors, return_distance)\n    385                 for s in gen_even_slices(X.shape[0], n_jobs)\n    386             )\n    387             if return_distance:\n    388                 dist, neigh_ind = tuple(zip(*result))\n--> 389                 result = np.vstack(dist), np.vstack(neigh_ind)\n        result = [(array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]), array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64))]\n        dist = (array([[16.24419813, 16.33248083, 16.34342691, .... 21.05574236,\n        21.05574236, 21.05601846]]),)\n        neigh_ind = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    390             else:\n    391                 result = np.vstack(result)\n    392         else:\n    393             raise ValueError(\"internal: _fit_method not recognized\")\n\n...........................................................................\nD:\\Anaconda\\lib\\site-packages\\numpy\\core\\shape_base.py in vstack(tup=(array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),))\n    278            [3],\n    279            [4]])\n    280 \n    281     \"\"\"\n    282     _warn_for_nonsequence(tup)\n--> 283     return _nx.concatenate([atleast_2d(_m) for _m in tup], 0)\n        tup = (array([[17582,  8135,  8520, ..., 23681,  6079, ..., 39943, ..., 45236, 30362, 34081]], dtype=int64),)\n    284 \n    285 \n    286 @array_function_dispatch(_vhstack_dispatcher)\n    287 def hstack(tup):\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "best_cv2 = fmin(loss2, space4knn, algo=tpe.suggest, max_evals=10, trials=trials2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 n_neighbors\n",
      "1 weights\n",
      "2 algorithm\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = ['n_neighbors', 'weights', 'algorithm']\n",
    "\n",
    "f, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "for i, val in enumerate(parameters):\n",
    "    print (i, val)\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials2.trials]).ravel()\n",
    "    ys = [-t['result']['loss'] for t in trials2.trials]\n",
    "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
    "    ys = np.array(ys)\n",
    "    axes[i//3,i%3].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i//3,i%3].set_title(val)\n",
    "    #axes[i/3,i%3].set_ylim([0.9,1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "best3 = 0\n",
    "\n",
    "def hyperopt_train_test3(params):\n",
    "    clf = LogisticRegression(**params)\n",
    "    return cross_val_score(clf, lgb_train, y,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n",
    "\n",
    "def loss3(params):\n",
    "    global best3\n",
    "    roc = hyperopt_train_test3(params)\n",
    "    if roc > best3:\n",
    "        best3 = roc\n",
    "        print ('new best:', best3, params)\n",
    "    return {'loss': -roc, 'status': STATUS_OK}\n",
    "\n",
    "trials3 = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4lr = {\n",
    "    'C': hp.lognormal('C', 0, 5),\n",
    "    'class_weight': hp.choice('class_weight ', [None, 'balanced']),\n",
    "    'penalty': hp.choice('penalty', ['l1']),\n",
    "    'solver': hp.choice('solver',['saga','liblinear'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901549951457467\n"
     ]
    }
   ],
   "source": [
    "oof=np.zeros(len(lgb_train))\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True,random_state=1111).split(lgb_train, y))\n",
    "for i, (train_idx, valid_idx) in enumerate(splits):\n",
    "    clf=LogisticRegression(C=0.000602399041, class_weight=None, penalty='l1',solver='saga')\n",
    "    x_trn=np.array(lgb_train)[train_idx]\n",
    "    y_trn=np.array(y)[train_idx]\n",
    "    clf.fit(x_trn,y_trn)\n",
    "    x_val=np.array(lgb_train)[valid_idx]\n",
    "    oof[valid_idx]=clf.predict_proba(x_val)[:,1]\n",
    "print (roc_auc_score(y, oof))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.75677778, 0.21202559, 0.        , 0.        , 0.49735836,\n",
       "        0.49735836, 0.34619125]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb_rank</th>\n",
       "      <th>xgb_rank</th>\n",
       "      <th>et_rank</th>\n",
       "      <th>rf_rank</th>\n",
       "      <th>nb_rank</th>\n",
       "      <th>knn_rank</th>\n",
       "      <th>nn_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.16339</td>\n",
       "      <td>0.224845</td>\n",
       "      <td>0.262845</td>\n",
       "      <td>0.240780</td>\n",
       "      <td>0.240780</td>\n",
       "      <td>0.197350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.932675</td>\n",
       "      <td>0.91672</td>\n",
       "      <td>0.960690</td>\n",
       "      <td>0.943895</td>\n",
       "      <td>0.929245</td>\n",
       "      <td>0.929245</td>\n",
       "      <td>0.958160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.07826</td>\n",
       "      <td>0.292580</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>0.115795</td>\n",
       "      <td>0.115795</td>\n",
       "      <td>0.137145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893975</td>\n",
       "      <td>0.90369</td>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.843835</td>\n",
       "      <td>0.899970</td>\n",
       "      <td>0.899970</td>\n",
       "      <td>0.878670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.743020</td>\n",
       "      <td>0.82797</td>\n",
       "      <td>0.720895</td>\n",
       "      <td>0.730730</td>\n",
       "      <td>0.748295</td>\n",
       "      <td>0.748295</td>\n",
       "      <td>0.713790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lgb_rank  xgb_rank   et_rank   rf_rank   nb_rank  knn_rank   nn_rank\n",
       "0  0.172765   0.16339  0.224845  0.262845  0.240780  0.240780  0.197350\n",
       "1  0.932675   0.91672  0.960690  0.943895  0.929245  0.929245  0.958160\n",
       "2  0.105860   0.07826  0.292580  0.079755  0.115795  0.115795  0.137145\n",
       "3  0.893975   0.90369  0.891025  0.843835  0.899970  0.899970  0.878670\n",
       "4  0.743020   0.82797  0.720895  0.730730  0.748295  0.748295  0.713790"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best:                                                                                                              \n",
      "0.5                                                                                                                    \n",
      "{'C': 2.0559144250889053e-05, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}                                 \n",
      "new best:                                                                                                              \n",
      "0.9014854003330851                                                                                                     \n",
      "{'C': 0.06634008745470066, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}                         \n",
      "new best:                                                                                                              \n",
      "0.901486522952677                                                                                                      \n",
      "{'C': 0.05164958658336488, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}                         \n",
      "new best:                                                                                                              \n",
      "0.9015170053424794                                                                                                     \n",
      "{'C': 0.0013128221869754043, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}                                  \n",
      "new best:                                                                                                              \n",
      "0.9015909960114553                                                                                                     \n",
      "{'C': 0.0003675429426041279, 'class_weight': 'balanced', 'penalty': 'l1', 'solver': 'liblinear'}                       \n",
      "new best:                                                                                                              \n",
      "0.9016233073803105                                                                                                     \n",
      "{'C': 0.0007189612202717262, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}                                  \n",
      "new best:                                                                                                              \n",
      "0.9016283019015529                                                                                                     \n",
      "{'C': 0.000562567234465805, 'class_weight': None, 'penalty': 'l1', 'solver': 'saga'}                                   \n",
      "100%|██████████████████████████████████████████████████| 50/50 [12:03<00:00,  4.14s/it, best loss: -0.9016283019015529]\n"
     ]
    }
   ],
   "source": [
    "best_cv3 = fmin(loss3, space4lr, algo=tpe.suggest, max_evals=50, trials=trials3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 C\n",
      "1 class_weight \n",
      "2 penalty\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = ['C', 'class_weight ', 'penalty']\n",
    "\n",
    "f, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,10))\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "for i, val in enumerate(parameters):\n",
    "    print (i, val)\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials3.trials]).ravel()\n",
    "    ys = [-t['result']['loss'] for t in trials3.trials]\n",
    "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
    "    ys = np.array(ys)\n",
    "    axes[i//3,i%3].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i//3,i%3].set_title(val)\n",
    "    #axes[i/3,i%3].set_ylim([0.9,1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "best4 = 0\n",
    "\n",
    "def hyperopt_train_test4(params):\n",
    "    clf = SVC(**params)\n",
    "    return cross_val_score(clf, X_small, y_small,scoring='roc_auc', cv=3, n_jobs=-1).mean()\n",
    "\n",
    "def loss4(params):\n",
    "    global best4\n",
    "    roc = hyperopt_train_test4(params)\n",
    "    if roc > best4:\n",
    "        best4 = roc\n",
    "        print ('new best:', best4, params)\n",
    "    return {'loss': -roc, 'status': STATUS_OK}\n",
    "\n",
    "trials4 = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4svc = {\n",
    "    'C': hp.lognormal('C', 0, 3),\n",
    "    'kernel': hp.choice('kernel ', ['rbf', 'poly','sigmoid']),\n",
    "    'gamma': hp.lognormal('gamma', 0, 3),\n",
    "    'class_weight': hp.choice('class_weight', ['balanced']),\n",
    "     'degree': hp.choice('degree', [1,2,3])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best:                                                                                                              \n",
      "0.5                                                                                                                    \n",
      "{'C': 0.31894451155462056, 'class_weight': 'balanced', 'degree': 2, 'gamma': 0.6399732463927398, 'kernel': 'rbf'}      \n",
      "  1%|▌                                                           | 1/100 [30:16<49:56:32, 1816.08s/it, best loss: -0.5]"
     ]
    }
   ],
   "source": [
    "best_cv4 = fmin(loss4, space4svc, algo=tpe.suggest, max_evals=100, trials=trials4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train=pd.read_csv('data/oof_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>et</th>\n",
       "      <th>rf</th>\n",
       "      <th>nb</th>\n",
       "      <th>knn1024</th>\n",
       "      <th>knn2048</th>\n",
       "      <th>knn4096</th>\n",
       "      <th>knn6000</th>\n",
       "      <th>nn</th>\n",
       "      <th>lgb_rank</th>\n",
       "      <th>xgb_rank</th>\n",
       "      <th>et_rank</th>\n",
       "      <th>rf_rank</th>\n",
       "      <th>nb_rank</th>\n",
       "      <th>knn_rank</th>\n",
       "      <th>nn_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.124640</td>\n",
       "      <td>0.031736</td>\n",
       "      <td>0.141378</td>\n",
       "      <td>0.462142</td>\n",
       "      <td>0.532505</td>\n",
       "      <td>0.035991</td>\n",
       "      <td>0.038355</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.117915</td>\n",
       "      <td>0.097595</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.187732</td>\n",
       "      <td>0.095804</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.029265</td>\n",
       "      <td>6.822721</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.026835</td>\n",
       "      <td>0.179971</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.288676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.093032</td>\n",
       "      <td>0.362467</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.041833</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.016327</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.131309</td>\n",
       "      <td>0.441959</td>\n",
       "      <td>0.020133</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.030273</td>\n",
       "      <td>0.033447</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>0.250004</td>\n",
       "      <td>0.250003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.046639</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.140074</td>\n",
       "      <td>0.460285</td>\n",
       "      <td>0.054885</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>0.039795</td>\n",
       "      <td>0.114667</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.500003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.138815</td>\n",
       "      <td>0.016842</td>\n",
       "      <td>0.149925</td>\n",
       "      <td>0.480155</td>\n",
       "      <td>0.170041</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.088483</td>\n",
       "      <td>0.750001</td>\n",
       "      <td>0.750001</td>\n",
       "      <td>0.750001</td>\n",
       "      <td>0.750001</td>\n",
       "      <td>0.750001</td>\n",
       "      <td>0.750001</td>\n",
       "      <td>0.750001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999042</td>\n",
       "      <td>0.998312</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>0.601022</td>\n",
       "      <td>1309.814299</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.132080</td>\n",
       "      <td>0.310500</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lgb            xgb             et             rf  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.124640       0.031736       0.141378       0.462142   \n",
       "std         0.187732       0.095804       0.014480       0.029265   \n",
       "min         0.000058       0.000011       0.093032       0.362467   \n",
       "25%         0.016327       0.001674       0.131309       0.441959   \n",
       "50%         0.046639       0.004947       0.140074       0.460285   \n",
       "75%         0.138815       0.016842       0.149925       0.480155   \n",
       "max         0.999042       0.998312       0.235257       0.601022   \n",
       "\n",
       "                  nb        knn1024        knn2048        knn4096  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.532505       0.035991       0.038355       0.041225   \n",
       "std         6.822721       0.012571       0.011733       0.011122   \n",
       "min         0.000252       0.003906       0.006836       0.011719   \n",
       "25%         0.020133       0.027344       0.030273       0.033447   \n",
       "50%         0.054885       0.034180       0.036621       0.039795   \n",
       "75%         0.170041       0.042969       0.044434       0.047363   \n",
       "max      1309.814299       0.145508       0.145508       0.132080   \n",
       "\n",
       "             knn6000             nn       lgb_rank       xgb_rank  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.117915       0.097595       0.500003       0.500003   \n",
       "std         0.026835       0.179971       0.288676       0.288676   \n",
       "min         0.041833       0.000041       0.000005       0.000005   \n",
       "25%         0.099000       0.007760       0.250004       0.250004   \n",
       "50%         0.114667       0.024959       0.500003       0.500003   \n",
       "75%         0.133000       0.088483       0.750001       0.750001   \n",
       "max         0.310500       0.999800       1.000000       1.000000   \n",
       "\n",
       "             et_rank        rf_rank        nb_rank       knn_rank  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.500002       0.500002       0.500003       0.500003   \n",
       "std         0.288676       0.288676       0.288676       0.288676   \n",
       "min         0.000005       0.000005       0.000005       0.000005   \n",
       "25%         0.250004       0.250004       0.250004       0.250004   \n",
       "50%         0.500003       0.500003       0.500003       0.500003   \n",
       "75%         0.750001       0.750001       0.750001       0.750001   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "             nn_rank  \n",
       "count  200000.000000  \n",
       "mean        0.500002  \n",
       "std         0.288676  \n",
       "min         0.000005  \n",
       "25%         0.250003  \n",
       "50%         0.500003  \n",
       "75%         0.750001  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#blend_train['knn6000']=oof\n",
    "blend_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend models by weighted ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train.to_csv('data/oof_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_train['lgb_rank']=blend_train['lgb'].rank()/200000\n",
    "blend_train['xgb_rank']=blend_train['xgb'].rank()/200000\n",
    "blend_train['et_rank']=blend_train['et'].rank()/200000\n",
    "blend_train['rf_rank']=blend_train['rf'].rank()/200000\n",
    "blend_train['nb_rank']=blend_train['nb'].rank()/200000\n",
    "blend_train['knn_rank']=blend_train['nb'].rank()/200000\n",
    "blend_train['nn_rank']=blend_train['nn'].rank()/200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test=pd.read_csv(\"data/test_pred_layer_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test.to_csv(\"data/test_pred_layer_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>xgb</th>\n",
       "      <th>et</th>\n",
       "      <th>rf</th>\n",
       "      <th>nb</th>\n",
       "      <th>knn1024</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.117297</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.141387</td>\n",
       "      <td>0.462227</td>\n",
       "      <td>0.371291</td>\n",
       "      <td>0.179273</td>\n",
       "      <td>0.089385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.168099</td>\n",
       "      <td>0.092649</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.027314</td>\n",
       "      <td>4.218662</td>\n",
       "      <td>0.057996</td>\n",
       "      <td>0.158665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.092282</td>\n",
       "      <td>0.351221</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.017927</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.132016</td>\n",
       "      <td>0.443465</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.137695</td>\n",
       "      <td>0.008643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.049635</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.140487</td>\n",
       "      <td>0.461118</td>\n",
       "      <td>0.058387</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.026801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.138098</td>\n",
       "      <td>0.020196</td>\n",
       "      <td>0.149694</td>\n",
       "      <td>0.479714</td>\n",
       "      <td>0.168124</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.087415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998715</td>\n",
       "      <td>1.197919</td>\n",
       "      <td>0.221672</td>\n",
       "      <td>0.598871</td>\n",
       "      <td>853.745483</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>0.999634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 lgb            xgb             et             rf  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.117297       0.031305       0.141387       0.462227   \n",
       "std         0.168099       0.092649       0.013492       0.027314   \n",
       "min         0.000091       0.000017       0.092282       0.351221   \n",
       "25%         0.017927       0.002217       0.132016       0.443465   \n",
       "50%         0.049635       0.006380       0.140487       0.461118   \n",
       "75%         0.138098       0.020196       0.149694       0.479714   \n",
       "max         0.998715       1.197919       0.221672       0.598871   \n",
       "\n",
       "                  nb        knn1024             nn  \n",
       "count  200000.000000  200000.000000  200000.000000  \n",
       "mean        0.371291       0.179273       0.089385  \n",
       "std         4.218662       0.057996       0.158665  \n",
       "min         0.000192       0.026367       0.000045  \n",
       "25%         0.021935       0.137695       0.008643  \n",
       "50%         0.058387       0.171875       0.026801  \n",
       "75%         0.168124       0.210938       0.087415  \n",
       "max       853.745483       0.768555       0.999634  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_test['lgb_rank']=blend_test['lgb'].rank()/200000\n",
    "blend_test['xgb_rank']=blend_test['xgb'].rank()/200000\n",
    "blend_test['et_rank']=blend_test['et'].rank()/200000\n",
    "blend_test['rf_rank']=blend_test['rf'].rank()/200000\n",
    "blend_test['nb_rank']=blend_test['nb'].rank()/200000\n",
    "#blend_test['knn_rank']=blend_test['knn'].rank()/200000\n",
    "blend_test['nn_rank']=blend_test['nn'].rank()/200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('test/901.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['rank']=df1['target'].rank()/200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.142333</td>\n",
       "      <td>0.756220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.274733</td>\n",
       "      <td>0.877320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.241985</td>\n",
       "      <td>0.857165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.291388</td>\n",
       "      <td>0.886205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.058313</td>\n",
       "      <td>0.540390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target      rank\n",
       "0  test_0  0.142333  0.756220\n",
       "1  test_1  0.274733  0.877320\n",
       "2  test_2  0.241985  0.857165\n",
       "3  test_3  0.291388  0.886205\n",
       "4  test_4  0.058313  0.540390"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.DataFrame()\n",
    "submission['ID_code']=df['ID_code']\n",
    "submission['target']=df1['rank']*10+blend_test['nb_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission/ensemble_aver3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb_rank</th>\n",
       "      <th>xgb_rank</th>\n",
       "      <th>et_rank</th>\n",
       "      <th>rf_rank</th>\n",
       "      <th>nb_rank</th>\n",
       "      <th>nn_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.172765</td>\n",
       "      <td>0.16339</td>\n",
       "      <td>0.224845</td>\n",
       "      <td>0.262845</td>\n",
       "      <td>0.240780</td>\n",
       "      <td>0.197350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.932675</td>\n",
       "      <td>0.91672</td>\n",
       "      <td>0.960690</td>\n",
       "      <td>0.943895</td>\n",
       "      <td>0.929245</td>\n",
       "      <td>0.958160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.07826</td>\n",
       "      <td>0.292580</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>0.115795</td>\n",
       "      <td>0.137145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893975</td>\n",
       "      <td>0.90369</td>\n",
       "      <td>0.891025</td>\n",
       "      <td>0.843835</td>\n",
       "      <td>0.899970</td>\n",
       "      <td>0.878670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.743020</td>\n",
       "      <td>0.82797</td>\n",
       "      <td>0.720895</td>\n",
       "      <td>0.730730</td>\n",
       "      <td>0.748295</td>\n",
       "      <td>0.713790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lgb_rank  xgb_rank   et_rank   rf_rank   nb_rank   nn_rank\n",
       "0  0.172765   0.16339  0.224845  0.262845  0.240780  0.197350\n",
       "1  0.932675   0.91672  0.960690  0.943895  0.929245  0.958160\n",
       "2  0.105860   0.07826  0.292580  0.079755  0.115795  0.137145\n",
       "3  0.893975   0.90369  0.891025  0.843835  0.899970  0.878670\n",
       "4  0.743020   0.82797  0.720895  0.730730  0.748295  0.713790"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_train=blend_train[['lgb_rank','xgb_rank','et_rank','rf_rank','nb_rank','nn_rank']]\n",
    "lgb_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blend_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-7f217c642e19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblend_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lgb_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblend_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xgb_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblend_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'et_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblend_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rf_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mblend_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nb_rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'blend_train' is not defined"
     ]
    }
   ],
   "source": [
    "print (roc_auc_score(y,blend_train['lgb_rank']))\n",
    "print (roc_auc_score(y,blend_train['xgb_rank']))\n",
    "print (roc_auc_score(y,blend_train['et_rank']))\n",
    "print (roc_auc_score(y,blend_train['rf_rank']))\n",
    "print (roc_auc_score(y,blend_train['nb_rank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param = {\n",
    "    # This one seems to be better than the lower one\n",
    "    'bagging_freq': 5,\n",
    "        'bagging_fraction': 0.335, \n",
    "        'boost_from_average':'false',\n",
    "        'boost': 'gbdt',\n",
    "        'feature_fraction': 0.041,\n",
    "        'learning_rate': 0.0083,#0.0083\n",
    "        'max_depth': -1,  \n",
    "        'metric':'auc',\n",
    "        'min_data_in_leaf': 80,\n",
    "        'min_sum_hessian_in_leaf': 10.0,\n",
    "        'num_leaves': 13, \n",
    "        #'num_threads': 8,\n",
    "        'tree_learner': 'serial',\n",
    "        'objective': 'binary', \n",
    "        'verbosity': 1,\n",
    "        \"boost_from_average\": \"false\",\n",
    "        #'is_unbalance':True #new\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:100000]\n",
    "y=y[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5 # Number of K-fold Splits\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True,random_state=1111).split(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "best5 = 0\n",
    "\n",
    "def hyperopt_train_test5(params):\n",
    "    global X\n",
    "    global y\n",
    "    global splits\n",
    "    oof=np.zeros(len(X))\n",
    "    for i, (train_idx, valid_idx) in enumerate(splits):  \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        x_train = X[train_idx.astype(int)]\n",
    "        y_train = y[train_idx.astype(int)]\n",
    "        X_t, y_t = shuffle(x_train, y_train)\n",
    "        X_t = pd.DataFrame(X_t)\n",
    "        X_t = X_t.add_prefix('var_')\n",
    "        X_t=np.array(X_t)\n",
    "        y_t=np.array(y_t)\n",
    "\n",
    "        trn_data = lgb.Dataset(X_t, label=y_t)\n",
    "        val_data = lgb.Dataset(X[valid_idx.astype(int)], label=y[valid_idx.astype(int)])\n",
    "        watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "        lgb_clf = lgb.train(params, trn_data, 500000, valid_sets = [trn_data, val_data], early_stopping_rounds=3000, verbose_eval=1000)\n",
    "        oof[valid_idx] = lgb_clf.predict(X[valid_idx], num_iteration=lgb_clf.best_iteration)\n",
    "    \n",
    "    return roc_auc_score(y, oof)\n",
    "\n",
    "def loss5(params):\n",
    "    global best5\n",
    "    roc = hyperopt_train_test5(params)\n",
    "    if roc > best5:\n",
    "        best5 = roc\n",
    "        print ('new best:', best5, params)\n",
    "    return {'loss': -roc, 'status': STATUS_OK}\n",
    "\n",
    "trials5 = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "space4lgb = {\n",
    "    'bagging_freq': hp.choice('bagging_freq', [2,3,4,5,6,7]),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.1, 0.5),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.1, 0.4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.002, 0.015),\n",
    "    'max_depth': hp.choice('max_depth', [-1,2,4,6,8]),\n",
    "    'metric': hp.choice('metric', ['auc']),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf', [50,55,60,65,75,80,85,90]),\n",
    "    'min_sum_hessian_in_leaf': hp.choice('min_sum_hessian_in_leaf', [5,7,9,11,13,15]),\n",
    "    'num_leaves': hp.choice('num_leaves',[7,9,11,13,15,17]),\n",
    "    'tree_learner': hp.choice('tree_learner',['serial']),\n",
    "    'objective': hp.choice('objective',['binary']),\n",
    "    'is_unbalance':hp.choice('is_unbalance', [True, False]),\n",
    "    'boost_from_average':hp.choice(\"boost_from_average\", [True, False]),\n",
    "    'boost': hp.choice('boost',['gbdt'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.868777\tvalid_1's auc: 0.85187                                                                 \n",
      "[2000]\ttraining's auc: 0.89569\tvalid_1's auc: 0.87515                                                                  \n",
      "[3000]\ttraining's auc: 0.90895\tvalid_1's auc: 0.885319                                                                 \n",
      "[4000]\ttraining's auc: 0.917059\tvalid_1's auc: 0.891039                                                                \n",
      "[5000]\ttraining's auc: 0.922734\tvalid_1's auc: 0.894179                                                                \n",
      "[6000]\ttraining's auc: 0.927157\tvalid_1's auc: 0.895705                                                                \n",
      "[7000]\ttraining's auc: 0.931077\tvalid_1's auc: 0.89686                                                                 \n",
      "[8000]\ttraining's auc: 0.934667\tvalid_1's auc: 0.89723                                                                 \n",
      "[9000]\ttraining's auc: 0.938\tvalid_1's auc: 0.8974                                                                     \n",
      "[10000]\ttraining's auc: 0.941216\tvalid_1's auc: 0.897379                                                               \n",
      "[11000]\ttraining's auc: 0.944387\tvalid_1's auc: 0.897276                                                               \n",
      "[12000]\ttraining's auc: 0.947445\tvalid_1's auc: 0.896945                                                               \n",
      "[13000]\ttraining's auc: 0.950362\tvalid_1's auc: 0.896856                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10256]\ttraining's auc: 0.942045\tvalid_1's auc: 0.897459\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.871013\tvalid_1's auc: 0.844897                                                                \n",
      "[2000]\ttraining's auc: 0.899081\tvalid_1's auc: 0.868842                                                                \n",
      "[3000]\ttraining's auc: 0.912244\tvalid_1's auc: 0.879082                                                                \n",
      "[4000]\ttraining's auc: 0.920337\tvalid_1's auc: 0.884583                                                                \n",
      "[5000]\ttraining's auc: 0.926045\tvalid_1's auc: 0.887392                                                                \n",
      "[6000]\ttraining's auc: 0.930363\tvalid_1's auc: 0.888847                                                                \n",
      "[7000]\ttraining's auc: 0.933973\tvalid_1's auc: 0.889521                                                                \n",
      "[8000]\ttraining's auc: 0.937434\tvalid_1's auc: 0.889967                                                                \n",
      "[9000]\ttraining's auc: 0.940639\tvalid_1's auc: 0.889904                                                                \n",
      "[10000]\ttraining's auc: 0.943765\tvalid_1's auc: 0.889852                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7958]\ttraining's auc: 0.937295\tvalid_1's auc: 0.889987\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.869044\tvalid_1's auc: 0.848731                                                                \n",
      "[2000]\ttraining's auc: 0.897191\tvalid_1's auc: 0.873999                                                                \n",
      "[3000]\ttraining's auc: 0.910354\tvalid_1's auc: 0.884365                                                                \n",
      "[4000]\ttraining's auc: 0.918174\tvalid_1's auc: 0.889921                                                                \n",
      "[5000]\ttraining's auc: 0.923555\tvalid_1's auc: 0.893154                                                                \n",
      "[6000]\ttraining's auc: 0.92784\tvalid_1's auc: 0.894933                                                                 \n",
      "[7000]\ttraining's auc: 0.931626\tvalid_1's auc: 0.895969                                                                \n",
      "[8000]\ttraining's auc: 0.93512\tvalid_1's auc: 0.896838                                                                 \n",
      "[9000]\ttraining's auc: 0.938488\tvalid_1's auc: 0.897032                                                                \n",
      "[10000]\ttraining's auc: 0.941714\tvalid_1's auc: 0.897165                                                               \n",
      "[11000]\ttraining's auc: 0.944823\tvalid_1's auc: 0.89711                                                                \n",
      "[12000]\ttraining's auc: 0.94775\tvalid_1's auc: 0.897046                                                                \n",
      "[13000]\ttraining's auc: 0.950657\tvalid_1's auc: 0.896909                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10204]\ttraining's auc: 0.942376\tvalid_1's auc: 0.897247\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.87103\tvalid_1's auc: 0.849801                                                                 \n",
      "[2000]\ttraining's auc: 0.89754\tvalid_1's auc: 0.872191                                                                 \n",
      "[3000]\ttraining's auc: 0.910732\tvalid_1's auc: 0.882387                                                                \n",
      "[4000]\ttraining's auc: 0.918889\tvalid_1's auc: 0.88787                                                                 \n",
      "[5000]\ttraining's auc: 0.924603\tvalid_1's auc: 0.890913                                                                \n",
      "[6000]\ttraining's auc: 0.928979\tvalid_1's auc: 0.892328                                                                \n",
      "[7000]\ttraining's auc: 0.932776\tvalid_1's auc: 0.893359                                                                \n",
      "[8000]\ttraining's auc: 0.936224\tvalid_1's auc: 0.894124                                                                \n",
      "[9000]\ttraining's auc: 0.939553\tvalid_1's auc: 0.894643                                                                \n",
      "[10000]\ttraining's auc: 0.942711\tvalid_1's auc: 0.894801                                                               \n",
      "[11000]\ttraining's auc: 0.945696\tvalid_1's auc: 0.894784                                                               \n",
      "[12000]\ttraining's auc: 0.948621\tvalid_1's auc: 0.894671                                                               \n",
      "[13000]\ttraining's auc: 0.951447\tvalid_1's auc: 0.894675                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10104]\ttraining's auc: 0.943052\tvalid_1's auc: 0.894869\n",
      "new best:                                                                                                              \n",
      "0.8949243079870943                                                                                                     \n",
      "{'bagging_fraction': 0.2870728140526571, 'bagging_freq': 4, 'boost': 'gbdt', 'boost_from_average': True, 'feature_fraction': 0.3990309430366299, 'is_unbalance': True, 'learning_rate': 0.008165859861510598, 'max_depth': -1, 'metric': 'auc', 'min_data_in_leaf': 80, 'min_sum_hessian_in_leaf': 11, 'num_leaves': 7, 'objective': 'binary', 'tree_learner': 'serial'}\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.868504\tvalid_1's auc: 0.845252                                                                \n",
      "[2000]\ttraining's auc: 0.89365\tvalid_1's auc: 0.866409                                                                 \n",
      "[3000]\ttraining's auc: 0.910064\tvalid_1's auc: 0.8789                                                                  \n",
      "[4000]\ttraining's auc: 0.920435\tvalid_1's auc: 0.886096                                                                \n",
      "[5000]\ttraining's auc: 0.927705\tvalid_1's auc: 0.890479                                                                \n",
      "[6000]\ttraining's auc: 0.933229\tvalid_1's auc: 0.893278                                                                \n",
      "[7000]\ttraining's auc: 0.937578\tvalid_1's auc: 0.894922                                                                \n",
      "[8000]\ttraining's auc: 0.941227\tvalid_1's auc: 0.896244                                                                \n",
      "[9000]\ttraining's auc: 0.94445\tvalid_1's auc: 0.89711                                                                  \n",
      "[10000]\ttraining's auc: 0.947371\tvalid_1's auc: 0.897531                                                               \n",
      "[11000]\ttraining's auc: 0.950012\tvalid_1's auc: 0.897785                                                               \n",
      "[12000]\ttraining's auc: 0.95245\tvalid_1's auc: 0.897856                                                                \n",
      "[13000]\ttraining's auc: 0.954735\tvalid_1's auc: 0.897835                                                               \n",
      "[14000]\ttraining's auc: 0.956929\tvalid_1's auc: 0.89778                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11798]\ttraining's auc: 0.951974\tvalid_1's auc: 0.897918\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.871341\tvalid_1's auc: 0.838728                                                                \n",
      "[2000]\ttraining's auc: 0.897169\tvalid_1's auc: 0.8596                                                                  \n",
      "[3000]\ttraining's auc: 0.912971\tvalid_1's auc: 0.871245                                                                \n",
      "[4000]\ttraining's auc: 0.923243\tvalid_1's auc: 0.878395                                                                \n",
      "[5000]\ttraining's auc: 0.930604\tvalid_1's auc: 0.883158                                                                \n",
      "[6000]\ttraining's auc: 0.936063\tvalid_1's auc: 0.886258                                                                \n",
      "[7000]\ttraining's auc: 0.940335\tvalid_1's auc: 0.888078                                                                \n",
      "[8000]\ttraining's auc: 0.94386\tvalid_1's auc: 0.889459                                                                 \n",
      "[9000]\ttraining's auc: 0.947023\tvalid_1's auc: 0.890255                                                                \n",
      "[10000]\ttraining's auc: 0.949795\tvalid_1's auc: 0.890723                                                               \n",
      "[11000]\ttraining's auc: 0.952343\tvalid_1's auc: 0.891111                                                               \n",
      "[12000]\ttraining's auc: 0.954726\tvalid_1's auc: 0.891306                                                               \n",
      "[13000]\ttraining's auc: 0.956925\tvalid_1's auc: 0.891217                                                               \n",
      "[14000]\ttraining's auc: 0.958982\tvalid_1's auc: 0.891212                                                               \n",
      "[15000]\ttraining's auc: 0.961029\tvalid_1's auc: 0.891003                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12091]\ttraining's auc: 0.954929\tvalid_1's auc: 0.891355\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.869874\tvalid_1's auc: 0.845678                                                                \n",
      "[2000]\ttraining's auc: 0.895972\tvalid_1's auc: 0.865525                                                                \n",
      "[3000]\ttraining's auc: 0.911628\tvalid_1's auc: 0.87772                                                                 \n",
      "[4000]\ttraining's auc: 0.921792\tvalid_1's auc: 0.884872                                                                \n",
      "[5000]\ttraining's auc: 0.928887\tvalid_1's auc: 0.889372                                                                \n",
      "[6000]\ttraining's auc: 0.93431\tvalid_1's auc: 0.892282                                                                 \n",
      "[7000]\ttraining's auc: 0.938592\tvalid_1's auc: 0.894229                                                                \n",
      "[8000]\ttraining's auc: 0.942229\tvalid_1's auc: 0.895631                                                                \n",
      "[9000]\ttraining's auc: 0.945401\tvalid_1's auc: 0.896662                                                                \n",
      "[10000]\ttraining's auc: 0.948245\tvalid_1's auc: 0.897446                                                               \n",
      "[11000]\ttraining's auc: 0.950794\tvalid_1's auc: 0.897837                                                               \n",
      "[12000]\ttraining's auc: 0.953208\tvalid_1's auc: 0.89827                                                                \n",
      "[13000]\ttraining's auc: 0.95546\tvalid_1's auc: 0.898546                                                                \n",
      "[14000]\ttraining's auc: 0.957578\tvalid_1's auc: 0.898521                                                               \n",
      "[15000]\ttraining's auc: 0.95967\tvalid_1's auc: 0.898606                                                                \n",
      "[16000]\ttraining's auc: 0.961678\tvalid_1's auc: 0.898672                                                               \n",
      "[17000]\ttraining's auc: 0.963632\tvalid_1's auc: 0.898741                                                               \n",
      "[18000]\ttraining's auc: 0.965487\tvalid_1's auc: 0.898759                                                               \n",
      "[19000]\ttraining's auc: 0.967354\tvalid_1's auc: 0.898605                                                               \n",
      "[20000]\ttraining's auc: 0.96916\tvalid_1's auc: 0.898482                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17672]\ttraining's auc: 0.964902\tvalid_1's auc: 0.898865\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.870728\tvalid_1's auc: 0.843173                                                                \n",
      "[2000]\ttraining's auc: 0.896454\tvalid_1's auc: 0.863637                                                                \n",
      "[3000]\ttraining's auc: 0.912277\tvalid_1's auc: 0.875737                                                                \n",
      "[4000]\ttraining's auc: 0.92251\tvalid_1's auc: 0.882665                                                                 \n",
      "[5000]\ttraining's auc: 0.929734\tvalid_1's auc: 0.887036                                                                \n",
      "[6000]\ttraining's auc: 0.935234\tvalid_1's auc: 0.889857                                                                \n",
      "[7000]\ttraining's auc: 0.939569\tvalid_1's auc: 0.891872                                                                \n",
      "[8000]\ttraining's auc: 0.943152\tvalid_1's auc: 0.893202                                                                \n",
      "[9000]\ttraining's auc: 0.946348\tvalid_1's auc: 0.89406                                                                 \n",
      "[10000]\ttraining's auc: 0.949248\tvalid_1's auc: 0.894652                                                               \n",
      "[11000]\ttraining's auc: 0.951879\tvalid_1's auc: 0.89502                                                                \n",
      "[12000]\ttraining's auc: 0.954232\tvalid_1's auc: 0.895289                                                               \n",
      "[13000]\ttraining's auc: 0.956424\tvalid_1's auc: 0.895458                                                               \n",
      "[14000]\ttraining's auc: 0.958535\tvalid_1's auc: 0.895547                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000]\ttraining's auc: 0.96061\tvalid_1's auc: 0.895665                                                                \n",
      "[16000]\ttraining's auc: 0.96256\tvalid_1's auc: 0.895728                                                                \n",
      "[17000]\ttraining's auc: 0.964501\tvalid_1's auc: 0.895654                                                               \n",
      "[18000]\ttraining's auc: 0.966324\tvalid_1's auc: 0.895624                                                               \n",
      "[19000]\ttraining's auc: 0.968022\tvalid_1's auc: 0.895585                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16254]\ttraining's auc: 0.963064\tvalid_1's auc: 0.89575\n",
      "new best:                                                                                                              \n",
      "0.8958419247275111                                                                                                     \n",
      "{'bagging_fraction': 0.29090726146946644, 'bagging_freq': 7, 'boost': 'gbdt', 'boost_from_average': False, 'feature_fraction': 0.1248310490574328, 'is_unbalance': False, 'learning_rate': 0.005699676913345863, 'max_depth': 4, 'metric': 'auc', 'min_data_in_leaf': 75, 'min_sum_hessian_in_leaf': 13, 'num_leaves': 17, 'objective': 'binary', 'tree_learner': 'serial'}\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.872636\tvalid_1's auc: 0.860871                                                                \n",
      "[2000]\ttraining's auc: 0.898502\tvalid_1's auc: 0.882841                                                                \n",
      "[3000]\ttraining's auc: 0.910216\tvalid_1's auc: 0.891962                                                                \n",
      "[4000]\ttraining's auc: 0.91714\tvalid_1's auc: 0.896037                                                                 \n",
      "[5000]\ttraining's auc: 0.921931\tvalid_1's auc: 0.897506                                                                \n",
      "[6000]\ttraining's auc: 0.92581\tvalid_1's auc: 0.898405                                                                 \n",
      "[7000]\ttraining's auc: 0.929269\tvalid_1's auc: 0.898708                                                                \n",
      "[8000]\ttraining's auc: 0.932557\tvalid_1's auc: 0.898889                                                                \n",
      "[9000]\ttraining's auc: 0.935839\tvalid_1's auc: 0.898699                                                                \n",
      "[10000]\ttraining's auc: 0.938808\tvalid_1's auc: 0.898259                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7580]\ttraining's auc: 0.931198\tvalid_1's auc: 0.899064\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.875993\tvalid_1's auc: 0.853094                                                                \n",
      "[2000]\ttraining's auc: 0.901702\tvalid_1's auc: 0.875793                                                                \n",
      "[3000]\ttraining's auc: 0.91359\tvalid_1's auc: 0.884672                                                                 \n",
      "[4000]\ttraining's auc: 0.920616\tvalid_1's auc: 0.888857                                                                \n",
      "[5000]\ttraining's auc: 0.92527\tvalid_1's auc: 0.890518                                                                 \n",
      "[6000]\ttraining's auc: 0.929057\tvalid_1's auc: 0.891246                                                                \n",
      "[7000]\ttraining's auc: 0.932309\tvalid_1's auc: 0.891457                                                                \n",
      "[8000]\ttraining's auc: 0.935365\tvalid_1's auc: 0.891183                                                                \n",
      "[9000]\ttraining's auc: 0.938366\tvalid_1's auc: 0.891344                                                                \n",
      "[10000]\ttraining's auc: 0.941308\tvalid_1's auc: 0.890992                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7010]\ttraining's auc: 0.932338\tvalid_1's auc: 0.891461\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.874229\tvalid_1's auc: 0.859303                                                                \n",
      "[2000]\ttraining's auc: 0.899363\tvalid_1's auc: 0.88132                                                                 \n",
      "[3000]\ttraining's auc: 0.911011\tvalid_1's auc: 0.890458                                                                \n",
      "[4000]\ttraining's auc: 0.917666\tvalid_1's auc: 0.894867                                                                \n",
      "[5000]\ttraining's auc: 0.922625\tvalid_1's auc: 0.897528                                                                \n",
      "[6000]\ttraining's auc: 0.926405\tvalid_1's auc: 0.89873                                                                 \n",
      "[7000]\ttraining's auc: 0.929857\tvalid_1's auc: 0.898894                                                                \n",
      "[8000]\ttraining's auc: 0.933163\tvalid_1's auc: 0.899212                                                                \n",
      "[9000]\ttraining's auc: 0.9363\tvalid_1's auc: 0.89948                                                                   \n",
      "[10000]\ttraining's auc: 0.939265\tvalid_1's auc: 0.899075                                                               \n",
      "[11000]\ttraining's auc: 0.942193\tvalid_1's auc: 0.899104                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8902]\ttraining's auc: 0.935989\tvalid_1's auc: 0.899535\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.875075\tvalid_1's auc: 0.858515                                                                \n",
      "[2000]\ttraining's auc: 0.900324\tvalid_1's auc: 0.879622                                                                \n",
      "[3000]\ttraining's auc: 0.912094\tvalid_1's auc: 0.888673                                                                \n",
      "[4000]\ttraining's auc: 0.919336\tvalid_1's auc: 0.892602                                                                \n",
      "[5000]\ttraining's auc: 0.924302\tvalid_1's auc: 0.894558                                                                \n",
      "[6000]\ttraining's auc: 0.928169\tvalid_1's auc: 0.895293                                                                \n",
      "[7000]\ttraining's auc: 0.931524\tvalid_1's auc: 0.895998                                                                \n",
      "[8000]\ttraining's auc: 0.934615\tvalid_1's auc: 0.895914                                                                \n",
      "[9000]\ttraining's auc: 0.937681\tvalid_1's auc: 0.895707                                                                \n",
      "[10000]\ttraining's auc: 0.940471\tvalid_1's auc: 0.895452                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7146]\ttraining's auc: 0.93202\tvalid_1's auc: 0.896069\n",
      "new best:                                                                                                              \n",
      "0.8965706077767274                                                                                                     \n",
      "{'bagging_fraction': 0.13740722607375322, 'bagging_freq': 5, 'boost': 'gbdt', 'boost_from_average': False, 'feature_fraction': 0.2407724210954242, 'is_unbalance': False, 'learning_rate': 0.009545206873889184, 'max_depth': 6, 'metric': 'auc', 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 15, 'num_leaves': 7, 'objective': 'binary', 'tree_learner': 'serial'}\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.872503\tvalid_1's auc: 0.857669                                                                \n",
      "[2000]\ttraining's auc: 0.891165\tvalid_1's auc: 0.872751                                                                \n",
      "[3000]\ttraining's auc: 0.903372\tvalid_1's auc: 0.882188                                                                \n",
      "[4000]\ttraining's auc: 0.911747\tvalid_1's auc: 0.888079                                                                \n",
      "[5000]\ttraining's auc: 0.917787\tvalid_1's auc: 0.892014                                                                \n",
      "[6000]\ttraining's auc: 0.922452\tvalid_1's auc: 0.894421                                                                \n",
      "[7000]\ttraining's auc: 0.926226\tvalid_1's auc: 0.895808                                                                \n",
      "[8000]\ttraining's auc: 0.929536\tvalid_1's auc: 0.896991                                                                \n",
      "[9000]\ttraining's auc: 0.932487\tvalid_1's auc: 0.897675                                                                \n",
      "[10000]\ttraining's auc: 0.935295\tvalid_1's auc: 0.898136                                                               \n",
      "[11000]\ttraining's auc: 0.937929\tvalid_1's auc: 0.898394                                                               \n",
      "[12000]\ttraining's auc: 0.940464\tvalid_1's auc: 0.898511                                                               \n",
      "[13000]\ttraining's auc: 0.942933\tvalid_1's auc: 0.898579                                                               \n",
      "[14000]\ttraining's auc: 0.945293\tvalid_1's auc: 0.898628                                                               \n",
      "[15000]\ttraining's auc: 0.947565\tvalid_1's auc: 0.898561                                                               \n",
      "[16000]\ttraining's auc: 0.949766\tvalid_1's auc: 0.898358                                                               \n",
      "[17000]\ttraining's auc: 0.951862\tvalid_1's auc: 0.89825                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14116]\ttraining's auc: 0.945564\tvalid_1's auc: 0.898645\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.875611\tvalid_1's auc: 0.851242                                                                \n",
      "[2000]\ttraining's auc: 0.894175\tvalid_1's auc: 0.865677                                                                \n",
      "[3000]\ttraining's auc: 0.906444\tvalid_1's auc: 0.875333                                                                \n",
      "[4000]\ttraining's auc: 0.914811\tvalid_1's auc: 0.881385                                                                \n",
      "[5000]\ttraining's auc: 0.920909\tvalid_1's auc: 0.884861                                                                \n",
      "[6000]\ttraining's auc: 0.925501\tvalid_1's auc: 0.887091                                                                \n",
      "[7000]\ttraining's auc: 0.929262\tvalid_1's auc: 0.888788                                                                \n",
      "[8000]\ttraining's auc: 0.932369\tvalid_1's auc: 0.889716                                                                \n",
      "[9000]\ttraining's auc: 0.935292\tvalid_1's auc: 0.890433                                                                \n",
      "[10000]\ttraining's auc: 0.93804\tvalid_1's auc: 0.890849                                                                \n",
      "[11000]\ttraining's auc: 0.940611\tvalid_1's auc: 0.890942                                                               \n",
      "[12000]\ttraining's auc: 0.943044\tvalid_1's auc: 0.890901                                                               \n",
      "[13000]\ttraining's auc: 0.945382\tvalid_1's auc: 0.890846                                                               \n",
      "[14000]\ttraining's auc: 0.947612\tvalid_1's auc: 0.890876                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11779]\ttraining's auc: 0.942539\tvalid_1's auc: 0.890986\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.873197\tvalid_1's auc: 0.85585                                                                 \n",
      "[2000]\ttraining's auc: 0.89207\tvalid_1's auc: 0.870719                                                                 \n",
      "[3000]\ttraining's auc: 0.904456\tvalid_1's auc: 0.880772                                                                \n",
      "[4000]\ttraining's auc: 0.912782\tvalid_1's auc: 0.887075                                                                \n",
      "[5000]\ttraining's auc: 0.918857\tvalid_1's auc: 0.891                                                                   \n",
      "[6000]\ttraining's auc: 0.923426\tvalid_1's auc: 0.893623                                                                \n",
      "[7000]\ttraining's auc: 0.927184\tvalid_1's auc: 0.895527                                                                \n",
      "[8000]\ttraining's auc: 0.930416\tvalid_1's auc: 0.896785                                                                \n",
      "[9000]\ttraining's auc: 0.933342\tvalid_1's auc: 0.897594                                                                \n",
      "[10000]\ttraining's auc: 0.936094\tvalid_1's auc: 0.898143                                                               \n",
      "[11000]\ttraining's auc: 0.938681\tvalid_1's auc: 0.898449                                                               \n",
      "[12000]\ttraining's auc: 0.94121\tvalid_1's auc: 0.898639                                                                \n",
      "[13000]\ttraining's auc: 0.943617\tvalid_1's auc: 0.898886                                                               \n",
      "[14000]\ttraining's auc: 0.945929\tvalid_1's auc: 0.899178                                                               \n",
      "[15000]\ttraining's auc: 0.948152\tvalid_1's auc: 0.899255                                                               \n",
      "[16000]\ttraining's auc: 0.950353\tvalid_1's auc: 0.899339                                                               \n",
      "[17000]\ttraining's auc: 0.952424\tvalid_1's auc: 0.899413                                                               \n",
      "[18000]\ttraining's auc: 0.954459\tvalid_1's auc: 0.89933                                                                \n",
      "[19000]\ttraining's auc: 0.956414\tvalid_1's auc: 0.89931                                                                \n",
      "[20000]\ttraining's auc: 0.958335\tvalid_1's auc: 0.899277                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17084]\ttraining's auc: 0.952601\tvalid_1's auc: 0.899433\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.874084\tvalid_1's auc: 0.854779                                                                \n",
      "[2000]\ttraining's auc: 0.892943\tvalid_1's auc: 0.870176                                                                \n",
      "[3000]\ttraining's auc: 0.90506\tvalid_1's auc: 0.879565                                                                 \n",
      "[4000]\ttraining's auc: 0.913534\tvalid_1's auc: 0.885301                                                                \n",
      "[5000]\ttraining's auc: 0.919748\tvalid_1's auc: 0.888959                                                                \n",
      "[6000]\ttraining's auc: 0.924437\tvalid_1's auc: 0.891447                                                                \n",
      "[7000]\ttraining's auc: 0.928299\tvalid_1's auc: 0.892962                                                                \n",
      "[8000]\ttraining's auc: 0.931592\tvalid_1's auc: 0.893922                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9000]\ttraining's auc: 0.934604\tvalid_1's auc: 0.894555                                                                \n",
      "[10000]\ttraining's auc: 0.937376\tvalid_1's auc: 0.895189                                                               \n",
      "[11000]\ttraining's auc: 0.939907\tvalid_1's auc: 0.895551                                                               \n",
      "[12000]\ttraining's auc: 0.94239\tvalid_1's auc: 0.895738                                                                \n",
      "[13000]\ttraining's auc: 0.944733\tvalid_1's auc: 0.895863                                                               \n",
      "[14000]\ttraining's auc: 0.947057\tvalid_1's auc: 0.89595                                                                \n",
      "[15000]\ttraining's auc: 0.949243\tvalid_1's auc: 0.895945                                                               \n",
      "[16000]\ttraining's auc: 0.951336\tvalid_1's auc: 0.895956                                                               \n",
      "[17000]\ttraining's auc: 0.953352\tvalid_1's auc: 0.89604                                                                \n",
      "[18000]\ttraining's auc: 0.955327\tvalid_1's auc: 0.895859                                                               \n",
      "[19000]\ttraining's auc: 0.957244\tvalid_1's auc: 0.895856                                                               \n",
      "[20000]\ttraining's auc: 0.959123\tvalid_1's auc: 0.895841                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17098]\ttraining's auc: 0.953544\tvalid_1's auc: 0.896074\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.892896\tvalid_1's auc: 0.877262                                                                \n",
      "[2000]\ttraining's auc: 0.911654\tvalid_1's auc: 0.891036                                                                \n",
      "[3000]\ttraining's auc: 0.920923\tvalid_1's auc: 0.895349                                                                \n",
      "[4000]\ttraining's auc: 0.927712\tvalid_1's auc: 0.896149                                                                \n",
      "[5000]\ttraining's auc: 0.933551\tvalid_1's auc: 0.896364                                                                \n",
      "[6000]\ttraining's auc: 0.938868\tvalid_1's auc: 0.895966                                                                \n",
      "[7000]\ttraining's auc: 0.943671\tvalid_1's auc: 0.895561                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4901]\ttraining's auc: 0.932983\tvalid_1's auc: 0.896457\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.895557\tvalid_1's auc: 0.870217                                                                \n",
      "[2000]\ttraining's auc: 0.915444\tvalid_1's auc: 0.884213                                                                \n",
      "[3000]\ttraining's auc: 0.924525\tvalid_1's auc: 0.887614                                                                \n",
      "[4000]\ttraining's auc: 0.93094\tvalid_1's auc: 0.889071                                                                 \n",
      "[5000]\ttraining's auc: 0.936366\tvalid_1's auc: 0.888561                                                                \n",
      "[6000]\ttraining's auc: 0.941377\tvalid_1's auc: 0.888362                                                                \n",
      "[7000]\ttraining's auc: 0.946092\tvalid_1's auc: 0.887781                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4342]\ttraining's auc: 0.932889\tvalid_1's auc: 0.889197\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.893189\tvalid_1's auc: 0.875432                                                                \n",
      "[2000]\ttraining's auc: 0.912584\tvalid_1's auc: 0.890236                                                                \n",
      "[3000]\ttraining's auc: 0.921678\tvalid_1's auc: 0.895133                                                                \n",
      "[4000]\ttraining's auc: 0.928061\tvalid_1's auc: 0.896582                                                                \n",
      "[5000]\ttraining's auc: 0.933654\tvalid_1's auc: 0.897181                                                                \n",
      "[6000]\ttraining's auc: 0.938919\tvalid_1's auc: 0.896887                                                                \n",
      "[7000]\ttraining's auc: 0.943714\tvalid_1's auc: 0.896378                                                                \n",
      "[8000]\ttraining's auc: 0.948139\tvalid_1's auc: 0.895782                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5424]\ttraining's auc: 0.935827\tvalid_1's auc: 0.897267\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.894198\tvalid_1's auc: 0.873231                                                                \n",
      "[2000]\ttraining's auc: 0.913468\tvalid_1's auc: 0.887621                                                                \n",
      "[3000]\ttraining's auc: 0.923138\tvalid_1's auc: 0.892512                                                                \n",
      "[4000]\ttraining's auc: 0.929706\tvalid_1's auc: 0.893903                                                                \n",
      "[5000]\ttraining's auc: 0.935188\tvalid_1's auc: 0.894013                                                                \n",
      "[6000]\ttraining's auc: 0.940274\tvalid_1's auc: 0.89369                                                                 \n",
      "[7000]\ttraining's auc: 0.945003\tvalid_1's auc: 0.893771                                                                \n",
      "[8000]\ttraining's auc: 0.949433\tvalid_1's auc: 0.893355                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5276]\ttraining's auc: 0.936588\tvalid_1's auc: 0.89411\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.863492\tvalid_1's auc: 0.845805                                                                \n",
      "[2000]\ttraining's auc: 0.883062\tvalid_1's auc: 0.861829                                                                \n",
      "[3000]\ttraining's auc: 0.897606\tvalid_1's auc: 0.873528                                                                \n",
      "[4000]\ttraining's auc: 0.907811\tvalid_1's auc: 0.881167                                                                \n",
      "[5000]\ttraining's auc: 0.915454\tvalid_1's auc: 0.886247                                                                \n",
      "[6000]\ttraining's auc: 0.921349\tvalid_1's auc: 0.889841                                                                \n",
      "[7000]\ttraining's auc: 0.926234\tvalid_1's auc: 0.892357                                                                \n",
      "[8000]\ttraining's auc: 0.930301\tvalid_1's auc: 0.894081                                                                \n",
      "[9000]\ttraining's auc: 0.933771\tvalid_1's auc: 0.89537                                                                 \n",
      "[10000]\ttraining's auc: 0.936984\tvalid_1's auc: 0.896415                                                               \n",
      "[11000]\ttraining's auc: 0.939982\tvalid_1's auc: 0.897251                                                               \n",
      "[12000]\ttraining's auc: 0.942735\tvalid_1's auc: 0.897743                                                               \n",
      "[13000]\ttraining's auc: 0.945375\tvalid_1's auc: 0.897978                                                               \n",
      "[14000]\ttraining's auc: 0.947877\tvalid_1's auc: 0.898194                                                               \n",
      "[15000]\ttraining's auc: 0.950271\tvalid_1's auc: 0.898395                                                               \n",
      "[16000]\ttraining's auc: 0.952537\tvalid_1's auc: 0.898367                                                               \n",
      "[17000]\ttraining's auc: 0.95471\tvalid_1's auc: 0.898368                                                                \n",
      "[18000]\ttraining's auc: 0.956823\tvalid_1's auc: 0.898434                                                               \n",
      "[19000]\ttraining's auc: 0.958878\tvalid_1's auc: 0.89842                                                                \n",
      "[20000]\ttraining's auc: 0.9608\tvalid_1's auc: 0.898305                                                                 \n",
      "[21000]\ttraining's auc: 0.962681\tvalid_1's auc: 0.898369                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18359]\ttraining's auc: 0.957573\tvalid_1's auc: 0.898491\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.866268\tvalid_1's auc: 0.838882                                                                \n",
      "[2000]\ttraining's auc: 0.885415\tvalid_1's auc: 0.854188                                                                \n",
      "[3000]\ttraining's auc: 0.900421\tvalid_1's auc: 0.866575                                                                \n",
      "[4000]\ttraining's auc: 0.910974\tvalid_1's auc: 0.874491                                                                \n",
      "[5000]\ttraining's auc: 0.918633\tvalid_1's auc: 0.879752                                                                \n",
      "[6000]\ttraining's auc: 0.924541\tvalid_1's auc: 0.883408                                                                \n",
      "[7000]\ttraining's auc: 0.929273\tvalid_1's auc: 0.885957                                                                \n",
      "[8000]\ttraining's auc: 0.933193\tvalid_1's auc: 0.887704                                                                \n",
      "[9000]\ttraining's auc: 0.936724\tvalid_1's auc: 0.889072                                                                \n",
      "[10000]\ttraining's auc: 0.939847\tvalid_1's auc: 0.88988                                                                \n",
      "[11000]\ttraining's auc: 0.94265\tvalid_1's auc: 0.890565                                                                \n",
      "[12000]\ttraining's auc: 0.945267\tvalid_1's auc: 0.891127                                                               \n",
      "[13000]\ttraining's auc: 0.947752\tvalid_1's auc: 0.891386                                                               \n",
      "[14000]\ttraining's auc: 0.950051\tvalid_1's auc: 0.89151                                                                \n",
      "[15000]\ttraining's auc: 0.952308\tvalid_1's auc: 0.891723                                                               \n",
      "[16000]\ttraining's auc: 0.954448\tvalid_1's auc: 0.891843                                                               \n",
      "[17000]\ttraining's auc: 0.956582\tvalid_1's auc: 0.891877                                                               \n",
      "[18000]\ttraining's auc: 0.958595\tvalid_1's auc: 0.891898                                                               \n",
      "[19000]\ttraining's auc: 0.960545\tvalid_1's auc: 0.891893                                                               \n",
      "[20000]\ttraining's auc: 0.962408\tvalid_1's auc: 0.891846                                                               \n",
      "[21000]\ttraining's auc: 0.964224\tvalid_1's auc: 0.891733                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18719]\ttraining's auc: 0.96001\tvalid_1's auc: 0.891938\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.864684\tvalid_1's auc: 0.844095                                                                \n",
      "[2000]\ttraining's auc: 0.884315\tvalid_1's auc: 0.860289                                                                \n",
      "[3000]\ttraining's auc: 0.89915\tvalid_1's auc: 0.872066                                                                 \n",
      "[4000]\ttraining's auc: 0.909248\tvalid_1's auc: 0.879697                                                                \n",
      "[5000]\ttraining's auc: 0.91666\tvalid_1's auc: 0.884981                                                                 \n",
      "[6000]\ttraining's auc: 0.922568\tvalid_1's auc: 0.888796                                                                \n",
      "[7000]\ttraining's auc: 0.92733\tvalid_1's auc: 0.891473                                                                 \n",
      "[8000]\ttraining's auc: 0.931288\tvalid_1's auc: 0.893442                                                                \n",
      "[9000]\ttraining's auc: 0.934773\tvalid_1's auc: 0.89495                                                                 \n",
      "[10000]\ttraining's auc: 0.937957\tvalid_1's auc: 0.896036                                                               \n",
      "[11000]\ttraining's auc: 0.940877\tvalid_1's auc: 0.89691                                                                \n",
      "[12000]\ttraining's auc: 0.943561\tvalid_1's auc: 0.897602                                                               \n",
      "[13000]\ttraining's auc: 0.946115\tvalid_1's auc: 0.898133                                                               \n",
      "[14000]\ttraining's auc: 0.948552\tvalid_1's auc: 0.898508                                                               \n",
      "[15000]\ttraining's auc: 0.950894\tvalid_1's auc: 0.898733                                                               \n",
      "[16000]\ttraining's auc: 0.953144\tvalid_1's auc: 0.898843                                                               \n",
      "[17000]\ttraining's auc: 0.955286\tvalid_1's auc: 0.898994                                                               \n",
      "[18000]\ttraining's auc: 0.957333\tvalid_1's auc: 0.898991                                                               \n",
      "[19000]\ttraining's auc: 0.959344\tvalid_1's auc: 0.899036                                                               \n",
      "[20000]\ttraining's auc: 0.961273\tvalid_1's auc: 0.899067                                                               \n",
      "[21000]\ttraining's auc: 0.96314\tvalid_1's auc: 0.899097                                                                \n",
      "[22000]\ttraining's auc: 0.964944\tvalid_1's auc: 0.899192                                                               \n",
      "[23000]\ttraining's auc: 0.966629\tvalid_1's auc: 0.899195                                                               \n",
      "[24000]\ttraining's auc: 0.968277\tvalid_1's auc: 0.899158                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21540]\ttraining's auc: 0.964115\tvalid_1's auc: 0.899211\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.864497\tvalid_1's auc: 0.843074                                                                \n",
      "[2000]\ttraining's auc: 0.884858\tvalid_1's auc: 0.859797                                                                \n",
      "[3000]\ttraining's auc: 0.899673\tvalid_1's auc: 0.870874                                                                \n",
      "[4000]\ttraining's auc: 0.910033\tvalid_1's auc: 0.878257                                                                \n",
      "[5000]\ttraining's auc: 0.917693\tvalid_1's auc: 0.883092                                                                \n",
      "[6000]\ttraining's auc: 0.923522\tvalid_1's auc: 0.886561                                                                \n",
      "[7000]\ttraining's auc: 0.928294\tvalid_1's auc: 0.888972                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000]\ttraining's auc: 0.932309\tvalid_1's auc: 0.89069                                                                 \n",
      "[9000]\ttraining's auc: 0.935914\tvalid_1's auc: 0.89223                                                                 \n",
      "[10000]\ttraining's auc: 0.93914\tvalid_1's auc: 0.893185                                                                \n",
      "[11000]\ttraining's auc: 0.942024\tvalid_1's auc: 0.893819                                                               \n",
      "[12000]\ttraining's auc: 0.944704\tvalid_1's auc: 0.894417                                                               \n",
      "[13000]\ttraining's auc: 0.947224\tvalid_1's auc: 0.8949                                                                 \n",
      "[14000]\ttraining's auc: 0.949631\tvalid_1's auc: 0.895234                                                               \n",
      "[15000]\ttraining's auc: 0.951876\tvalid_1's auc: 0.895407                                                               \n",
      "[16000]\ttraining's auc: 0.954044\tvalid_1's auc: 0.895654                                                               \n",
      "[17000]\ttraining's auc: 0.956164\tvalid_1's auc: 0.895829                                                               \n",
      "[18000]\ttraining's auc: 0.958181\tvalid_1's auc: 0.895931                                                               \n",
      "[19000]\ttraining's auc: 0.960136\tvalid_1's auc: 0.896046                                                               \n",
      "[20000]\ttraining's auc: 0.962025\tvalid_1's auc: 0.896093                                                               \n",
      "[21000]\ttraining's auc: 0.963825\tvalid_1's auc: 0.896135                                                               \n",
      "[22000]\ttraining's auc: 0.965607\tvalid_1's auc: 0.896107                                                               \n",
      "[23000]\ttraining's auc: 0.967287\tvalid_1's auc: 0.896021                                                               \n",
      "[24000]\ttraining's auc: 0.968884\tvalid_1's auc: 0.896045                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21591]\ttraining's auc: 0.964899\tvalid_1's auc: 0.896159\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.858651\tvalid_1's auc: 0.83747                                                                 \n",
      "[2000]\ttraining's auc: 0.888269\tvalid_1's auc: 0.862922                                                                \n",
      "[3000]\ttraining's auc: 0.903711\tvalid_1's auc: 0.875471                                                                \n",
      "[4000]\ttraining's auc: 0.913506\tvalid_1's auc: 0.882834                                                                \n",
      "[5000]\ttraining's auc: 0.920359\tvalid_1's auc: 0.887447                                                                \n",
      "[6000]\ttraining's auc: 0.925631\tvalid_1's auc: 0.890466                                                                \n",
      "[7000]\ttraining's auc: 0.929879\tvalid_1's auc: 0.892557                                                                \n",
      "[8000]\ttraining's auc: 0.933505\tvalid_1's auc: 0.893967                                                                \n",
      "[9000]\ttraining's auc: 0.93668\tvalid_1's auc: 0.89499                                                                  \n",
      "[10000]\ttraining's auc: 0.939715\tvalid_1's auc: 0.895619                                                               \n",
      "[11000]\ttraining's auc: 0.942488\tvalid_1's auc: 0.896012                                                               \n",
      "[12000]\ttraining's auc: 0.945218\tvalid_1's auc: 0.89623                                                                \n",
      "[13000]\ttraining's auc: 0.947897\tvalid_1's auc: 0.896218                                                               \n",
      "[14000]\ttraining's auc: 0.950459\tvalid_1's auc: 0.896247                                                               \n",
      "[15000]\ttraining's auc: 0.952954\tvalid_1's auc: 0.896255                                                               \n",
      "[16000]\ttraining's auc: 0.955327\tvalid_1's auc: 0.896228                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13307]\ttraining's auc: 0.948726\tvalid_1's auc: 0.896278\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.860025\tvalid_1's auc: 0.831643                                                                \n",
      "[2000]\ttraining's auc: 0.890546\tvalid_1's auc: 0.857287                                                                \n",
      "[3000]\ttraining's auc: 0.906406\tvalid_1's auc: 0.870357                                                                \n",
      "[4000]\ttraining's auc: 0.916428\tvalid_1's auc: 0.877569                                                                \n",
      "[5000]\ttraining's auc: 0.923346\tvalid_1's auc: 0.881923                                                                \n",
      "[6000]\ttraining's auc: 0.928503\tvalid_1's auc: 0.884752                                                                \n",
      "[7000]\ttraining's auc: 0.932635\tvalid_1's auc: 0.886832                                                                \n",
      "[8000]\ttraining's auc: 0.936164\tvalid_1's auc: 0.887982                                                                \n",
      "[9000]\ttraining's auc: 0.939243\tvalid_1's auc: 0.888819                                                                \n",
      "[10000]\ttraining's auc: 0.942126\tvalid_1's auc: 0.889244                                                               \n",
      "[11000]\ttraining's auc: 0.944823\tvalid_1's auc: 0.889509                                                               \n",
      "[12000]\ttraining's auc: 0.947444\tvalid_1's auc: 0.889749                                                               \n",
      "[13000]\ttraining's auc: 0.94999\tvalid_1's auc: 0.889742                                                                \n",
      "[14000]\ttraining's auc: 0.952411\tvalid_1's auc: 0.889683                                                               \n",
      "[15000]\ttraining's auc: 0.95479\tvalid_1's auc: 0.889717                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12277]\ttraining's auc: 0.948132\tvalid_1's auc: 0.88979\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.859045\tvalid_1's auc: 0.834742                                                                \n",
      "[2000]\ttraining's auc: 0.889154\tvalid_1's auc: 0.861471                                                                \n",
      "[3000]\ttraining's auc: 0.904894\tvalid_1's auc: 0.874396                                                                \n",
      "[4000]\ttraining's auc: 0.91456\tvalid_1's auc: 0.881839                                                                 \n",
      "[5000]\ttraining's auc: 0.92138\tvalid_1's auc: 0.886313                                                                 \n",
      "[6000]\ttraining's auc: 0.926619\tvalid_1's auc: 0.889564                                                                \n",
      "[7000]\ttraining's auc: 0.930698\tvalid_1's auc: 0.891736                                                                \n",
      "[8000]\ttraining's auc: 0.934249\tvalid_1's auc: 0.893359                                                                \n",
      "[9000]\ttraining's auc: 0.937315\tvalid_1's auc: 0.894642                                                                \n",
      "[10000]\ttraining's auc: 0.940259\tvalid_1's auc: 0.895359                                                               \n",
      "[11000]\ttraining's auc: 0.943031\tvalid_1's auc: 0.895954                                                               \n",
      "[12000]\ttraining's auc: 0.945694\tvalid_1's auc: 0.896434                                                               \n",
      "[13000]\ttraining's auc: 0.948311\tvalid_1's auc: 0.896639                                                               \n",
      "[14000]\ttraining's auc: 0.950778\tvalid_1's auc: 0.89676                                                                \n",
      "[15000]\ttraining's auc: 0.953225\tvalid_1's auc: 0.896899                                                               \n",
      "[16000]\ttraining's auc: 0.955547\tvalid_1's auc: 0.896938                                                               \n",
      "[17000]\ttraining's auc: 0.957741\tvalid_1's auc: 0.896958                                                               \n",
      "[18000]\ttraining's auc: 0.959883\tvalid_1's auc: 0.896967                                                               \n",
      "[19000]\ttraining's auc: 0.961943\tvalid_1's auc: 0.896906                                                               \n",
      "[20000]\ttraining's auc: 0.963941\tvalid_1's auc: 0.896963                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17754]\ttraining's auc: 0.959353\tvalid_1's auc: 0.896997\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.860092\tvalid_1's auc: 0.835517                                                                \n",
      "[2000]\ttraining's auc: 0.889736\tvalid_1's auc: 0.860462                                                                \n",
      "[3000]\ttraining's auc: 0.905276\tvalid_1's auc: 0.872825                                                                \n",
      "[4000]\ttraining's auc: 0.914792\tvalid_1's auc: 0.87977                                                                 \n",
      "[5000]\ttraining's auc: 0.921906\tvalid_1's auc: 0.884538                                                                \n",
      "[6000]\ttraining's auc: 0.927162\tvalid_1's auc: 0.887614                                                                \n",
      "[7000]\ttraining's auc: 0.931494\tvalid_1's auc: 0.889775                                                                \n",
      "[8000]\ttraining's auc: 0.935069\tvalid_1's auc: 0.891288                                                                \n",
      "[9000]\ttraining's auc: 0.938249\tvalid_1's auc: 0.892286                                                                \n",
      "[10000]\ttraining's auc: 0.941165\tvalid_1's auc: 0.893017                                                               \n",
      "[11000]\ttraining's auc: 0.943919\tvalid_1's auc: 0.893671                                                               \n",
      "[12000]\ttraining's auc: 0.946563\tvalid_1's auc: 0.894042                                                               \n",
      "[13000]\ttraining's auc: 0.949115\tvalid_1's auc: 0.894264                                                               \n",
      "[14000]\ttraining's auc: 0.951573\tvalid_1's auc: 0.894435                                                               \n",
      "[15000]\ttraining's auc: 0.953985\tvalid_1's auc: 0.89461                                                                \n",
      "[16000]\ttraining's auc: 0.956285\tvalid_1's auc: 0.894615                                                               \n",
      "[17000]\ttraining's auc: 0.958474\tvalid_1's auc: 0.894643                                                               \n",
      "[18000]\ttraining's auc: 0.960554\tvalid_1's auc: 0.894614                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15743]\ttraining's auc: 0.955691\tvalid_1's auc: 0.894697\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.892282\tvalid_1's auc: 0.871577                                                                \n",
      "[2000]\ttraining's auc: 0.916013\tvalid_1's auc: 0.889347                                                                \n",
      "[3000]\ttraining's auc: 0.927163\tvalid_1's auc: 0.895099                                                                \n",
      "[4000]\ttraining's auc: 0.934647\tvalid_1's auc: 0.897578                                                                \n",
      "[5000]\ttraining's auc: 0.941009\tvalid_1's auc: 0.897711                                                                \n",
      "[6000]\ttraining's auc: 0.946767\tvalid_1's auc: 0.897792                                                                \n",
      "[7000]\ttraining's auc: 0.952055\tvalid_1's auc: 0.897384                                                                \n",
      "[8000]\ttraining's auc: 0.956958\tvalid_1's auc: 0.897163                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5908]\ttraining's auc: 0.946239\tvalid_1's auc: 0.897847\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.895793\tvalid_1's auc: 0.864396                                                                \n",
      "[2000]\ttraining's auc: 0.919501\tvalid_1's auc: 0.882144                                                                \n",
      "[3000]\ttraining's auc: 0.930224\tvalid_1's auc: 0.887833                                                                \n",
      "[4000]\ttraining's auc: 0.937366\tvalid_1's auc: 0.889858                                                                \n",
      "[5000]\ttraining's auc: 0.943452\tvalid_1's auc: 0.890282                                                                \n",
      "[6000]\ttraining's auc: 0.948903\tvalid_1's auc: 0.890221                                                                \n",
      "[7000]\ttraining's auc: 0.953939\tvalid_1's auc: 0.890258                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4863]\ttraining's auc: 0.942678\tvalid_1's auc: 0.890413\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.893291\tvalid_1's auc: 0.87022                                                                 \n",
      "[2000]\ttraining's auc: 0.917071\tvalid_1's auc: 0.887851                                                                \n",
      "[3000]\ttraining's auc: 0.928022\tvalid_1's auc: 0.894401                                                                \n",
      "[4000]\ttraining's auc: 0.935475\tvalid_1's auc: 0.897292                                                                \n",
      "[5000]\ttraining's auc: 0.94155\tvalid_1's auc: 0.898682                                                                 \n",
      "[6000]\ttraining's auc: 0.947249\tvalid_1's auc: 0.899025                                                                \n",
      "[7000]\ttraining's auc: 0.952426\tvalid_1's auc: 0.899158                                                                \n",
      "[8000]\ttraining's auc: 0.957106\tvalid_1's auc: 0.899064                                                                \n",
      "[9000]\ttraining's auc: 0.961604\tvalid_1's auc: 0.898945                                                                \n",
      "[10000]\ttraining's auc: 0.965678\tvalid_1's auc: 0.898751                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7178]\ttraining's auc: 0.953328\tvalid_1's auc: 0.899239\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.894882\tvalid_1's auc: 0.869004                                                                \n",
      "[2000]\ttraining's auc: 0.918074\tvalid_1's auc: 0.886101                                                                \n",
      "[3000]\ttraining's auc: 0.929455\tvalid_1's auc: 0.892213                                                                \n",
      "[4000]\ttraining's auc: 0.936823\tvalid_1's auc: 0.894358                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttraining's auc: 0.942886\tvalid_1's auc: 0.895642                                                                \n",
      "[6000]\ttraining's auc: 0.948418\tvalid_1's auc: 0.895945                                                                \n",
      "[7000]\ttraining's auc: 0.953518\tvalid_1's auc: 0.895949                                                                \n",
      "[8000]\ttraining's auc: 0.958137\tvalid_1's auc: 0.895733                                                                \n",
      "[9000]\ttraining's auc: 0.962487\tvalid_1's auc: 0.89582                                                                 \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6788]\ttraining's auc: 0.952447\tvalid_1's auc: 0.896054\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.906288\tvalid_1's auc: 0.875511                                                                \n",
      "[2000]\ttraining's auc: 0.930025\tvalid_1's auc: 0.890565                                                                \n",
      "[3000]\ttraining's auc: 0.942075\tvalid_1's auc: 0.894356                                                                \n",
      "[4000]\ttraining's auc: 0.951433\tvalid_1's auc: 0.895614                                                                \n",
      "[5000]\ttraining's auc: 0.959314\tvalid_1's auc: 0.895839                                                                \n",
      "[6000]\ttraining's auc: 0.966299\tvalid_1's auc: 0.895745                                                                \n",
      "[7000]\ttraining's auc: 0.972148\tvalid_1's auc: 0.895353                                                                \n",
      "[8000]\ttraining's auc: 0.977049\tvalid_1's auc: 0.894974                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5493]\ttraining's auc: 0.962939\tvalid_1's auc: 0.895972\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.909142\tvalid_1's auc: 0.870387                                                                \n",
      "[2000]\ttraining's auc: 0.932646\tvalid_1's auc: 0.884662                                                                \n",
      "[3000]\ttraining's auc: 0.944289\tvalid_1's auc: 0.888578                                                                \n",
      "[4000]\ttraining's auc: 0.953132\tvalid_1's auc: 0.889672                                                                \n",
      "[5000]\ttraining's auc: 0.960777\tvalid_1's auc: 0.889452                                                                \n",
      "[6000]\ttraining's auc: 0.967369\tvalid_1's auc: 0.889141                                                                \n",
      "[7000]\ttraining's auc: 0.973015\tvalid_1's auc: 0.889023                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4223]\ttraining's auc: 0.954915\tvalid_1's auc: 0.889892\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.907351\tvalid_1's auc: 0.87393                                                                 \n",
      "[2000]\ttraining's auc: 0.930501\tvalid_1's auc: 0.889386                                                                \n",
      "[3000]\ttraining's auc: 0.942427\tvalid_1's auc: 0.893571                                                                \n",
      "[4000]\ttraining's auc: 0.951486\tvalid_1's auc: 0.894994                                                                \n",
      "[5000]\ttraining's auc: 0.959287\tvalid_1's auc: 0.895507                                                                \n",
      "[6000]\ttraining's auc: 0.96603\tvalid_1's auc: 0.895439                                                                 \n",
      "[7000]\ttraining's auc: 0.971792\tvalid_1's auc: 0.895176                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4900]\ttraining's auc: 0.958583\tvalid_1's auc: 0.895621\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.908138\tvalid_1's auc: 0.873951                                                                \n",
      "[2000]\ttraining's auc: 0.931333\tvalid_1's auc: 0.888605                                                                \n",
      "[3000]\ttraining's auc: 0.943517\tvalid_1's auc: 0.892807                                                                \n",
      "[4000]\ttraining's auc: 0.952613\tvalid_1's auc: 0.893952                                                                \n",
      "[5000]\ttraining's auc: 0.960346\tvalid_1's auc: 0.893967                                                                \n",
      "[6000]\ttraining's auc: 0.966929\tvalid_1's auc: 0.893907                                                                \n",
      "[7000]\ttraining's auc: 0.972503\tvalid_1's auc: 0.893949                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4475]\ttraining's auc: 0.956411\tvalid_1's auc: 0.894204\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.866987\tvalid_1's auc: 0.844146                                                                \n",
      "[2000]\ttraining's auc: 0.897274\tvalid_1's auc: 0.869971                                                                \n",
      "[3000]\ttraining's auc: 0.912268\tvalid_1's auc: 0.881423                                                                \n",
      "[4000]\ttraining's auc: 0.921733\tvalid_1's auc: 0.887783                                                                \n",
      "[5000]\ttraining's auc: 0.928492\tvalid_1's auc: 0.891579                                                                \n",
      "[6000]\ttraining's auc: 0.93377\tvalid_1's auc: 0.893924                                                                 \n",
      "[7000]\ttraining's auc: 0.93821\tvalid_1's auc: 0.89537                                                                  \n",
      "[8000]\ttraining's auc: 0.94221\tvalid_1's auc: 0.89612                                                                  \n",
      "[9000]\ttraining's auc: 0.945858\tvalid_1's auc: 0.896358                                                                \n",
      "[10000]\ttraining's auc: 0.949349\tvalid_1's auc: 0.896569                                                               \n",
      "[11000]\ttraining's auc: 0.952596\tvalid_1's auc: 0.896723                                                               \n",
      "[12000]\ttraining's auc: 0.955749\tvalid_1's auc: 0.896742                                                               \n",
      "[13000]\ttraining's auc: 0.958809\tvalid_1's auc: 0.896714                                                               \n",
      "[14000]\ttraining's auc: 0.961578\tvalid_1's auc: 0.896713                                                               \n",
      "[15000]\ttraining's auc: 0.964204\tvalid_1's auc: 0.896594                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12333]\ttraining's auc: 0.956783\tvalid_1's auc: 0.896831\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.868894\tvalid_1's auc: 0.838442                                                                \n",
      "[2000]\ttraining's auc: 0.89981\tvalid_1's auc: 0.863881                                                                 \n",
      "[3000]\ttraining's auc: 0.915121\tvalid_1's auc: 0.875392                                                                \n",
      "[4000]\ttraining's auc: 0.924642\tvalid_1's auc: 0.881687                                                                \n",
      "[5000]\ttraining's auc: 0.931333\tvalid_1's auc: 0.885172                                                                \n",
      "[6000]\ttraining's auc: 0.936446\tvalid_1's auc: 0.887308                                                                \n",
      "[7000]\ttraining's auc: 0.940696\tvalid_1's auc: 0.888648                                                                \n",
      "[8000]\ttraining's auc: 0.94452\tvalid_1's auc: 0.889396                                                                 \n",
      "[9000]\ttraining's auc: 0.947972\tvalid_1's auc: 0.889815                                                                \n",
      "[10000]\ttraining's auc: 0.951321\tvalid_1's auc: 0.890064                                                               \n",
      "[11000]\ttraining's auc: 0.954478\tvalid_1's auc: 0.890296                                                               \n",
      "[12000]\ttraining's auc: 0.957463\tvalid_1's auc: 0.890246                                                               \n",
      "[13000]\ttraining's auc: 0.960292\tvalid_1's auc: 0.890263                                                               \n",
      "[14000]\ttraining's auc: 0.962971\tvalid_1's auc: 0.890258                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11077]\ttraining's auc: 0.954718\tvalid_1's auc: 0.890316\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.867819\tvalid_1's auc: 0.842719                                                                \n",
      "[2000]\ttraining's auc: 0.898393\tvalid_1's auc: 0.868703                                                                \n",
      "[3000]\ttraining's auc: 0.913579\tvalid_1's auc: 0.879933                                                                \n",
      "[4000]\ttraining's auc: 0.92286\tvalid_1's auc: 0.885959                                                                 \n",
      "[5000]\ttraining's auc: 0.92936\tvalid_1's auc: 0.889871                                                                 \n",
      "[6000]\ttraining's auc: 0.934458\tvalid_1's auc: 0.892285                                                                \n",
      "[7000]\ttraining's auc: 0.938804\tvalid_1's auc: 0.893856                                                                \n",
      "[8000]\ttraining's auc: 0.942674\tvalid_1's auc: 0.894727                                                                \n",
      "[9000]\ttraining's auc: 0.946193\tvalid_1's auc: 0.895493                                                                \n",
      "[10000]\ttraining's auc: 0.949596\tvalid_1's auc: 0.895901                                                               \n",
      "[11000]\ttraining's auc: 0.952897\tvalid_1's auc: 0.896126                                                               \n",
      "[12000]\ttraining's auc: 0.955965\tvalid_1's auc: 0.8963                                                                 \n",
      "[13000]\ttraining's auc: 0.958901\tvalid_1's auc: 0.896406                                                               \n",
      "[14000]\ttraining's auc: 0.961635\tvalid_1's auc: 0.896485                                                               \n",
      "[15000]\ttraining's auc: 0.964235\tvalid_1's auc: 0.89645                                                                \n",
      "[16000]\ttraining's auc: 0.966642\tvalid_1's auc: 0.89642                                                                \n",
      "[17000]\ttraining's auc: 0.968962\tvalid_1's auc: 0.896382                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14045]\ttraining's auc: 0.961758\tvalid_1's auc: 0.896506\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.868696\tvalid_1's auc: 0.842138                                                                \n",
      "[2000]\ttraining's auc: 0.898544\tvalid_1's auc: 0.866808                                                                \n",
      "[3000]\ttraining's auc: 0.9135\tvalid_1's auc: 0.878179                                                                  \n",
      "[4000]\ttraining's auc: 0.923008\tvalid_1's auc: 0.884207                                                                \n",
      "[5000]\ttraining's auc: 0.92993\tvalid_1's auc: 0.888136                                                                 \n",
      "[6000]\ttraining's auc: 0.935155\tvalid_1's auc: 0.890466                                                                \n",
      "[7000]\ttraining's auc: 0.939607\tvalid_1's auc: 0.891956                                                                \n",
      "[8000]\ttraining's auc: 0.943503\tvalid_1's auc: 0.89301                                                                 \n",
      "[9000]\ttraining's auc: 0.947095\tvalid_1's auc: 0.893591                                                                \n",
      "[10000]\ttraining's auc: 0.950375\tvalid_1's auc: 0.894112                                                               \n",
      "[11000]\ttraining's auc: 0.953596\tvalid_1's auc: 0.894477                                                               \n",
      "[12000]\ttraining's auc: 0.956607\tvalid_1's auc: 0.894713                                                               \n",
      "[13000]\ttraining's auc: 0.959503\tvalid_1's auc: 0.894768                                                               \n",
      "[14000]\ttraining's auc: 0.962176\tvalid_1's auc: 0.894651                                                               \n",
      "[15000]\ttraining's auc: 0.964759\tvalid_1's auc: 0.894718                                                               \n",
      "[16000]\ttraining's auc: 0.967161\tvalid_1's auc: 0.894703                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13226]\ttraining's auc: 0.960126\tvalid_1's auc: 0.89479\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.881443\tvalid_1's auc: 0.858509                                                                \n",
      "[2000]\ttraining's auc: 0.907678\tvalid_1's auc: 0.879817                                                                \n",
      "[3000]\ttraining's auc: 0.920813\tvalid_1's auc: 0.888491                                                                \n",
      "[4000]\ttraining's auc: 0.9292\tvalid_1's auc: 0.892836                                                                  \n",
      "[5000]\ttraining's auc: 0.935336\tvalid_1's auc: 0.894841                                                                \n",
      "[6000]\ttraining's auc: 0.940639\tvalid_1's auc: 0.89613                                                                 \n",
      "[7000]\ttraining's auc: 0.9454\tvalid_1's auc: 0.896685                                                                  \n",
      "[8000]\ttraining's auc: 0.949828\tvalid_1's auc: 0.896729                                                                \n",
      "[9000]\ttraining's auc: 0.953971\tvalid_1's auc: 0.896828                                                                \n",
      "[10000]\ttraining's auc: 0.957937\tvalid_1's auc: 0.896609                                                               \n",
      "[11000]\ttraining's auc: 0.961532\tvalid_1's auc: 0.896374                                                               \n",
      "[12000]\ttraining's auc: 0.964977\tvalid_1's auc: 0.896165                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9105]\ttraining's auc: 0.954394\tvalid_1's auc: 0.896918\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.883387\tvalid_1's auc: 0.850822                                                                \n",
      "[2000]\ttraining's auc: 0.910554\tvalid_1's auc: 0.87325                                                                 \n",
      "[3000]\ttraining's auc: 0.923805\tvalid_1's auc: 0.882089                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000]\ttraining's auc: 0.9321\tvalid_1's auc: 0.886502                                                                  \n",
      "[5000]\ttraining's auc: 0.938148\tvalid_1's auc: 0.888667                                                                \n",
      "[6000]\ttraining's auc: 0.943115\tvalid_1's auc: 0.889562                                                                \n",
      "[7000]\ttraining's auc: 0.947676\tvalid_1's auc: 0.890074                                                                \n",
      "[8000]\ttraining's auc: 0.951879\tvalid_1's auc: 0.890399                                                                \n",
      "[9000]\ttraining's auc: 0.955788\tvalid_1's auc: 0.890326                                                                \n",
      "[10000]\ttraining's auc: 0.959511\tvalid_1's auc: 0.890094                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7986]\ttraining's auc: 0.951816\tvalid_1's auc: 0.890409\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.882888\tvalid_1's auc: 0.856773                                                                \n",
      "[2000]\ttraining's auc: 0.908916\tvalid_1's auc: 0.87876                                                                 \n",
      "[3000]\ttraining's auc: 0.921894\tvalid_1's auc: 0.887676                                                                \n",
      "[4000]\ttraining's auc: 0.93007\tvalid_1's auc: 0.891996                                                                 \n",
      "[5000]\ttraining's auc: 0.936162\tvalid_1's auc: 0.894409                                                                \n",
      "[6000]\ttraining's auc: 0.941386\tvalid_1's auc: 0.89568                                                                 \n",
      "[7000]\ttraining's auc: 0.946022\tvalid_1's auc: 0.896455                                                                \n",
      "[8000]\ttraining's auc: 0.950332\tvalid_1's auc: 0.896877                                                                \n",
      "[9000]\ttraining's auc: 0.954367\tvalid_1's auc: 0.896949                                                                \n",
      "[10000]\ttraining's auc: 0.958182\tvalid_1's auc: 0.896939                                                               \n",
      "[11000]\ttraining's auc: 0.961817\tvalid_1's auc: 0.896842                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8327]\ttraining's auc: 0.951682\tvalid_1's auc: 0.897002\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.883491\tvalid_1's auc: 0.85592                                                                 \n",
      "[2000]\ttraining's auc: 0.909144\tvalid_1's auc: 0.876541                                                                \n",
      "[3000]\ttraining's auc: 0.922267\tvalid_1's auc: 0.885517                                                                \n",
      "[4000]\ttraining's auc: 0.9307\tvalid_1's auc: 0.889571                                                                  \n",
      "[5000]\ttraining's auc: 0.93697\tvalid_1's auc: 0.891769                                                                 \n",
      "[6000]\ttraining's auc: 0.942095\tvalid_1's auc: 0.892917                                                                \n",
      "[7000]\ttraining's auc: 0.946747\tvalid_1's auc: 0.893424                                                                \n",
      "[8000]\ttraining's auc: 0.951056\tvalid_1's auc: 0.893715                                                                \n",
      "[9000]\ttraining's auc: 0.95507\tvalid_1's auc: 0.893824                                                                 \n",
      "[10000]\ttraining's auc: 0.958808\tvalid_1's auc: 0.893869                                                               \n",
      "[11000]\ttraining's auc: 0.962331\tvalid_1's auc: 0.893974                                                               \n",
      "[12000]\ttraining's auc: 0.965543\tvalid_1's auc: 0.893949                                                               \n",
      "[13000]\ttraining's auc: 0.968643\tvalid_1's auc: 0.893877                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10926]\ttraining's auc: 0.962079\tvalid_1's auc: 0.894028\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.904382\tvalid_1's auc: 0.874145                                                                \n",
      "[2000]\ttraining's auc: 0.92764\tvalid_1's auc: 0.889222                                                                 \n",
      "[3000]\ttraining's auc: 0.940365\tvalid_1's auc: 0.894357                                                                \n",
      "[4000]\ttraining's auc: 0.949303\tvalid_1's auc: 0.896204                                                                \n",
      "[5000]\ttraining's auc: 0.956836\tvalid_1's auc: 0.896518                                                                \n",
      "[6000]\ttraining's auc: 0.963429\tvalid_1's auc: 0.896396                                                                \n",
      "[7000]\ttraining's auc: 0.969231\tvalid_1's auc: 0.896019                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4929]\ttraining's auc: 0.956355\tvalid_1's auc: 0.896564\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.906939\tvalid_1's auc: 0.868165                                                                \n",
      "[2000]\ttraining's auc: 0.930371\tvalid_1's auc: 0.882357                                                                \n",
      "[3000]\ttraining's auc: 0.942667\tvalid_1's auc: 0.88751                                                                 \n",
      "[4000]\ttraining's auc: 0.951327\tvalid_1's auc: 0.889051                                                                \n",
      "[5000]\ttraining's auc: 0.958586\tvalid_1's auc: 0.889277                                                                \n",
      "[6000]\ttraining's auc: 0.964829\tvalid_1's auc: 0.889236                                                                \n",
      "[7000]\ttraining's auc: 0.970348\tvalid_1's auc: 0.889395                                                                \n",
      "[8000]\ttraining's auc: 0.975113\tvalid_1's auc: 0.88895                                                                 \n",
      "[9000]\ttraining's auc: 0.97918\tvalid_1's auc: 0.888554                                                                 \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6708]\ttraining's auc: 0.968838\tvalid_1's auc: 0.889572\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.905124\tvalid_1's auc: 0.872401                                                                \n",
      "[2000]\ttraining's auc: 0.928608\tvalid_1's auc: 0.888294                                                                \n",
      "[3000]\ttraining's auc: 0.940916\tvalid_1's auc: 0.893789                                                                \n",
      "[4000]\ttraining's auc: 0.949596\tvalid_1's auc: 0.895723                                                                \n",
      "[5000]\ttraining's auc: 0.957041\tvalid_1's auc: 0.896506                                                                \n",
      "[6000]\ttraining's auc: 0.963549\tvalid_1's auc: 0.896648                                                                \n",
      "[7000]\ttraining's auc: 0.969271\tvalid_1's auc: 0.896572                                                                \n",
      "[8000]\ttraining's auc: 0.974106\tvalid_1's auc: 0.896541                                                                \n",
      "[9000]\ttraining's auc: 0.978334\tvalid_1's auc: 0.896254                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6664]\ttraining's auc: 0.967432\tvalid_1's auc: 0.896714\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.906082\tvalid_1's auc: 0.870752                                                                \n",
      "[2000]\ttraining's auc: 0.929161\tvalid_1's auc: 0.88569                                                                 \n",
      "[3000]\ttraining's auc: 0.941848\tvalid_1's auc: 0.890882                                                                \n",
      "[4000]\ttraining's auc: 0.950611\tvalid_1's auc: 0.893041                                                                \n",
      "[5000]\ttraining's auc: 0.958042\tvalid_1's auc: 0.893892                                                                \n",
      "[6000]\ttraining's auc: 0.964448\tvalid_1's auc: 0.894115                                                                \n",
      "[7000]\ttraining's auc: 0.970019\tvalid_1's auc: 0.894382                                                                \n",
      "[8000]\ttraining's auc: 0.974785\tvalid_1's auc: 0.894402                                                                \n",
      "[9000]\ttraining's auc: 0.978861\tvalid_1's auc: 0.894242                                                                \n",
      "[10000]\ttraining's auc: 0.982287\tvalid_1's auc: 0.894156                                                               \n",
      "[11000]\ttraining's auc: 0.985255\tvalid_1's auc: 0.89407                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8271]\ttraining's auc: 0.975958\tvalid_1's auc: 0.894478\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.848653\tvalid_1's auc: 0.835788                                                                \n",
      "[2000]\ttraining's auc: 0.87009\tvalid_1's auc: 0.855382                                                                 \n",
      "[3000]\ttraining's auc: 0.885325\tvalid_1's auc: 0.868754                                                                \n",
      "[4000]\ttraining's auc: 0.895771\tvalid_1's auc: 0.877547                                                                \n",
      "[5000]\ttraining's auc: 0.902902\tvalid_1's auc: 0.883289                                                                \n",
      "[6000]\ttraining's auc: 0.90827\tvalid_1's auc: 0.887286                                                                 \n",
      "[7000]\ttraining's auc: 0.912546\tvalid_1's auc: 0.890303                                                                \n",
      "[8000]\ttraining's auc: 0.915978\tvalid_1's auc: 0.892522                                                                \n",
      "[9000]\ttraining's auc: 0.918853\tvalid_1's auc: 0.894238                                                                \n",
      "[10000]\ttraining's auc: 0.921386\tvalid_1's auc: 0.89551                                                                \n",
      "[11000]\ttraining's auc: 0.923621\tvalid_1's auc: 0.896361                                                               \n",
      "[12000]\ttraining's auc: 0.925663\tvalid_1's auc: 0.897053                                                               \n",
      "[13000]\ttraining's auc: 0.92759\tvalid_1's auc: 0.897412                                                                \n",
      "[14000]\ttraining's auc: 0.929395\tvalid_1's auc: 0.897785                                                               \n",
      "[15000]\ttraining's auc: 0.931159\tvalid_1's auc: 0.89804                                                                \n",
      "[16000]\ttraining's auc: 0.932854\tvalid_1's auc: 0.898207                                                               \n",
      "[17000]\ttraining's auc: 0.934424\tvalid_1's auc: 0.898316                                                               \n",
      "[18000]\ttraining's auc: 0.935959\tvalid_1's auc: 0.898449                                                               \n",
      "[19000]\ttraining's auc: 0.937466\tvalid_1's auc: 0.898526                                                               \n",
      "[20000]\ttraining's auc: 0.938988\tvalid_1's auc: 0.898547                                                               \n",
      "[21000]\ttraining's auc: 0.940439\tvalid_1's auc: 0.898546                                                               \n",
      "[22000]\ttraining's auc: 0.941871\tvalid_1's auc: 0.89849                                                                \n",
      "[23000]\ttraining's auc: 0.943301\tvalid_1's auc: 0.898354                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20748]\ttraining's auc: 0.940073\tvalid_1's auc: 0.898584\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.852025\tvalid_1's auc: 0.830232                                                                \n",
      "[2000]\ttraining's auc: 0.873451\tvalid_1's auc: 0.849002                                                                \n",
      "[3000]\ttraining's auc: 0.888264\tvalid_1's auc: 0.861959                                                                \n",
      "[4000]\ttraining's auc: 0.898889\tvalid_1's auc: 0.87075                                                                 \n",
      "[5000]\ttraining's auc: 0.906225\tvalid_1's auc: 0.876692                                                                \n",
      "[6000]\ttraining's auc: 0.911704\tvalid_1's auc: 0.880706                                                                \n",
      "[7000]\ttraining's auc: 0.91601\tvalid_1's auc: 0.883586                                                                 \n",
      "[8000]\ttraining's auc: 0.919399\tvalid_1's auc: 0.885572                                                                \n",
      "[9000]\ttraining's auc: 0.922299\tvalid_1's auc: 0.887039                                                                \n",
      "[10000]\ttraining's auc: 0.924784\tvalid_1's auc: 0.888191                                                               \n",
      "[11000]\ttraining's auc: 0.926949\tvalid_1's auc: 0.889042                                                               \n",
      "[12000]\ttraining's auc: 0.928969\tvalid_1's auc: 0.889739                                                               \n",
      "[13000]\ttraining's auc: 0.930803\tvalid_1's auc: 0.89026                                                                \n",
      "[14000]\ttraining's auc: 0.932506\tvalid_1's auc: 0.890504                                                               \n",
      "[15000]\ttraining's auc: 0.934116\tvalid_1's auc: 0.890798                                                               \n",
      "[16000]\ttraining's auc: 0.93571\tvalid_1's auc: 0.891088                                                                \n",
      "[17000]\ttraining's auc: 0.937255\tvalid_1's auc: 0.891249                                                               \n",
      "[18000]\ttraining's auc: 0.938769\tvalid_1's auc: 0.891241                                                               \n",
      "[19000]\ttraining's auc: 0.940223\tvalid_1's auc: 0.891374                                                               \n",
      "[20000]\ttraining's auc: 0.941684\tvalid_1's auc: 0.891418                                                               \n",
      "[21000]\ttraining's auc: 0.943094\tvalid_1's auc: 0.891451                                                               \n",
      "[22000]\ttraining's auc: 0.944469\tvalid_1's auc: 0.891458                                                               \n",
      "[23000]\ttraining's auc: 0.945818\tvalid_1's auc: 0.891404                                                               \n",
      "[24000]\ttraining's auc: 0.947168\tvalid_1's auc: 0.891368                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21382]\ttraining's auc: 0.94362\tvalid_1's auc: 0.891477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.849779\tvalid_1's auc: 0.836149                                                                \n",
      "[2000]\ttraining's auc: 0.871144\tvalid_1's auc: 0.854423                                                                \n",
      "[3000]\ttraining's auc: 0.886721\tvalid_1's auc: 0.868033                                                                \n",
      "[4000]\ttraining's auc: 0.896887\tvalid_1's auc: 0.876553                                                                \n",
      "[5000]\ttraining's auc: 0.904146\tvalid_1's auc: 0.88251                                                                 \n",
      "[6000]\ttraining's auc: 0.909622\tvalid_1's auc: 0.886691                                                                \n",
      "[7000]\ttraining's auc: 0.913844\tvalid_1's auc: 0.889665                                                                \n",
      "[8000]\ttraining's auc: 0.91719\tvalid_1's auc: 0.891824                                                                 \n",
      "[9000]\ttraining's auc: 0.920001\tvalid_1's auc: 0.893604                                                                \n",
      "[10000]\ttraining's auc: 0.922454\tvalid_1's auc: 0.894948                                                               \n",
      "[11000]\ttraining's auc: 0.92462\tvalid_1's auc: 0.896162                                                                \n",
      "[12000]\ttraining's auc: 0.926658\tvalid_1's auc: 0.897044                                                               \n",
      "[13000]\ttraining's auc: 0.928491\tvalid_1's auc: 0.897645                                                               \n",
      "[14000]\ttraining's auc: 0.93027\tvalid_1's auc: 0.898115                                                                \n",
      "[15000]\ttraining's auc: 0.931976\tvalid_1's auc: 0.898495                                                               \n",
      "[16000]\ttraining's auc: 0.933595\tvalid_1's auc: 0.898833                                                               \n",
      "[17000]\ttraining's auc: 0.93518\tvalid_1's auc: 0.898968                                                                \n",
      "[18000]\ttraining's auc: 0.936716\tvalid_1's auc: 0.89913                                                                \n",
      "[19000]\ttraining's auc: 0.938232\tvalid_1's auc: 0.899313                                                               \n",
      "[20000]\ttraining's auc: 0.939672\tvalid_1's auc: 0.899425                                                               \n",
      "[21000]\ttraining's auc: 0.941133\tvalid_1's auc: 0.8995                                                                 \n",
      "[22000]\ttraining's auc: 0.942543\tvalid_1's auc: 0.899478                                                               \n",
      "[23000]\ttraining's auc: 0.943941\tvalid_1's auc: 0.899567                                                               \n",
      "[24000]\ttraining's auc: 0.945309\tvalid_1's auc: 0.89959                                                                \n",
      "[25000]\ttraining's auc: 0.946648\tvalid_1's auc: 0.89956                                                                \n",
      "[26000]\ttraining's auc: 0.947957\tvalid_1's auc: 0.899574                                                               \n",
      "[27000]\ttraining's auc: 0.94924\tvalid_1's auc: 0.899565                                                                \n",
      "[28000]\ttraining's auc: 0.950492\tvalid_1's auc: 0.899515                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25456]\ttraining's auc: 0.947253\tvalid_1's auc: 0.89962\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.850723\tvalid_1's auc: 0.835011                                                                \n",
      "[2000]\ttraining's auc: 0.872492\tvalid_1's auc: 0.853755                                                                \n",
      "[3000]\ttraining's auc: 0.887261\tvalid_1's auc: 0.866169                                                                \n",
      "[4000]\ttraining's auc: 0.897546\tvalid_1's auc: 0.8744                                                                  \n",
      "[5000]\ttraining's auc: 0.904828\tvalid_1's auc: 0.880138                                                                \n",
      "[6000]\ttraining's auc: 0.910223\tvalid_1's auc: 0.884118                                                                \n",
      "[7000]\ttraining's auc: 0.914582\tvalid_1's auc: 0.887085                                                                \n",
      "[8000]\ttraining's auc: 0.918136\tvalid_1's auc: 0.889347                                                                \n",
      "[9000]\ttraining's auc: 0.921128\tvalid_1's auc: 0.891064                                                                \n",
      "[10000]\ttraining's auc: 0.923691\tvalid_1's auc: 0.89233                                                                \n",
      "[11000]\ttraining's auc: 0.925947\tvalid_1's auc: 0.893259                                                               \n",
      "[12000]\ttraining's auc: 0.928022\tvalid_1's auc: 0.894137                                                               \n",
      "[13000]\ttraining's auc: 0.929945\tvalid_1's auc: 0.894661                                                               \n",
      "[14000]\ttraining's auc: 0.931726\tvalid_1's auc: 0.895054                                                               \n",
      "[15000]\ttraining's auc: 0.933392\tvalid_1's auc: 0.895359                                                               \n",
      "[16000]\ttraining's auc: 0.935012\tvalid_1's auc: 0.895671                                                               \n",
      "[17000]\ttraining's auc: 0.936611\tvalid_1's auc: 0.895836                                                               \n",
      "[18000]\ttraining's auc: 0.938122\tvalid_1's auc: 0.895927                                                               \n",
      "[19000]\ttraining's auc: 0.939593\tvalid_1's auc: 0.896051                                                               \n",
      "[20000]\ttraining's auc: 0.941037\tvalid_1's auc: 0.896138                                                               \n",
      "[21000]\ttraining's auc: 0.942449\tvalid_1's auc: 0.896166                                                               \n",
      "[22000]\ttraining's auc: 0.943821\tvalid_1's auc: 0.896169                                                               \n",
      "[23000]\ttraining's auc: 0.945149\tvalid_1's auc: 0.896211                                                               \n",
      "[24000]\ttraining's auc: 0.946473\tvalid_1's auc: 0.896128                                                               \n",
      "[25000]\ttraining's auc: 0.947797\tvalid_1's auc: 0.896123                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22393]\ttraining's auc: 0.944347\tvalid_1's auc: 0.896221\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.850985\tvalid_1's auc: 0.83866                                                                 \n",
      "[2000]\ttraining's auc: 0.865069\tvalid_1's auc: 0.851408                                                                \n",
      "[3000]\ttraining's auc: 0.877497\tvalid_1's auc: 0.862575                                                                \n",
      "[4000]\ttraining's auc: 0.887012\tvalid_1's auc: 0.870872                                                                \n",
      "[5000]\ttraining's auc: 0.89422\tvalid_1's auc: 0.877196                                                                 \n",
      "[6000]\ttraining's auc: 0.899852\tvalid_1's auc: 0.881634                                                                \n",
      "[7000]\ttraining's auc: 0.904247\tvalid_1's auc: 0.88495                                                                 \n",
      "[8000]\ttraining's auc: 0.908032\tvalid_1's auc: 0.887745                                                                \n",
      "[9000]\ttraining's auc: 0.911165\tvalid_1's auc: 0.889999                                                                \n",
      "[10000]\ttraining's auc: 0.913858\tvalid_1's auc: 0.891812                                                               \n",
      "[11000]\ttraining's auc: 0.916158\tvalid_1's auc: 0.893097                                                               \n",
      "[12000]\ttraining's auc: 0.91832\tvalid_1's auc: 0.894175                                                                \n",
      "[13000]\ttraining's auc: 0.920235\tvalid_1's auc: 0.894952                                                               \n",
      "[14000]\ttraining's auc: 0.92197\tvalid_1's auc: 0.895592                                                                \n",
      "[15000]\ttraining's auc: 0.923598\tvalid_1's auc: 0.895972                                                               \n",
      "[16000]\ttraining's auc: 0.925096\tvalid_1's auc: 0.89633                                                                \n",
      "[17000]\ttraining's auc: 0.926558\tvalid_1's auc: 0.896601                                                               \n",
      "[18000]\ttraining's auc: 0.927943\tvalid_1's auc: 0.896805                                                               \n",
      "[19000]\ttraining's auc: 0.929302\tvalid_1's auc: 0.89694                                                                \n",
      "[20000]\ttraining's auc: 0.930595\tvalid_1's auc: 0.897126                                                               \n",
      "[21000]\ttraining's auc: 0.931883\tvalid_1's auc: 0.897231                                                               \n",
      "[22000]\ttraining's auc: 0.933086\tvalid_1's auc: 0.89721                                                                \n",
      "[23000]\ttraining's auc: 0.934285\tvalid_1's auc: 0.897221                                                               \n",
      "[24000]\ttraining's auc: 0.935462\tvalid_1's auc: 0.897251                                                               \n",
      "[25000]\ttraining's auc: 0.936646\tvalid_1's auc: 0.897216                                                               \n",
      "[26000]\ttraining's auc: 0.937771\tvalid_1's auc: 0.897094                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23826]\ttraining's auc: 0.935259\tvalid_1's auc: 0.897267\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.853832\tvalid_1's auc: 0.833025                                                                \n",
      "[2000]\ttraining's auc: 0.868571\tvalid_1's auc: 0.846005                                                                \n",
      "[3000]\ttraining's auc: 0.880632\tvalid_1's auc: 0.856434                                                                \n",
      "[4000]\ttraining's auc: 0.890247\tvalid_1's auc: 0.864754                                                                \n",
      "[5000]\ttraining's auc: 0.897427\tvalid_1's auc: 0.870585                                                                \n",
      "[6000]\ttraining's auc: 0.903258\tvalid_1's auc: 0.87512                                                                 \n",
      "[7000]\ttraining's auc: 0.907855\tvalid_1's auc: 0.878644                                                                \n",
      "[8000]\ttraining's auc: 0.911626\tvalid_1's auc: 0.881381                                                                \n",
      "[9000]\ttraining's auc: 0.914681\tvalid_1's auc: 0.883286                                                                \n",
      "[10000]\ttraining's auc: 0.917398\tvalid_1's auc: 0.885006                                                               \n",
      "[11000]\ttraining's auc: 0.919726\tvalid_1's auc: 0.886334                                                               \n",
      "[12000]\ttraining's auc: 0.921766\tvalid_1's auc: 0.887348                                                               \n",
      "[13000]\ttraining's auc: 0.923633\tvalid_1's auc: 0.888077                                                               \n",
      "[14000]\ttraining's auc: 0.92531\tvalid_1's auc: 0.888802                                                                \n",
      "[15000]\ttraining's auc: 0.926869\tvalid_1's auc: 0.889382                                                               \n",
      "[16000]\ttraining's auc: 0.928311\tvalid_1's auc: 0.889696                                                               \n",
      "[17000]\ttraining's auc: 0.929666\tvalid_1's auc: 0.889887                                                               \n",
      "[18000]\ttraining's auc: 0.930973\tvalid_1's auc: 0.890063                                                               \n",
      "[19000]\ttraining's auc: 0.932234\tvalid_1's auc: 0.890219                                                               \n",
      "[20000]\ttraining's auc: 0.93347\tvalid_1's auc: 0.890337                                                                \n",
      "[21000]\ttraining's auc: 0.934678\tvalid_1's auc: 0.890351                                                               \n",
      "[22000]\ttraining's auc: 0.93585\tvalid_1's auc: 0.890437                                                                \n",
      "[23000]\ttraining's auc: 0.93701\tvalid_1's auc: 0.890427                                                                \n",
      "[24000]\ttraining's auc: 0.938144\tvalid_1's auc: 0.890388                                                               \n",
      "[25000]\ttraining's auc: 0.939261\tvalid_1's auc: 0.89028                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22406]\ttraining's auc: 0.936319\tvalid_1's auc: 0.890477\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.852017\tvalid_1's auc: 0.836791                                                                \n",
      "[2000]\ttraining's auc: 0.86664\tvalid_1's auc: 0.850249                                                                 \n",
      "[3000]\ttraining's auc: 0.878809\tvalid_1's auc: 0.861379                                                                \n",
      "[4000]\ttraining's auc: 0.888243\tvalid_1's auc: 0.869642                                                                \n",
      "[5000]\ttraining's auc: 0.895287\tvalid_1's auc: 0.87582                                                                 \n",
      "[6000]\ttraining's auc: 0.900947\tvalid_1's auc: 0.880532                                                                \n",
      "[7000]\ttraining's auc: 0.905417\tvalid_1's auc: 0.884124                                                                \n",
      "[8000]\ttraining's auc: 0.90915\tvalid_1's auc: 0.887035                                                                 \n",
      "[9000]\ttraining's auc: 0.912181\tvalid_1's auc: 0.889188                                                                \n",
      "[10000]\ttraining's auc: 0.914785\tvalid_1's auc: 0.890802                                                               \n",
      "[11000]\ttraining's auc: 0.917096\tvalid_1's auc: 0.892189                                                               \n",
      "[12000]\ttraining's auc: 0.919148\tvalid_1's auc: 0.893418                                                               \n",
      "[13000]\ttraining's auc: 0.920983\tvalid_1's auc: 0.894263                                                               \n",
      "[14000]\ttraining's auc: 0.922724\tvalid_1's auc: 0.894992                                                               \n",
      "[15000]\ttraining's auc: 0.924284\tvalid_1's auc: 0.895524                                                               \n",
      "[16000]\ttraining's auc: 0.925775\tvalid_1's auc: 0.896027                                                               \n",
      "[17000]\ttraining's auc: 0.92717\tvalid_1's auc: 0.896444                                                                \n",
      "[18000]\ttraining's auc: 0.928544\tvalid_1's auc: 0.896845                                                               \n",
      "[19000]\ttraining's auc: 0.929822\tvalid_1's auc: 0.897093                                                               \n",
      "[20000]\ttraining's auc: 0.931077\tvalid_1's auc: 0.897212                                                               \n",
      "[21000]\ttraining's auc: 0.932337\tvalid_1's auc: 0.89738                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22000]\ttraining's auc: 0.933567\tvalid_1's auc: 0.897506                                                               \n",
      "[23000]\ttraining's auc: 0.934744\tvalid_1's auc: 0.897595                                                               \n",
      "[24000]\ttraining's auc: 0.935892\tvalid_1's auc: 0.897693                                                               \n",
      "[25000]\ttraining's auc: 0.937028\tvalid_1's auc: 0.897807                                                               \n",
      "[26000]\ttraining's auc: 0.938162\tvalid_1's auc: 0.89786                                                                \n",
      "[27000]\ttraining's auc: 0.939274\tvalid_1's auc: 0.897904                                                               \n",
      "[28000]\ttraining's auc: 0.940366\tvalid_1's auc: 0.897933                                                               \n",
      "[29000]\ttraining's auc: 0.941437\tvalid_1's auc: 0.89797                                                                \n",
      "[30000]\ttraining's auc: 0.942491\tvalid_1's auc: 0.897959                                                               \n",
      "[31000]\ttraining's auc: 0.94354\tvalid_1's auc: 0.897989                                                                \n",
      "[32000]\ttraining's auc: 0.944566\tvalid_1's auc: 0.897952                                                               \n",
      "[33000]\ttraining's auc: 0.945584\tvalid_1's auc: 0.897886                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30902]\ttraining's auc: 0.94344\tvalid_1's auc: 0.898023\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.852041\tvalid_1's auc: 0.835763                                                                \n",
      "[2000]\ttraining's auc: 0.867\tvalid_1's auc: 0.849301                                                                   \n",
      "[3000]\ttraining's auc: 0.879431\tvalid_1's auc: 0.859824                                                                \n",
      "[4000]\ttraining's auc: 0.889106\tvalid_1's auc: 0.868314                                                                \n",
      "[5000]\ttraining's auc: 0.895947\tvalid_1's auc: 0.873889                                                                \n",
      "[6000]\ttraining's auc: 0.901592\tvalid_1's auc: 0.878445                                                                \n",
      "[7000]\ttraining's auc: 0.906039\tvalid_1's auc: 0.881879                                                                \n",
      "[8000]\ttraining's auc: 0.90982\tvalid_1's auc: 0.884726                                                                 \n",
      "[9000]\ttraining's auc: 0.912959\tvalid_1's auc: 0.886899                                                                \n",
      "[10000]\ttraining's auc: 0.915664\tvalid_1's auc: 0.8887                                                                 \n",
      "[11000]\ttraining's auc: 0.918051\tvalid_1's auc: 0.890071                                                               \n",
      "[12000]\ttraining's auc: 0.9201\tvalid_1's auc: 0.89113                                                                  \n",
      "[13000]\ttraining's auc: 0.922005\tvalid_1's auc: 0.892026                                                               \n",
      "[14000]\ttraining's auc: 0.923757\tvalid_1's auc: 0.892803                                                               \n",
      "[15000]\ttraining's auc: 0.925372\tvalid_1's auc: 0.893405                                                               \n",
      "[16000]\ttraining's auc: 0.926848\tvalid_1's auc: 0.893811                                                               \n",
      "[17000]\ttraining's auc: 0.928258\tvalid_1's auc: 0.894122                                                               \n",
      "[18000]\ttraining's auc: 0.929653\tvalid_1's auc: 0.894367                                                               \n",
      "[19000]\ttraining's auc: 0.930941\tvalid_1's auc: 0.894642                                                               \n",
      "[20000]\ttraining's auc: 0.932195\tvalid_1's auc: 0.894881                                                               \n",
      "[21000]\ttraining's auc: 0.933424\tvalid_1's auc: 0.89503                                                                \n",
      "[22000]\ttraining's auc: 0.934615\tvalid_1's auc: 0.895162                                                               \n",
      "[23000]\ttraining's auc: 0.935789\tvalid_1's auc: 0.895227                                                               \n",
      "[24000]\ttraining's auc: 0.936937\tvalid_1's auc: 0.895315                                                               \n",
      "[25000]\ttraining's auc: 0.93806\tvalid_1's auc: 0.895443                                                                \n",
      "[26000]\ttraining's auc: 0.939163\tvalid_1's auc: 0.895481                                                               \n",
      "[27000]\ttraining's auc: 0.940268\tvalid_1's auc: 0.895517                                                               \n",
      "[28000]\ttraining's auc: 0.941347\tvalid_1's auc: 0.895541                                                               \n",
      "[29000]\ttraining's auc: 0.942405\tvalid_1's auc: 0.895512                                                               \n",
      "[30000]\ttraining's auc: 0.943439\tvalid_1's auc: 0.895538                                                               \n",
      "[31000]\ttraining's auc: 0.944469\tvalid_1's auc: 0.895594                                                               \n",
      "[32000]\ttraining's auc: 0.945498\tvalid_1's auc: 0.895553                                                               \n",
      "[33000]\ttraining's auc: 0.946502\tvalid_1's auc: 0.895512                                                               \n",
      "[34000]\ttraining's auc: 0.947492\tvalid_1's auc: 0.895471                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31176]\ttraining's auc: 0.94465\tvalid_1's auc: 0.895615\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.909383\tvalid_1's auc: 0.876115                                                                \n",
      "[2000]\ttraining's auc: 0.933123\tvalid_1's auc: 0.890892                                                                \n",
      "[3000]\ttraining's auc: 0.945379\tvalid_1's auc: 0.894747                                                                \n",
      "[4000]\ttraining's auc: 0.954741\tvalid_1's auc: 0.895862                                                                \n",
      "[5000]\ttraining's auc: 0.962754\tvalid_1's auc: 0.896052                                                                \n",
      "[6000]\ttraining's auc: 0.969566\tvalid_1's auc: 0.895711                                                                \n",
      "[7000]\ttraining's auc: 0.975289\tvalid_1's auc: 0.89549                                                                 \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4563]\ttraining's auc: 0.959382\tvalid_1's auc: 0.896209\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.912197\tvalid_1's auc: 0.869702                                                                \n",
      "[2000]\ttraining's auc: 0.935643\tvalid_1's auc: 0.8842                                                                  \n",
      "[3000]\ttraining's auc: 0.947434\tvalid_1's auc: 0.888243                                                                \n",
      "[4000]\ttraining's auc: 0.956396\tvalid_1's auc: 0.889291                                                                \n",
      "[5000]\ttraining's auc: 0.964139\tvalid_1's auc: 0.889401                                                                \n",
      "[6000]\ttraining's auc: 0.970579\tvalid_1's auc: 0.889274                                                                \n",
      "[7000]\ttraining's auc: 0.976059\tvalid_1's auc: 0.888747                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4502]\ttraining's auc: 0.960399\tvalid_1's auc: 0.889608\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.910783\tvalid_1's auc: 0.874402                                                                \n",
      "[2000]\ttraining's auc: 0.933915\tvalid_1's auc: 0.888973                                                                \n",
      "[3000]\ttraining's auc: 0.945851\tvalid_1's auc: 0.893972                                                                \n",
      "[4000]\ttraining's auc: 0.954994\tvalid_1's auc: 0.895678                                                                \n",
      "[5000]\ttraining's auc: 0.962906\tvalid_1's auc: 0.896026                                                                \n",
      "[6000]\ttraining's auc: 0.969697\tvalid_1's auc: 0.896008                                                                \n",
      "[7000]\ttraining's auc: 0.975282\tvalid_1's auc: 0.895819                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4772]\ttraining's auc: 0.961223\tvalid_1's auc: 0.896074\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.911017\tvalid_1's auc: 0.872454                                                                \n",
      "[2000]\ttraining's auc: 0.934547\tvalid_1's auc: 0.886971                                                                \n",
      "[3000]\ttraining's auc: 0.946898\tvalid_1's auc: 0.89154                                                                 \n",
      "[4000]\ttraining's auc: 0.955988\tvalid_1's auc: 0.892957                                                                \n",
      "[5000]\ttraining's auc: 0.963679\tvalid_1's auc: 0.893533                                                                \n",
      "[6000]\ttraining's auc: 0.970209\tvalid_1's auc: 0.893504                                                                \n",
      "[7000]\ttraining's auc: 0.975672\tvalid_1's auc: 0.89348                                                                 \n",
      "[8000]\ttraining's auc: 0.980242\tvalid_1's auc: 0.893351                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5101]\ttraining's auc: 0.96437\tvalid_1's auc: 0.893661\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.820434\tvalid_1's auc: 0.805001                                                                \n",
      "[2000]\ttraining's auc: 0.846117\tvalid_1's auc: 0.829055                                                                \n",
      "[3000]\ttraining's auc: 0.865874\tvalid_1's auc: 0.847946                                                                \n",
      "[4000]\ttraining's auc: 0.879454\tvalid_1's auc: 0.85996                                                                 \n",
      "[5000]\ttraining's auc: 0.889426\tvalid_1's auc: 0.868384                                                                \n",
      "[6000]\ttraining's auc: 0.896754\tvalid_1's auc: 0.874449                                                                \n",
      "[7000]\ttraining's auc: 0.902653\tvalid_1's auc: 0.879102                                                                \n",
      "[8000]\ttraining's auc: 0.907509\tvalid_1's auc: 0.882856                                                                \n",
      "[9000]\ttraining's auc: 0.911469\tvalid_1's auc: 0.885777                                                                \n",
      "[10000]\ttraining's auc: 0.914904\tvalid_1's auc: 0.888144                                                               \n",
      "[11000]\ttraining's auc: 0.917841\tvalid_1's auc: 0.890105                                                               \n",
      "[12000]\ttraining's auc: 0.920465\tvalid_1's auc: 0.891779                                                               \n",
      "[13000]\ttraining's auc: 0.922795\tvalid_1's auc: 0.893077                                                               \n",
      "[14000]\ttraining's auc: 0.924884\tvalid_1's auc: 0.894168                                                               \n",
      "[15000]\ttraining's auc: 0.926785\tvalid_1's auc: 0.895102                                                               \n",
      "[16000]\ttraining's auc: 0.928513\tvalid_1's auc: 0.89587                                                                \n",
      "[17000]\ttraining's auc: 0.930116\tvalid_1's auc: 0.896443                                                               \n",
      "[18000]\ttraining's auc: 0.931646\tvalid_1's auc: 0.896949                                                               \n",
      "[19000]\ttraining's auc: 0.933037\tvalid_1's auc: 0.89742                                                                \n",
      "[20000]\ttraining's auc: 0.934411\tvalid_1's auc: 0.897739                                                               \n",
      "[21000]\ttraining's auc: 0.935721\tvalid_1's auc: 0.898054                                                               \n",
      "[22000]\ttraining's auc: 0.936957\tvalid_1's auc: 0.898297                                                               \n",
      "[23000]\ttraining's auc: 0.938197\tvalid_1's auc: 0.898427                                                               \n",
      "[24000]\ttraining's auc: 0.939392\tvalid_1's auc: 0.898556                                                               \n",
      "[25000]\ttraining's auc: 0.940565\tvalid_1's auc: 0.898659                                                               \n",
      "[26000]\ttraining's auc: 0.941687\tvalid_1's auc: 0.898728                                                               \n",
      "[27000]\ttraining's auc: 0.942786\tvalid_1's auc: 0.898815                                                               \n",
      "[28000]\ttraining's auc: 0.943899\tvalid_1's auc: 0.898851                                                               \n",
      "[29000]\ttraining's auc: 0.945001\tvalid_1's auc: 0.898888                                                               \n",
      "[30000]\ttraining's auc: 0.946079\tvalid_1's auc: 0.898865                                                               \n",
      "[31000]\ttraining's auc: 0.947128\tvalid_1's auc: 0.898917                                                               \n",
      "[32000]\ttraining's auc: 0.94816\tvalid_1's auc: 0.898869                                                                \n",
      "[33000]\ttraining's auc: 0.949182\tvalid_1's auc: 0.898862                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30442]\ttraining's auc: 0.94655\tvalid_1's auc: 0.898935\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.821071\tvalid_1's auc: 0.795302                                                                \n",
      "[2000]\ttraining's auc: 0.847497\tvalid_1's auc: 0.820594                                                                \n",
      "[3000]\ttraining's auc: 0.868058\tvalid_1's auc: 0.839811                                                                \n",
      "[4000]\ttraining's auc: 0.882169\tvalid_1's auc: 0.85247                                                                 \n",
      "[5000]\ttraining's auc: 0.892361\tvalid_1's auc: 0.86094                                                                 \n",
      "[6000]\ttraining's auc: 0.899943\tvalid_1's auc: 0.86723                                                                 \n",
      "[7000]\ttraining's auc: 0.905881\tvalid_1's auc: 0.872132                                                                \n",
      "[8000]\ttraining's auc: 0.910806\tvalid_1's auc: 0.875919                                                                \n",
      "[9000]\ttraining's auc: 0.914818\tvalid_1's auc: 0.878876                                                                \n",
      "[10000]\ttraining's auc: 0.918188\tvalid_1's auc: 0.881205                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11000]\ttraining's auc: 0.921128\tvalid_1's auc: 0.883014                                                               \n",
      "[12000]\ttraining's auc: 0.923653\tvalid_1's auc: 0.884611                                                               \n",
      "[13000]\ttraining's auc: 0.925973\tvalid_1's auc: 0.88597                                                                \n",
      "[14000]\ttraining's auc: 0.928021\tvalid_1's auc: 0.887001                                                               \n",
      "[15000]\ttraining's auc: 0.929931\tvalid_1's auc: 0.887881                                                               \n",
      "[16000]\ttraining's auc: 0.931653\tvalid_1's auc: 0.888688                                                               \n",
      "[17000]\ttraining's auc: 0.933243\tvalid_1's auc: 0.88931                                                                \n",
      "[18000]\ttraining's auc: 0.934669\tvalid_1's auc: 0.889782                                                               \n",
      "[19000]\ttraining's auc: 0.936048\tvalid_1's auc: 0.890212                                                               \n",
      "[20000]\ttraining's auc: 0.937359\tvalid_1's auc: 0.890567                                                               \n",
      "[21000]\ttraining's auc: 0.938635\tvalid_1's auc: 0.890845                                                               \n",
      "[22000]\ttraining's auc: 0.939837\tvalid_1's auc: 0.891072                                                               \n",
      "[23000]\ttraining's auc: 0.940987\tvalid_1's auc: 0.89124                                                                \n",
      "[24000]\ttraining's auc: 0.942117\tvalid_1's auc: 0.891292                                                               \n",
      "[25000]\ttraining's auc: 0.943197\tvalid_1's auc: 0.89142                                                                \n",
      "[26000]\ttraining's auc: 0.944295\tvalid_1's auc: 0.891539                                                               \n",
      "[27000]\ttraining's auc: 0.945367\tvalid_1's auc: 0.891663                                                               \n",
      "[28000]\ttraining's auc: 0.946414\tvalid_1's auc: 0.891738                                                               \n",
      "[29000]\ttraining's auc: 0.947457\tvalid_1's auc: 0.891801                                                               \n",
      "[30000]\ttraining's auc: 0.948447\tvalid_1's auc: 0.891856                                                               \n",
      "[31000]\ttraining's auc: 0.949453\tvalid_1's auc: 0.891836                                                               \n",
      "[32000]\ttraining's auc: 0.950426\tvalid_1's auc: 0.891812                                                               \n",
      "[33000]\ttraining's auc: 0.95139\tvalid_1's auc: 0.891781                                                                \n",
      "[34000]\ttraining's auc: 0.952336\tvalid_1's auc: 0.89182                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31377]\ttraining's auc: 0.949816\tvalid_1's auc: 0.891875\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.821469\tvalid_1's auc: 0.804707                                                                \n",
      "[2000]\ttraining's auc: 0.847083\tvalid_1's auc: 0.827578                                                                \n",
      "[3000]\ttraining's auc: 0.867279\tvalid_1's auc: 0.845857                                                                \n",
      "[4000]\ttraining's auc: 0.880608\tvalid_1's auc: 0.857772                                                                \n",
      "[5000]\ttraining's auc: 0.890272\tvalid_1's auc: 0.866094                                                                \n",
      "[6000]\ttraining's auc: 0.897943\tvalid_1's auc: 0.872463                                                                \n",
      "[7000]\ttraining's auc: 0.903874\tvalid_1's auc: 0.877375                                                                \n",
      "[8000]\ttraining's auc: 0.9087\tvalid_1's auc: 0.88117                                                                   \n",
      "[9000]\ttraining's auc: 0.912756\tvalid_1's auc: 0.884199                                                                \n",
      "[10000]\ttraining's auc: 0.916181\tvalid_1's auc: 0.886608                                                               \n",
      "[11000]\ttraining's auc: 0.919064\tvalid_1's auc: 0.888681                                                               \n",
      "[12000]\ttraining's auc: 0.921579\tvalid_1's auc: 0.890364                                                               \n",
      "[13000]\ttraining's auc: 0.92386\tvalid_1's auc: 0.891793                                                                \n",
      "[14000]\ttraining's auc: 0.925888\tvalid_1's auc: 0.893055                                                               \n",
      "[15000]\ttraining's auc: 0.927732\tvalid_1's auc: 0.894074                                                               \n",
      "[16000]\ttraining's auc: 0.929445\tvalid_1's auc: 0.894802                                                               \n",
      "[17000]\ttraining's auc: 0.930986\tvalid_1's auc: 0.895512                                                               \n",
      "[18000]\ttraining's auc: 0.93245\tvalid_1's auc: 0.896019                                                                \n",
      "[19000]\ttraining's auc: 0.933899\tvalid_1's auc: 0.896598                                                               \n",
      "[20000]\ttraining's auc: 0.935236\tvalid_1's auc: 0.89701                                                                \n",
      "[21000]\ttraining's auc: 0.936537\tvalid_1's auc: 0.897384                                                               \n",
      "[22000]\ttraining's auc: 0.937749\tvalid_1's auc: 0.897684                                                               \n",
      "[23000]\ttraining's auc: 0.938944\tvalid_1's auc: 0.897883                                                               \n",
      "[24000]\ttraining's auc: 0.940139\tvalid_1's auc: 0.898139                                                               \n",
      "[25000]\ttraining's auc: 0.941259\tvalid_1's auc: 0.898313                                                               \n",
      "[26000]\ttraining's auc: 0.942413\tvalid_1's auc: 0.898498                                                               \n",
      "[27000]\ttraining's auc: 0.943517\tvalid_1's auc: 0.898656                                                               \n",
      "[28000]\ttraining's auc: 0.944607\tvalid_1's auc: 0.898756                                                               \n",
      "[29000]\ttraining's auc: 0.945653\tvalid_1's auc: 0.898847                                                               \n",
      "[30000]\ttraining's auc: 0.946704\tvalid_1's auc: 0.898871                                                               \n",
      "[31000]\ttraining's auc: 0.947741\tvalid_1's auc: 0.898949                                                               \n",
      "[32000]\ttraining's auc: 0.948753\tvalid_1's auc: 0.898993                                                               \n",
      "[33000]\ttraining's auc: 0.949771\tvalid_1's auc: 0.89903                                                                \n",
      "[34000]\ttraining's auc: 0.950759\tvalid_1's auc: 0.899063                                                               \n",
      "[35000]\ttraining's auc: 0.95173\tvalid_1's auc: 0.899135                                                                \n",
      "[36000]\ttraining's auc: 0.952694\tvalid_1's auc: 0.899113                                                               \n",
      "[37000]\ttraining's auc: 0.953638\tvalid_1's auc: 0.899101                                                               \n",
      "[38000]\ttraining's auc: 0.954577\tvalid_1's auc: 0.899125                                                               \n",
      "[39000]\ttraining's auc: 0.955516\tvalid_1's auc: 0.899105                                                               \n",
      "[40000]\ttraining's auc: 0.956471\tvalid_1's auc: 0.89913                                                                \n",
      "[41000]\ttraining's auc: 0.957384\tvalid_1's auc: 0.89912                                                                \n",
      "[42000]\ttraining's auc: 0.958281\tvalid_1's auc: 0.89911                                                                \n",
      "[43000]\ttraining's auc: 0.959167\tvalid_1's auc: 0.899115                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40279]\ttraining's auc: 0.956722\tvalid_1's auc: 0.899158\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.820165\tvalid_1's auc: 0.804749                                                                \n",
      "[2000]\ttraining's auc: 0.847686\tvalid_1's auc: 0.829147                                                                \n",
      "[3000]\ttraining's auc: 0.868265\tvalid_1's auc: 0.846277                                                                \n",
      "[4000]\ttraining's auc: 0.88206\tvalid_1's auc: 0.857886                                                                 \n",
      "[5000]\ttraining's auc: 0.891764\tvalid_1's auc: 0.866042                                                                \n",
      "[6000]\ttraining's auc: 0.898989\tvalid_1's auc: 0.87168                                                                 \n",
      "[7000]\ttraining's auc: 0.904857\tvalid_1's auc: 0.876117                                                                \n",
      "[8000]\ttraining's auc: 0.909624\tvalid_1's auc: 0.879688                                                                \n",
      "[9000]\ttraining's auc: 0.913577\tvalid_1's auc: 0.882509                                                                \n",
      "[10000]\ttraining's auc: 0.917\tvalid_1's auc: 0.884923                                                                  \n",
      "[11000]\ttraining's auc: 0.919942\tvalid_1's auc: 0.886882                                                               \n",
      "[12000]\ttraining's auc: 0.922593\tvalid_1's auc: 0.88845                                                                \n",
      "[13000]\ttraining's auc: 0.924959\tvalid_1's auc: 0.889771                                                               \n",
      "[14000]\ttraining's auc: 0.927063\tvalid_1's auc: 0.890917                                                               \n",
      "[15000]\ttraining's auc: 0.928889\tvalid_1's auc: 0.891769                                                               \n",
      "[16000]\ttraining's auc: 0.930639\tvalid_1's auc: 0.892625                                                               \n",
      "[17000]\ttraining's auc: 0.932258\tvalid_1's auc: 0.893298                                                               \n",
      "[18000]\ttraining's auc: 0.933749\tvalid_1's auc: 0.893839                                                               \n",
      "[19000]\ttraining's auc: 0.935154\tvalid_1's auc: 0.894353                                                               \n",
      "[20000]\ttraining's auc: 0.936486\tvalid_1's auc: 0.894734                                                               \n",
      "[21000]\ttraining's auc: 0.937733\tvalid_1's auc: 0.89499                                                                \n",
      "[22000]\ttraining's auc: 0.938965\tvalid_1's auc: 0.895273                                                               \n",
      "[23000]\ttraining's auc: 0.940144\tvalid_1's auc: 0.895525                                                               \n",
      "[24000]\ttraining's auc: 0.941299\tvalid_1's auc: 0.895703                                                               \n",
      "[25000]\ttraining's auc: 0.94243\tvalid_1's auc: 0.895836                                                                \n",
      "[26000]\ttraining's auc: 0.943524\tvalid_1's auc: 0.895984                                                               \n",
      "[27000]\ttraining's auc: 0.944623\tvalid_1's auc: 0.896026                                                               \n",
      "[28000]\ttraining's auc: 0.945694\tvalid_1's auc: 0.896099                                                               \n",
      "[29000]\ttraining's auc: 0.946736\tvalid_1's auc: 0.896221                                                               \n",
      "[30000]\ttraining's auc: 0.947774\tvalid_1's auc: 0.896268                                                               \n",
      "[31000]\ttraining's auc: 0.948772\tvalid_1's auc: 0.896289                                                               \n",
      "[32000]\ttraining's auc: 0.94978\tvalid_1's auc: 0.896295                                                                \n",
      "[33000]\ttraining's auc: 0.950747\tvalid_1's auc: 0.896323                                                               \n",
      "[34000]\ttraining's auc: 0.951724\tvalid_1's auc: 0.896315                                                               \n",
      "[35000]\ttraining's auc: 0.952679\tvalid_1's auc: 0.896283                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32719]\ttraining's auc: 0.950476\tvalid_1's auc: 0.896345\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.828571\tvalid_1's auc: 0.81315                                                                 \n",
      "[2000]\ttraining's auc: 0.862329\tvalid_1's auc: 0.844856                                                                \n",
      "[3000]\ttraining's auc: 0.880307\tvalid_1's auc: 0.860787                                                                \n",
      "[4000]\ttraining's auc: 0.891486\tvalid_1's auc: 0.870754                                                                \n",
      "[5000]\ttraining's auc: 0.899513\tvalid_1's auc: 0.877415                                                                \n",
      "[6000]\ttraining's auc: 0.905558\tvalid_1's auc: 0.882179                                                                \n",
      "[7000]\ttraining's auc: 0.910043\tvalid_1's auc: 0.885463                                                                \n",
      "[8000]\ttraining's auc: 0.913946\tvalid_1's auc: 0.888147                                                                \n",
      "[9000]\ttraining's auc: 0.91712\tvalid_1's auc: 0.890089                                                                 \n",
      "[10000]\ttraining's auc: 0.919539\tvalid_1's auc: 0.891606                                                               \n",
      "[11000]\ttraining's auc: 0.921818\tvalid_1's auc: 0.893023                                                               \n",
      "[12000]\ttraining's auc: 0.92388\tvalid_1's auc: 0.893974                                                                \n",
      "[13000]\ttraining's auc: 0.925621\tvalid_1's auc: 0.894629                                                               \n",
      "[14000]\ttraining's auc: 0.927248\tvalid_1's auc: 0.8953                                                                 \n",
      "[15000]\ttraining's auc: 0.928787\tvalid_1's auc: 0.895721                                                               \n",
      "[16000]\ttraining's auc: 0.930222\tvalid_1's auc: 0.896061                                                               \n",
      "[17000]\ttraining's auc: 0.931612\tvalid_1's auc: 0.896139                                                               \n",
      "[18000]\ttraining's auc: 0.932877\tvalid_1's auc: 0.896462                                                               \n",
      "[19000]\ttraining's auc: 0.934158\tvalid_1's auc: 0.896525                                                               \n",
      "[20000]\ttraining's auc: 0.93537\tvalid_1's auc: 0.896602                                                                \n",
      "[21000]\ttraining's auc: 0.936564\tvalid_1's auc: 0.896686                                                               \n",
      "[22000]\ttraining's auc: 0.93767\tvalid_1's auc: 0.896612                                                                \n",
      "[23000]\ttraining's auc: 0.938774\tvalid_1's auc: 0.896537                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20718]\ttraining's auc: 0.936226\tvalid_1's auc: 0.896765\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's auc: 0.830767\tvalid_1's auc: 0.807658                                                                \n",
      "[2000]\ttraining's auc: 0.864549\tvalid_1's auc: 0.838958                                                                \n",
      "[3000]\ttraining's auc: 0.883339\tvalid_1's auc: 0.855472                                                                \n",
      "[4000]\ttraining's auc: 0.894767\tvalid_1's auc: 0.86517                                                                 \n",
      "[5000]\ttraining's auc: 0.902675\tvalid_1's auc: 0.871533                                                                \n",
      "[6000]\ttraining's auc: 0.908777\tvalid_1's auc: 0.876131                                                                \n",
      "[7000]\ttraining's auc: 0.913583\tvalid_1's auc: 0.879106                                                                \n",
      "[8000]\ttraining's auc: 0.917201\tvalid_1's auc: 0.881762                                                                \n",
      "[9000]\ttraining's auc: 0.9203\tvalid_1's auc: 0.883485                                                                  \n",
      "[10000]\ttraining's auc: 0.922936\tvalid_1's auc: 0.884873                                                               \n",
      "[11000]\ttraining's auc: 0.925125\tvalid_1's auc: 0.88618                                                                \n",
      "[12000]\ttraining's auc: 0.927076\tvalid_1's auc: 0.886963                                                               \n",
      "[13000]\ttraining's auc: 0.928815\tvalid_1's auc: 0.887567                                                               \n",
      "[14000]\ttraining's auc: 0.930403\tvalid_1's auc: 0.888043                                                               \n",
      "[15000]\ttraining's auc: 0.931807\tvalid_1's auc: 0.888326                                                               \n",
      "[16000]\ttraining's auc: 0.933199\tvalid_1's auc: 0.888645                                                               \n",
      "[17000]\ttraining's auc: 0.934482\tvalid_1's auc: 0.888974                                                               \n",
      "[18000]\ttraining's auc: 0.935714\tvalid_1's auc: 0.889189                                                               \n",
      "[19000]\ttraining's auc: 0.936902\tvalid_1's auc: 0.889393                                                               \n",
      "[20000]\ttraining's auc: 0.93807\tvalid_1's auc: 0.88951                                                                 \n",
      "[21000]\ttraining's auc: 0.939195\tvalid_1's auc: 0.889606                                                               \n",
      "[22000]\ttraining's auc: 0.940267\tvalid_1's auc: 0.889576                                                               \n",
      "[23000]\ttraining's auc: 0.941298\tvalid_1's auc: 0.889527                                                               \n",
      "[24000]\ttraining's auc: 0.942321\tvalid_1's auc: 0.889329                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21188]\ttraining's auc: 0.93941\tvalid_1's auc: 0.889659\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.8277\tvalid_1's auc: 0.809768                                                                  \n",
      "[2000]\ttraining's auc: 0.863194\tvalid_1's auc: 0.84322                                                                 \n",
      "[3000]\ttraining's auc: 0.881615\tvalid_1's auc: 0.859965                                                                \n",
      "[4000]\ttraining's auc: 0.892889\tvalid_1's auc: 0.869987                                                                \n",
      "[5000]\ttraining's auc: 0.900899\tvalid_1's auc: 0.876616                                                                \n",
      "[6000]\ttraining's auc: 0.906853\tvalid_1's auc: 0.881287                                                                \n",
      "[7000]\ttraining's auc: 0.911547\tvalid_1's auc: 0.884697                                                                \n",
      "[8000]\ttraining's auc: 0.915013\tvalid_1's auc: 0.886961                                                                \n",
      "[9000]\ttraining's auc: 0.917961\tvalid_1's auc: 0.889017                                                                \n",
      "[10000]\ttraining's auc: 0.920397\tvalid_1's auc: 0.890711                                                               \n",
      "[11000]\ttraining's auc: 0.922619\tvalid_1's auc: 0.892046                                                               \n",
      "[12000]\ttraining's auc: 0.924523\tvalid_1's auc: 0.893139                                                               \n",
      "[13000]\ttraining's auc: 0.926269\tvalid_1's auc: 0.894031                                                               \n",
      "[14000]\ttraining's auc: 0.927861\tvalid_1's auc: 0.894672                                                               \n",
      "[15000]\ttraining's auc: 0.929369\tvalid_1's auc: 0.895233                                                               \n",
      "[16000]\ttraining's auc: 0.93077\tvalid_1's auc: 0.895751                                                                \n",
      "[17000]\ttraining's auc: 0.932078\tvalid_1's auc: 0.896136                                                               \n",
      "[18000]\ttraining's auc: 0.933337\tvalid_1's auc: 0.896455                                                               \n",
      "[19000]\ttraining's auc: 0.934556\tvalid_1's auc: 0.896683                                                               \n",
      "[20000]\ttraining's auc: 0.935734\tvalid_1's auc: 0.896926                                                               \n",
      "[21000]\ttraining's auc: 0.936926\tvalid_1's auc: 0.897086                                                               \n",
      "[22000]\ttraining's auc: 0.938002\tvalid_1's auc: 0.897136                                                               \n",
      "[23000]\ttraining's auc: 0.939093\tvalid_1's auc: 0.897238                                                               \n",
      "[24000]\ttraining's auc: 0.940178\tvalid_1's auc: 0.897279                                                               \n",
      "[25000]\ttraining's auc: 0.941217\tvalid_1's auc: 0.897192                                                               \n",
      "[26000]\ttraining's auc: 0.942244\tvalid_1's auc: 0.897148                                                               \n",
      "[27000]\ttraining's auc: 0.943258\tvalid_1's auc: 0.897009                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24003]\ttraining's auc: 0.940181\tvalid_1's auc: 0.897279\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.829564\tvalid_1's auc: 0.81245                                                                 \n",
      "[2000]\ttraining's auc: 0.864583\tvalid_1's auc: 0.843425                                                                \n",
      "[3000]\ttraining's auc: 0.882213\tvalid_1's auc: 0.858641                                                                \n",
      "[4000]\ttraining's auc: 0.893469\tvalid_1's auc: 0.868368                                                                \n",
      "[5000]\ttraining's auc: 0.901324\tvalid_1's auc: 0.8747                                                                  \n",
      "[6000]\ttraining's auc: 0.906961\tvalid_1's auc: 0.878794                                                                \n",
      "[7000]\ttraining's auc: 0.911721\tvalid_1's auc: 0.882134                                                                \n",
      "[8000]\ttraining's auc: 0.915432\tvalid_1's auc: 0.884652                                                                \n",
      "[9000]\ttraining's auc: 0.918546\tvalid_1's auc: 0.886675                                                                \n",
      "[10000]\ttraining's auc: 0.921339\tvalid_1's auc: 0.888677                                                               \n",
      "[11000]\ttraining's auc: 0.923643\tvalid_1's auc: 0.889881                                                               \n",
      "[12000]\ttraining's auc: 0.925577\tvalid_1's auc: 0.890983                                                               \n",
      "[13000]\ttraining's auc: 0.92746\tvalid_1's auc: 0.891744                                                                \n",
      "[14000]\ttraining's auc: 0.929157\tvalid_1's auc: 0.892332                                                               \n",
      "[15000]\ttraining's auc: 0.930686\tvalid_1's auc: 0.892835                                                               \n",
      "[16000]\ttraining's auc: 0.932121\tvalid_1's auc: 0.893257                                                               \n",
      "[17000]\ttraining's auc: 0.933498\tvalid_1's auc: 0.893695                                                               \n",
      "[18000]\ttraining's auc: 0.934824\tvalid_1's auc: 0.894005                                                               \n",
      "[19000]\ttraining's auc: 0.936028\tvalid_1's auc: 0.894233                                                               \n",
      "[20000]\ttraining's auc: 0.937234\tvalid_1's auc: 0.894295                                                               \n",
      "[21000]\ttraining's auc: 0.938337\tvalid_1's auc: 0.894342                                                               \n",
      "[22000]\ttraining's auc: 0.939432\tvalid_1's auc: 0.894366                                                               \n",
      "[23000]\ttraining's auc: 0.94048\tvalid_1's auc: 0.894418                                                                \n",
      "[24000]\ttraining's auc: 0.941507\tvalid_1's auc: 0.894454                                                               \n",
      "[25000]\ttraining's auc: 0.94254\tvalid_1's auc: 0.894473                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[22605]\ttraining's auc: 0.940074\tvalid_1's auc: 0.894503\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.910684\tvalid_1's auc: 0.884018                                                                \n",
      "[2000]\ttraining's auc: 0.929625\tvalid_1's auc: 0.892606                                                                \n",
      "[3000]\ttraining's auc: 0.941094\tvalid_1's auc: 0.894418                                                                \n",
      "[4000]\ttraining's auc: 0.950614\tvalid_1's auc: 0.89415                                                                 \n",
      "[5000]\ttraining's auc: 0.958798\tvalid_1's auc: 0.893622                                                                \n",
      "[6000]\ttraining's auc: 0.96579\tvalid_1's auc: 0.89312                                                                  \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3117]\ttraining's auc: 0.942304\tvalid_1's auc: 0.894561\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.913956\tvalid_1's auc: 0.878144                                                                \n",
      "[2000]\ttraining's auc: 0.932596\tvalid_1's auc: 0.887157                                                                \n",
      "[3000]\ttraining's auc: 0.943477\tvalid_1's auc: 0.887363                                                                \n",
      "[4000]\ttraining's auc: 0.952612\tvalid_1's auc: 0.88736                                                                 \n",
      "[5000]\ttraining's auc: 0.960535\tvalid_1's auc: 0.887233                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[2628]\ttraining's auc: 0.939722\tvalid_1's auc: 0.887984\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.911691\tvalid_1's auc: 0.882986                                                                \n",
      "[2000]\ttraining's auc: 0.93046\tvalid_1's auc: 0.893511                                                                 \n",
      "[3000]\ttraining's auc: 0.941392\tvalid_1's auc: 0.894837                                                                \n",
      "[4000]\ttraining's auc: 0.950852\tvalid_1's auc: 0.895192                                                                \n",
      "[5000]\ttraining's auc: 0.95892\tvalid_1's auc: 0.894658                                                                 \n",
      "[6000]\ttraining's auc: 0.965857\tvalid_1's auc: 0.894088                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3966]\ttraining's auc: 0.950497\tvalid_1's auc: 0.895313\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.91247\tvalid_1's auc: 0.880863                                                                 \n",
      "[2000]\ttraining's auc: 0.93141\tvalid_1's auc: 0.890394                                                                 \n",
      "[3000]\ttraining's auc: 0.942271\tvalid_1's auc: 0.892254                                                                \n",
      "[4000]\ttraining's auc: 0.951478\tvalid_1's auc: 0.892622                                                                \n",
      "[5000]\ttraining's auc: 0.959565\tvalid_1's auc: 0.892596                                                                \n",
      "[6000]\ttraining's auc: 0.966322\tvalid_1's auc: 0.891727                                                                \n",
      "[7000]\ttraining's auc: 0.971925\tvalid_1's auc: 0.891629                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4803]\ttraining's auc: 0.958043\tvalid_1's auc: 0.892788\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.800998\tvalid_1's auc: 0.788982                                                                \n",
      "[2000]\ttraining's auc: 0.836294\tvalid_1's auc: 0.822558                                                                \n",
      "[3000]\ttraining's auc: 0.85637\tvalid_1's auc: 0.841215                                                                 \n",
      "[4000]\ttraining's auc: 0.869359\tvalid_1's auc: 0.853203                                                                \n",
      "[5000]\ttraining's auc: 0.879011\tvalid_1's auc: 0.861752                                                                \n",
      "[6000]\ttraining's auc: 0.886443\tvalid_1's auc: 0.868176                                                                \n",
      "[7000]\ttraining's auc: 0.892298\tvalid_1's auc: 0.87298                                                                 \n",
      "[8000]\ttraining's auc: 0.897062\tvalid_1's auc: 0.876975                                                                \n",
      "[9000]\ttraining's auc: 0.900836\tvalid_1's auc: 0.879959                                                                \n",
      "[10000]\ttraining's auc: 0.904008\tvalid_1's auc: 0.882331                                                               \n",
      "[11000]\ttraining's auc: 0.906851\tvalid_1's auc: 0.884572                                                               \n",
      "[12000]\ttraining's auc: 0.909302\tvalid_1's auc: 0.886428                                                               \n",
      "[13000]\ttraining's auc: 0.911476\tvalid_1's auc: 0.888034                                                               \n",
      "[14000]\ttraining's auc: 0.913453\tvalid_1's auc: 0.889524                                                               \n",
      "[15000]\ttraining's auc: 0.915278\tvalid_1's auc: 0.890837                                                               \n",
      "[16000]\ttraining's auc: 0.916883\tvalid_1's auc: 0.891782                                                               \n",
      "[17000]\ttraining's auc: 0.918332\tvalid_1's auc: 0.892662                                                               \n",
      "[18000]\ttraining's auc: 0.919697\tvalid_1's auc: 0.89341                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19000]\ttraining's auc: 0.920929\tvalid_1's auc: 0.894085                                                               \n",
      "[20000]\ttraining's auc: 0.922101\tvalid_1's auc: 0.894629                                                               \n",
      "[21000]\ttraining's auc: 0.923153\tvalid_1's auc: 0.895028                                                               \n",
      "[22000]\ttraining's auc: 0.924178\tvalid_1's auc: 0.895456                                                               \n",
      "[23000]\ttraining's auc: 0.925151\tvalid_1's auc: 0.89578                                                                \n",
      "[24000]\ttraining's auc: 0.926056\tvalid_1's auc: 0.895994                                                               \n",
      "[25000]\ttraining's auc: 0.926946\tvalid_1's auc: 0.896236                                                               \n",
      "[26000]\ttraining's auc: 0.927796\tvalid_1's auc: 0.89639                                                                \n",
      "[27000]\ttraining's auc: 0.928626\tvalid_1's auc: 0.896534                                                               \n",
      "[28000]\ttraining's auc: 0.929427\tvalid_1's auc: 0.896688                                                               \n",
      "[29000]\ttraining's auc: 0.930199\tvalid_1's auc: 0.896749                                                               \n",
      "[30000]\ttraining's auc: 0.930971\tvalid_1's auc: 0.896786                                                               \n",
      "[31000]\ttraining's auc: 0.931688\tvalid_1's auc: 0.896882                                                               \n",
      "[32000]\ttraining's auc: 0.932434\tvalid_1's auc: 0.896882                                                               \n",
      "[33000]\ttraining's auc: 0.933096\tvalid_1's auc: 0.896925                                                               \n",
      "[34000]\ttraining's auc: 0.933802\tvalid_1's auc: 0.896914                                                               \n",
      "[35000]\ttraining's auc: 0.93447\tvalid_1's auc: 0.89695                                                                 \n",
      "[36000]\ttraining's auc: 0.935169\tvalid_1's auc: 0.897013                                                               \n",
      "[37000]\ttraining's auc: 0.935847\tvalid_1's auc: 0.89697                                                                \n",
      "[38000]\ttraining's auc: 0.936512\tvalid_1's auc: 0.896989                                                               \n",
      "[39000]\ttraining's auc: 0.937151\tvalid_1's auc: 0.897031                                                               \n",
      "[40000]\ttraining's auc: 0.937809\tvalid_1's auc: 0.89696                                                                \n",
      "[41000]\ttraining's auc: 0.938455\tvalid_1's auc: 0.89684                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38624]\ttraining's auc: 0.93692\tvalid_1's auc: 0.89708\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.800517\tvalid_1's auc: 0.778866                                                                \n",
      "[2000]\ttraining's auc: 0.838446\tvalid_1's auc: 0.815782                                                                \n",
      "[3000]\ttraining's auc: 0.858407\tvalid_1's auc: 0.834679                                                                \n",
      "[4000]\ttraining's auc: 0.871828\tvalid_1's auc: 0.847078                                                                \n",
      "[5000]\ttraining's auc: 0.881819\tvalid_1's auc: 0.855763                                                                \n",
      "[6000]\ttraining's auc: 0.889505\tvalid_1's auc: 0.862182                                                                \n",
      "[7000]\ttraining's auc: 0.895353\tvalid_1's auc: 0.866832                                                                \n",
      "[8000]\ttraining's auc: 0.900293\tvalid_1's auc: 0.870912                                                                \n",
      "[9000]\ttraining's auc: 0.904225\tvalid_1's auc: 0.873981                                                                \n",
      "[10000]\ttraining's auc: 0.907609\tvalid_1's auc: 0.8765                                                                 \n",
      "[11000]\ttraining's auc: 0.910422\tvalid_1's auc: 0.878867                                                               \n",
      "[12000]\ttraining's auc: 0.913024\tvalid_1's auc: 0.880728                                                               \n",
      "[13000]\ttraining's auc: 0.915184\tvalid_1's auc: 0.882192                                                               \n",
      "[14000]\ttraining's auc: 0.91712\tvalid_1's auc: 0.883416                                                                \n",
      "[15000]\ttraining's auc: 0.918862\tvalid_1's auc: 0.884545                                                               \n",
      "[16000]\ttraining's auc: 0.920478\tvalid_1's auc: 0.885577                                                               \n",
      "[17000]\ttraining's auc: 0.921835\tvalid_1's auc: 0.886284                                                               \n",
      "[18000]\ttraining's auc: 0.923155\tvalid_1's auc: 0.886885                                                               \n",
      "[19000]\ttraining's auc: 0.92445\tvalid_1's auc: 0.887452                                                                \n",
      "[20000]\ttraining's auc: 0.925559\tvalid_1's auc: 0.88798                                                                \n",
      "[21000]\ttraining's auc: 0.92656\tvalid_1's auc: 0.888349                                                                \n",
      "[22000]\ttraining's auc: 0.927534\tvalid_1's auc: 0.888717                                                               \n",
      "[23000]\ttraining's auc: 0.928475\tvalid_1's auc: 0.889057                                                               \n",
      "[24000]\ttraining's auc: 0.929334\tvalid_1's auc: 0.889263                                                               \n",
      "[25000]\ttraining's auc: 0.930181\tvalid_1's auc: 0.889479                                                               \n",
      "[26000]\ttraining's auc: 0.930976\tvalid_1's auc: 0.889644                                                               \n",
      "[27000]\ttraining's auc: 0.931747\tvalid_1's auc: 0.889757                                                               \n",
      "[28000]\ttraining's auc: 0.932514\tvalid_1's auc: 0.8899                                                                 \n",
      "[29000]\ttraining's auc: 0.933243\tvalid_1's auc: 0.889837                                                               \n",
      "[30000]\ttraining's auc: 0.933954\tvalid_1's auc: 0.889759                                                               \n",
      "[31000]\ttraining's auc: 0.934653\tvalid_1's auc: 0.889849                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28030]\ttraining's auc: 0.932535\tvalid_1's auc: 0.88991\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.799173\tvalid_1's auc: 0.78312                                                                 \n",
      "[2000]\ttraining's auc: 0.837332\tvalid_1's auc: 0.820756                                                                \n",
      "[3000]\ttraining's auc: 0.857444\tvalid_1's auc: 0.839346                                                                \n",
      "[4000]\ttraining's auc: 0.869779\tvalid_1's auc: 0.851258                                                                \n",
      "[5000]\ttraining's auc: 0.879727\tvalid_1's auc: 0.860119                                                                \n",
      "[6000]\ttraining's auc: 0.887301\tvalid_1's auc: 0.866752                                                                \n",
      "[7000]\ttraining's auc: 0.8934\tvalid_1's auc: 0.872011                                                                  \n",
      "[8000]\ttraining's auc: 0.898184\tvalid_1's auc: 0.875988                                                                \n",
      "[9000]\ttraining's auc: 0.902071\tvalid_1's auc: 0.879402                                                                \n",
      "[10000]\ttraining's auc: 0.905301\tvalid_1's auc: 0.881764                                                               \n",
      "[11000]\ttraining's auc: 0.908184\tvalid_1's auc: 0.884025                                                               \n",
      "[12000]\ttraining's auc: 0.910719\tvalid_1's auc: 0.885856                                                               \n",
      "[13000]\ttraining's auc: 0.912865\tvalid_1's auc: 0.887456                                                               \n",
      "[14000]\ttraining's auc: 0.914655\tvalid_1's auc: 0.888564                                                               \n",
      "[15000]\ttraining's auc: 0.916375\tvalid_1's auc: 0.889794                                                               \n",
      "[16000]\ttraining's auc: 0.917886\tvalid_1's auc: 0.890877                                                               \n",
      "[17000]\ttraining's auc: 0.919225\tvalid_1's auc: 0.891741                                                               \n",
      "[18000]\ttraining's auc: 0.920586\tvalid_1's auc: 0.892603                                                               \n",
      "[19000]\ttraining's auc: 0.921767\tvalid_1's auc: 0.893368                                                               \n",
      "[20000]\ttraining's auc: 0.922901\tvalid_1's auc: 0.894                                                                  \n",
      "[21000]\ttraining's auc: 0.923989\tvalid_1's auc: 0.894617                                                               \n",
      "[22000]\ttraining's auc: 0.924907\tvalid_1's auc: 0.895025                                                               \n",
      "[23000]\ttraining's auc: 0.925874\tvalid_1's auc: 0.895437                                                               \n",
      "[24000]\ttraining's auc: 0.92678\tvalid_1's auc: 0.895809                                                                \n",
      "[25000]\ttraining's auc: 0.927674\tvalid_1's auc: 0.896089                                                               \n",
      "[26000]\ttraining's auc: 0.928529\tvalid_1's auc: 0.896376                                                               \n",
      "[27000]\ttraining's auc: 0.929318\tvalid_1's auc: 0.896551                                                               \n",
      "[28000]\ttraining's auc: 0.930085\tvalid_1's auc: 0.896822                                                               \n",
      "[29000]\ttraining's auc: 0.930832\tvalid_1's auc: 0.896897                                                               \n",
      "[30000]\ttraining's auc: 0.931572\tvalid_1's auc: 0.897088                                                               \n",
      "[31000]\ttraining's auc: 0.932288\tvalid_1's auc: 0.897263                                                               \n",
      "[32000]\ttraining's auc: 0.933\tvalid_1's auc: 0.897354                                                                  \n",
      "[33000]\ttraining's auc: 0.9337\tvalid_1's auc: 0.897428                                                                 \n",
      "[34000]\ttraining's auc: 0.934391\tvalid_1's auc: 0.897462                                                               \n",
      "[35000]\ttraining's auc: 0.935057\tvalid_1's auc: 0.897525                                                               \n",
      "[36000]\ttraining's auc: 0.935719\tvalid_1's auc: 0.897623                                                               \n",
      "[37000]\ttraining's auc: 0.936342\tvalid_1's auc: 0.897646                                                               \n",
      "[38000]\ttraining's auc: 0.936972\tvalid_1's auc: 0.897632                                                               \n",
      "[39000]\ttraining's auc: 0.937618\tvalid_1's auc: 0.897626                                                               \n",
      "[40000]\ttraining's auc: 0.938239\tvalid_1's auc: 0.897613                                                               \n",
      "[41000]\ttraining's auc: 0.938845\tvalid_1's auc: 0.897602                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38185]\ttraining's auc: 0.937098\tvalid_1's auc: 0.897674\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.800506\tvalid_1's auc: 0.787288                                                                \n",
      "[2000]\ttraining's auc: 0.838082\tvalid_1's auc: 0.820921                                                                \n",
      "[3000]\ttraining's auc: 0.858911\tvalid_1's auc: 0.839613                                                                \n",
      "[4000]\ttraining's auc: 0.871867\tvalid_1's auc: 0.851142                                                                \n",
      "[5000]\ttraining's auc: 0.880877\tvalid_1's auc: 0.858991                                                                \n",
      "[6000]\ttraining's auc: 0.887912\tvalid_1's auc: 0.864796                                                                \n",
      "[7000]\ttraining's auc: 0.893654\tvalid_1's auc: 0.869759                                                                \n",
      "[8000]\ttraining's auc: 0.898305\tvalid_1's auc: 0.873632                                                                \n",
      "[9000]\ttraining's auc: 0.902089\tvalid_1's auc: 0.876719                                                                \n",
      "[10000]\ttraining's auc: 0.905407\tvalid_1's auc: 0.879365                                                               \n",
      "[11000]\ttraining's auc: 0.908198\tvalid_1's auc: 0.881417                                                               \n",
      "[12000]\ttraining's auc: 0.91076\tvalid_1's auc: 0.883293                                                                \n",
      "[13000]\ttraining's auc: 0.913092\tvalid_1's auc: 0.884795                                                               \n",
      "[14000]\ttraining's auc: 0.9151\tvalid_1's auc: 0.886238                                                                 \n",
      "[15000]\ttraining's auc: 0.916937\tvalid_1's auc: 0.887386                                                               \n",
      "[16000]\ttraining's auc: 0.918621\tvalid_1's auc: 0.88851                                                                \n",
      "[17000]\ttraining's auc: 0.920123\tvalid_1's auc: 0.889557                                                               \n",
      "[18000]\ttraining's auc: 0.921504\tvalid_1's auc: 0.890348                                                               \n",
      "[19000]\ttraining's auc: 0.922805\tvalid_1's auc: 0.891113                                                               \n",
      "[20000]\ttraining's auc: 0.923978\tvalid_1's auc: 0.891658                                                               \n",
      "[21000]\ttraining's auc: 0.925051\tvalid_1's auc: 0.892061                                                               \n",
      "[22000]\ttraining's auc: 0.926043\tvalid_1's auc: 0.892386                                                               \n",
      "[23000]\ttraining's auc: 0.927043\tvalid_1's auc: 0.89277                                                                \n",
      "[24000]\ttraining's auc: 0.927952\tvalid_1's auc: 0.893159                                                               \n",
      "[25000]\ttraining's auc: 0.928853\tvalid_1's auc: 0.893491                                                               \n",
      "[26000]\ttraining's auc: 0.929676\tvalid_1's auc: 0.89376                                                                \n",
      "[27000]\ttraining's auc: 0.930505\tvalid_1's auc: 0.893967                                                               \n",
      "[28000]\ttraining's auc: 0.931298\tvalid_1's auc: 0.894304                                                               \n",
      "[29000]\ttraining's auc: 0.932056\tvalid_1's auc: 0.894489                                                               \n",
      "[30000]\ttraining's auc: 0.932804\tvalid_1's auc: 0.894595                                                               \n",
      "[31000]\ttraining's auc: 0.933538\tvalid_1's auc: 0.894655                                                               \n",
      "[32000]\ttraining's auc: 0.934251\tvalid_1's auc: 0.894715                                                               \n",
      "[33000]\ttraining's auc: 0.93493\tvalid_1's auc: 0.894732                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34000]\ttraining's auc: 0.935609\tvalid_1's auc: 0.894826                                                               \n",
      "[35000]\ttraining's auc: 0.936275\tvalid_1's auc: 0.894823                                                               \n",
      "[36000]\ttraining's auc: 0.936883\tvalid_1's auc: 0.894868                                                               \n",
      "[37000]\ttraining's auc: 0.937531\tvalid_1's auc: 0.89491                                                                \n",
      "[38000]\ttraining's auc: 0.938154\tvalid_1's auc: 0.894918                                                               \n",
      "[39000]\ttraining's auc: 0.938781\tvalid_1's auc: 0.894918                                                               \n",
      "[40000]\ttraining's auc: 0.939397\tvalid_1's auc: 0.894866                                                               \n",
      "[41000]\ttraining's auc: 0.94002\tvalid_1's auc: 0.894799                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38563]\ttraining's auc: 0.938525\tvalid_1's auc: 0.894961\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.811197\tvalid_1's auc: 0.797202                                                                \n",
      "[2000]\ttraining's auc: 0.842691\tvalid_1's auc: 0.827325                                                                \n",
      "[3000]\ttraining's auc: 0.863267\tvalid_1's auc: 0.846505                                                                \n",
      "[4000]\ttraining's auc: 0.87675\tvalid_1's auc: 0.858757                                                                 \n",
      "[5000]\ttraining's auc: 0.886256\tvalid_1's auc: 0.867021                                                                \n",
      "[6000]\ttraining's auc: 0.893481\tvalid_1's auc: 0.873183                                                                \n",
      "[7000]\ttraining's auc: 0.899433\tvalid_1's auc: 0.877931                                                                \n",
      "[8000]\ttraining's auc: 0.90411\tvalid_1's auc: 0.881716                                                                 \n",
      "[9000]\ttraining's auc: 0.907869\tvalid_1's auc: 0.88448                                                                 \n",
      "[10000]\ttraining's auc: 0.911043\tvalid_1's auc: 0.886859                                                               \n",
      "[11000]\ttraining's auc: 0.913749\tvalid_1's auc: 0.888763                                                               \n",
      "[12000]\ttraining's auc: 0.916129\tvalid_1's auc: 0.890419                                                               \n",
      "[13000]\ttraining's auc: 0.918242\tvalid_1's auc: 0.891748                                                               \n",
      "[14000]\ttraining's auc: 0.92022\tvalid_1's auc: 0.89297                                                                 \n",
      "[15000]\ttraining's auc: 0.922011\tvalid_1's auc: 0.893927                                                               \n",
      "[16000]\ttraining's auc: 0.923584\tvalid_1's auc: 0.894729                                                               \n",
      "[17000]\ttraining's auc: 0.92506\tvalid_1's auc: 0.895468                                                                \n",
      "[18000]\ttraining's auc: 0.926437\tvalid_1's auc: 0.896055                                                               \n",
      "[19000]\ttraining's auc: 0.927717\tvalid_1's auc: 0.896549                                                               \n",
      "[20000]\ttraining's auc: 0.928958\tvalid_1's auc: 0.89699                                                                \n",
      "[21000]\ttraining's auc: 0.930114\tvalid_1's auc: 0.897295                                                               \n",
      "[22000]\ttraining's auc: 0.931239\tvalid_1's auc: 0.897562                                                               \n",
      "[23000]\ttraining's auc: 0.932339\tvalid_1's auc: 0.897722                                                               \n",
      "[24000]\ttraining's auc: 0.933394\tvalid_1's auc: 0.897916                                                               \n",
      "[25000]\ttraining's auc: 0.934437\tvalid_1's auc: 0.898046                                                               \n",
      "[26000]\ttraining's auc: 0.935455\tvalid_1's auc: 0.898133                                                               \n",
      "[27000]\ttraining's auc: 0.936468\tvalid_1's auc: 0.898227                                                               \n",
      "[28000]\ttraining's auc: 0.937475\tvalid_1's auc: 0.898266                                                               \n",
      "[29000]\ttraining's auc: 0.938468\tvalid_1's auc: 0.898294                                                               \n",
      "[30000]\ttraining's auc: 0.939429\tvalid_1's auc: 0.898291                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27624]\ttraining's auc: 0.937107\tvalid_1's auc: 0.898321\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.812713\tvalid_1's auc: 0.788541                                                                \n",
      "[2000]\ttraining's auc: 0.843859\tvalid_1's auc: 0.818082                                                                \n",
      "[3000]\ttraining's auc: 0.865689\tvalid_1's auc: 0.838692                                                                \n",
      "[4000]\ttraining's auc: 0.879498\tvalid_1's auc: 0.851385                                                                \n",
      "[5000]\ttraining's auc: 0.889316\tvalid_1's auc: 0.859831                                                                \n",
      "[6000]\ttraining's auc: 0.896753\tvalid_1's auc: 0.866026                                                                \n",
      "[7000]\ttraining's auc: 0.902472\tvalid_1's auc: 0.870654                                                                \n",
      "[8000]\ttraining's auc: 0.90725\tvalid_1's auc: 0.874474                                                                 \n",
      "[9000]\ttraining's auc: 0.911097\tvalid_1's auc: 0.877315                                                                \n",
      "[10000]\ttraining's auc: 0.914382\tvalid_1's auc: 0.879802                                                               \n",
      "[11000]\ttraining's auc: 0.917157\tvalid_1's auc: 0.881826                                                               \n",
      "[12000]\ttraining's auc: 0.919618\tvalid_1's auc: 0.88342                                                                \n",
      "[13000]\ttraining's auc: 0.92171\tvalid_1's auc: 0.884758                                                                \n",
      "[14000]\ttraining's auc: 0.923595\tvalid_1's auc: 0.885751                                                               \n",
      "[15000]\ttraining's auc: 0.925315\tvalid_1's auc: 0.886701                                                               \n",
      "[16000]\ttraining's auc: 0.926883\tvalid_1's auc: 0.887494                                                               \n",
      "[17000]\ttraining's auc: 0.928298\tvalid_1's auc: 0.888098                                                               \n",
      "[18000]\ttraining's auc: 0.929628\tvalid_1's auc: 0.888687                                                               \n",
      "[19000]\ttraining's auc: 0.930942\tvalid_1's auc: 0.889135                                                               \n",
      "[20000]\ttraining's auc: 0.932121\tvalid_1's auc: 0.889593                                                               \n",
      "[21000]\ttraining's auc: 0.933247\tvalid_1's auc: 0.889911                                                               \n",
      "[22000]\ttraining's auc: 0.934311\tvalid_1's auc: 0.890111                                                               \n",
      "[23000]\ttraining's auc: 0.935352\tvalid_1's auc: 0.890356                                                               \n",
      "[24000]\ttraining's auc: 0.936384\tvalid_1's auc: 0.890526                                                               \n",
      "[25000]\ttraining's auc: 0.937378\tvalid_1's auc: 0.890672                                                               \n",
      "[26000]\ttraining's auc: 0.938341\tvalid_1's auc: 0.890742                                                               \n",
      "[27000]\ttraining's auc: 0.939318\tvalid_1's auc: 0.890873                                                               \n",
      "[28000]\ttraining's auc: 0.940245\tvalid_1's auc: 0.890929                                                               \n",
      "[29000]\ttraining's auc: 0.941176\tvalid_1's auc: 0.890954                                                               \n",
      "[30000]\ttraining's auc: 0.942124\tvalid_1's auc: 0.89095                                                                \n",
      "[31000]\ttraining's auc: 0.943034\tvalid_1's auc: 0.890962                                                               \n",
      "[32000]\ttraining's auc: 0.943918\tvalid_1's auc: 0.890983                                                               \n",
      "[33000]\ttraining's auc: 0.944801\tvalid_1's auc: 0.891004                                                               \n",
      "[34000]\ttraining's auc: 0.945672\tvalid_1's auc: 0.890969                                                               \n",
      "[35000]\ttraining's auc: 0.946534\tvalid_1's auc: 0.890969                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[32751]\ttraining's auc: 0.94458\tvalid_1's auc: 0.891018\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.812153\tvalid_1's auc: 0.7962                                                                  \n",
      "[2000]\ttraining's auc: 0.843966\tvalid_1's auc: 0.825785                                                                \n",
      "[3000]\ttraining's auc: 0.86475\tvalid_1's auc: 0.844865                                                                 \n",
      "[4000]\ttraining's auc: 0.877916\tvalid_1's auc: 0.857002                                                                \n",
      "[5000]\ttraining's auc: 0.88758\tvalid_1's auc: 0.865697                                                                 \n",
      "[6000]\ttraining's auc: 0.894838\tvalid_1's auc: 0.871782                                                                \n",
      "[7000]\ttraining's auc: 0.900587\tvalid_1's auc: 0.876641                                                                \n",
      "[8000]\ttraining's auc: 0.905293\tvalid_1's auc: 0.880493                                                                \n",
      "[9000]\ttraining's auc: 0.909132\tvalid_1's auc: 0.883606                                                                \n",
      "[10000]\ttraining's auc: 0.912281\tvalid_1's auc: 0.885899                                                               \n",
      "[11000]\ttraining's auc: 0.914967\tvalid_1's auc: 0.887931                                                               \n",
      "[12000]\ttraining's auc: 0.917422\tvalid_1's auc: 0.889585                                                               \n",
      "[13000]\ttraining's auc: 0.919529\tvalid_1's auc: 0.890932                                                               \n",
      "[14000]\ttraining's auc: 0.921369\tvalid_1's auc: 0.892137                                                               \n",
      "[15000]\ttraining's auc: 0.923074\tvalid_1's auc: 0.89314                                                                \n",
      "[16000]\ttraining's auc: 0.924622\tvalid_1's auc: 0.894081                                                               \n",
      "[17000]\ttraining's auc: 0.925979\tvalid_1's auc: 0.894855                                                               \n",
      "[18000]\ttraining's auc: 0.927344\tvalid_1's auc: 0.895445                                                               \n",
      "[19000]\ttraining's auc: 0.928557\tvalid_1's auc: 0.896074                                                               \n",
      "[20000]\ttraining's auc: 0.929804\tvalid_1's auc: 0.896594                                                               \n",
      "[21000]\ttraining's auc: 0.930979\tvalid_1's auc: 0.897026                                                               \n",
      "[22000]\ttraining's auc: 0.932085\tvalid_1's auc: 0.897398                                                               \n",
      "[23000]\ttraining's auc: 0.933173\tvalid_1's auc: 0.89773                                                                \n",
      "[24000]\ttraining's auc: 0.934244\tvalid_1's auc: 0.897967                                                               \n",
      "[25000]\ttraining's auc: 0.935265\tvalid_1's auc: 0.898172                                                               \n",
      "[26000]\ttraining's auc: 0.936282\tvalid_1's auc: 0.898338                                                               \n",
      "[27000]\ttraining's auc: 0.937272\tvalid_1's auc: 0.898504                                                               \n",
      "[28000]\ttraining's auc: 0.938237\tvalid_1's auc: 0.898616                                                               \n",
      "[29000]\ttraining's auc: 0.939202\tvalid_1's auc: 0.898692                                                               \n",
      "[30000]\ttraining's auc: 0.940159\tvalid_1's auc: 0.898805                                                               \n",
      "[31000]\ttraining's auc: 0.941099\tvalid_1's auc: 0.898941                                                               \n",
      "[32000]\ttraining's auc: 0.942027\tvalid_1's auc: 0.898977                                                               \n",
      "[33000]\ttraining's auc: 0.942962\tvalid_1's auc: 0.899011                                                               \n",
      "[34000]\ttraining's auc: 0.943864\tvalid_1's auc: 0.899056                                                               \n",
      "[35000]\ttraining's auc: 0.944744\tvalid_1's auc: 0.899085                                                               \n",
      "[36000]\ttraining's auc: 0.945609\tvalid_1's auc: 0.899093                                                               \n",
      "[37000]\ttraining's auc: 0.946478\tvalid_1's auc: 0.899182                                                               \n",
      "[38000]\ttraining's auc: 0.947333\tvalid_1's auc: 0.89917                                                                \n",
      "[39000]\ttraining's auc: 0.948178\tvalid_1's auc: 0.899108                                                               \n",
      "[40000]\ttraining's auc: 0.949015\tvalid_1's auc: 0.899112                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37000]\ttraining's auc: 0.946478\tvalid_1's auc: 0.899182\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.811438\tvalid_1's auc: 0.797426                                                                \n",
      "[2000]\ttraining's auc: 0.844261\tvalid_1's auc: 0.826197                                                                \n",
      "[3000]\ttraining's auc: 0.865661\tvalid_1's auc: 0.84468                                                                 \n",
      "[4000]\ttraining's auc: 0.879315\tvalid_1's auc: 0.856491                                                                \n",
      "[5000]\ttraining's auc: 0.888626\tvalid_1's auc: 0.864557                                                                \n",
      "[6000]\ttraining's auc: 0.895669\tvalid_1's auc: 0.87034                                                                 \n",
      "[7000]\ttraining's auc: 0.901244\tvalid_1's auc: 0.874801                                                                \n",
      "[8000]\ttraining's auc: 0.905754\tvalid_1's auc: 0.878289                                                                \n",
      "[9000]\ttraining's auc: 0.909538\tvalid_1's auc: 0.881075                                                                \n",
      "[10000]\ttraining's auc: 0.912862\tvalid_1's auc: 0.88352                                                                \n",
      "[11000]\ttraining's auc: 0.915643\tvalid_1's auc: 0.885414                                                               \n",
      "[12000]\ttraining's auc: 0.918117\tvalid_1's auc: 0.887009                                                               \n",
      "[13000]\ttraining's auc: 0.920349\tvalid_1's auc: 0.888472                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14000]\ttraining's auc: 0.922309\tvalid_1's auc: 0.889621                                                               \n",
      "[15000]\ttraining's auc: 0.924091\tvalid_1's auc: 0.890723                                                               \n",
      "[16000]\ttraining's auc: 0.925685\tvalid_1's auc: 0.891593                                                               \n",
      "[17000]\ttraining's auc: 0.927144\tvalid_1's auc: 0.892341                                                               \n",
      "[18000]\ttraining's auc: 0.928545\tvalid_1's auc: 0.893006                                                               \n",
      "[19000]\ttraining's auc: 0.929864\tvalid_1's auc: 0.893605                                                               \n",
      "[20000]\ttraining's auc: 0.931086\tvalid_1's auc: 0.894021                                                               \n",
      "[21000]\ttraining's auc: 0.932235\tvalid_1's auc: 0.894403                                                               \n",
      "[22000]\ttraining's auc: 0.93333\tvalid_1's auc: 0.894717                                                                \n",
      "[23000]\ttraining's auc: 0.934417\tvalid_1's auc: 0.895029                                                               \n",
      "[24000]\ttraining's auc: 0.935487\tvalid_1's auc: 0.895258                                                               \n",
      "[25000]\ttraining's auc: 0.936518\tvalid_1's auc: 0.895527                                                               \n",
      "[26000]\ttraining's auc: 0.937501\tvalid_1's auc: 0.895687                                                               \n",
      "[27000]\ttraining's auc: 0.938472\tvalid_1's auc: 0.89582                                                                \n",
      "[28000]\ttraining's auc: 0.939459\tvalid_1's auc: 0.895966                                                               \n",
      "[29000]\ttraining's auc: 0.940395\tvalid_1's auc: 0.896097                                                               \n",
      "[30000]\ttraining's auc: 0.941344\tvalid_1's auc: 0.896174                                                               \n",
      "[31000]\ttraining's auc: 0.94228\tvalid_1's auc: 0.89621                                                                 \n",
      "[32000]\ttraining's auc: 0.943194\tvalid_1's auc: 0.896241                                                               \n",
      "[33000]\ttraining's auc: 0.944101\tvalid_1's auc: 0.896295                                                               \n",
      "[34000]\ttraining's auc: 0.944952\tvalid_1's auc: 0.896305                                                               \n",
      "[35000]\ttraining's auc: 0.945822\tvalid_1's auc: 0.896321                                                               \n",
      "[36000]\ttraining's auc: 0.946654\tvalid_1's auc: 0.896325                                                               \n",
      "[37000]\ttraining's auc: 0.947497\tvalid_1's auc: 0.896306                                                               \n",
      "[38000]\ttraining's auc: 0.948336\tvalid_1's auc: 0.896349                                                               \n",
      "[39000]\ttraining's auc: 0.94916\tvalid_1's auc: 0.896328                                                                \n",
      "[40000]\ttraining's auc: 0.949973\tvalid_1's auc: 0.8963                                                                 \n",
      "[41000]\ttraining's auc: 0.950778\tvalid_1's auc: 0.89631                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38539]\ttraining's auc: 0.948794\tvalid_1's auc: 0.896361\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.890351\tvalid_1's auc: 0.871106                                                                \n",
      "[2000]\ttraining's auc: 0.914465\tvalid_1's auc: 0.889619                                                                \n",
      "[3000]\ttraining's auc: 0.925376\tvalid_1's auc: 0.89537                                                                 \n",
      "[4000]\ttraining's auc: 0.932582\tvalid_1's auc: 0.897783                                                                \n",
      "[5000]\ttraining's auc: 0.938422\tvalid_1's auc: 0.897921                                                                \n",
      "[6000]\ttraining's auc: 0.943866\tvalid_1's auc: 0.897994                                                                \n",
      "[7000]\ttraining's auc: 0.94887\tvalid_1's auc: 0.897487                                                                 \n",
      "[8000]\ttraining's auc: 0.95363\tvalid_1's auc: 0.89713                                                                  \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5928]\ttraining's auc: 0.943478\tvalid_1's auc: 0.898025\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.892708\tvalid_1's auc: 0.862938                                                                \n",
      "[2000]\ttraining's auc: 0.917718\tvalid_1's auc: 0.881659                                                                \n",
      "[3000]\ttraining's auc: 0.928436\tvalid_1's auc: 0.887964                                                                \n",
      "[4000]\ttraining's auc: 0.935411\tvalid_1's auc: 0.890343                                                                \n",
      "[5000]\ttraining's auc: 0.941044\tvalid_1's auc: 0.890798                                                                \n",
      "[6000]\ttraining's auc: 0.946339\tvalid_1's auc: 0.890744                                                                \n",
      "[7000]\ttraining's auc: 0.951059\tvalid_1's auc: 0.890644                                                                \n",
      "[8000]\ttraining's auc: 0.955643\tvalid_1's auc: 0.89014                                                                 \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5406]\ttraining's auc: 0.943248\tvalid_1's auc: 0.89098\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.891669\tvalid_1's auc: 0.868775                                                                \n",
      "[2000]\ttraining's auc: 0.915735\tvalid_1's auc: 0.888314                                                                \n",
      "[3000]\ttraining's auc: 0.926303\tvalid_1's auc: 0.894765                                                                \n",
      "[4000]\ttraining's auc: 0.933449\tvalid_1's auc: 0.897358                                                                \n",
      "[5000]\ttraining's auc: 0.939026\tvalid_1's auc: 0.898229                                                                \n",
      "[6000]\ttraining's auc: 0.944377\tvalid_1's auc: 0.898604                                                                \n",
      "[7000]\ttraining's auc: 0.949524\tvalid_1's auc: 0.898721                                                                \n",
      "[8000]\ttraining's auc: 0.954158\tvalid_1's auc: 0.89869                                                                 \n",
      "[9000]\ttraining's auc: 0.958634\tvalid_1's auc: 0.898018                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6910]\ttraining's auc: 0.94904\tvalid_1's auc: 0.898828\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.892109\tvalid_1's auc: 0.867441                                                                \n",
      "[2000]\ttraining's auc: 0.916149\tvalid_1's auc: 0.885746                                                                \n",
      "[3000]\ttraining's auc: 0.927176\tvalid_1's auc: 0.891788                                                                \n",
      "[4000]\ttraining's auc: 0.934323\tvalid_1's auc: 0.893936                                                                \n",
      "[5000]\ttraining's auc: 0.939947\tvalid_1's auc: 0.894756                                                                \n",
      "[6000]\ttraining's auc: 0.945285\tvalid_1's auc: 0.894969                                                                \n",
      "[7000]\ttraining's auc: 0.950215\tvalid_1's auc: 0.894789                                                                \n",
      "[8000]\ttraining's auc: 0.954745\tvalid_1's auc: 0.894463                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5515]\ttraining's auc: 0.942676\tvalid_1's auc: 0.895278\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.889245\tvalid_1's auc: 0.868719                                                                \n",
      "[2000]\ttraining's auc: 0.914743\tvalid_1's auc: 0.888513                                                                \n",
      "[3000]\ttraining's auc: 0.926547\tvalid_1's auc: 0.895193                                                                \n",
      "[4000]\ttraining's auc: 0.934117\tvalid_1's auc: 0.897759                                                                \n",
      "[5000]\ttraining's auc: 0.940214\tvalid_1's auc: 0.898503                                                                \n",
      "[6000]\ttraining's auc: 0.945718\tvalid_1's auc: 0.898383                                                                \n",
      "[7000]\ttraining's auc: 0.950931\tvalid_1's auc: 0.897878                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4699]\ttraining's auc: 0.938457\tvalid_1's auc: 0.898652\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.892487\tvalid_1's auc: 0.861265                                                                \n",
      "[2000]\ttraining's auc: 0.917909\tvalid_1's auc: 0.880569                                                                \n",
      "[3000]\ttraining's auc: 0.929618\tvalid_1's auc: 0.8876                                                                  \n",
      "[4000]\ttraining's auc: 0.936872\tvalid_1's auc: 0.89059                                                                 \n",
      "[5000]\ttraining's auc: 0.942643\tvalid_1's auc: 0.891111                                                                \n",
      "[6000]\ttraining's auc: 0.947905\tvalid_1's auc: 0.891355                                                                \n",
      "[7000]\ttraining's auc: 0.952757\tvalid_1's auc: 0.891178                                                                \n",
      "[8000]\ttraining's auc: 0.957342\tvalid_1's auc: 0.890502                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5403]\ttraining's auc: 0.944869\tvalid_1's auc: 0.891469\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.890509\tvalid_1's auc: 0.866924                                                                \n",
      "[2000]\ttraining's auc: 0.915831\tvalid_1's auc: 0.88717                                                                 \n",
      "[3000]\ttraining's auc: 0.927311\tvalid_1's auc: 0.894241                                                                \n",
      "[4000]\ttraining's auc: 0.934854\tvalid_1's auc: 0.896937                                                                \n",
      "[5000]\ttraining's auc: 0.9408\tvalid_1's auc: 0.89806                                                                   \n",
      "[6000]\ttraining's auc: 0.946147\tvalid_1's auc: 0.898472                                                                \n",
      "[7000]\ttraining's auc: 0.951219\tvalid_1's auc: 0.898469                                                                \n",
      "[8000]\ttraining's auc: 0.956056\tvalid_1's auc: 0.898267                                                                \n",
      "[9000]\ttraining's auc: 0.960649\tvalid_1's auc: 0.898043                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6643]\ttraining's auc: 0.949381\tvalid_1's auc: 0.898673\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.891932\tvalid_1's auc: 0.865636                                                                \n",
      "[2000]\ttraining's auc: 0.916811\tvalid_1's auc: 0.884614                                                                \n",
      "[3000]\ttraining's auc: 0.928586\tvalid_1's auc: 0.891716                                                                \n",
      "[4000]\ttraining's auc: 0.936118\tvalid_1's auc: 0.89471                                                                 \n",
      "[5000]\ttraining's auc: 0.942169\tvalid_1's auc: 0.895659                                                                \n",
      "[6000]\ttraining's auc: 0.94743\tvalid_1's auc: 0.895585                                                                 \n",
      "[7000]\ttraining's auc: 0.952369\tvalid_1's auc: 0.895396                                                                \n",
      "[8000]\ttraining's auc: 0.957029\tvalid_1's auc: 0.895117                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5249]\ttraining's auc: 0.94348\tvalid_1's auc: 0.895762\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.903567\tvalid_1's auc: 0.878642                                                                \n",
      "[2000]\ttraining's auc: 0.926522\tvalid_1's auc: 0.893549                                                                \n",
      "[3000]\ttraining's auc: 0.937437\tvalid_1's auc: 0.89764                                                                 \n",
      "[4000]\ttraining's auc: 0.945741\tvalid_1's auc: 0.898537                                                                \n",
      "[5000]\ttraining's auc: 0.953013\tvalid_1's auc: 0.897973                                                                \n",
      "[6000]\ttraining's auc: 0.959754\tvalid_1's auc: 0.897405                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3818]\ttraining's auc: 0.944402\tvalid_1's auc: 0.898569\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.907356\tvalid_1's auc: 0.871721                                                                \n",
      "[2000]\ttraining's auc: 0.929786\tvalid_1's auc: 0.886718                                                                \n",
      "[3000]\ttraining's auc: 0.940299\tvalid_1's auc: 0.890018                                                                \n",
      "[4000]\ttraining's auc: 0.948115\tvalid_1's auc: 0.890726                                                                \n",
      "[5000]\ttraining's auc: 0.955074\tvalid_1's auc: 0.890285                                                                \n",
      "[6000]\ttraining's auc: 0.961509\tvalid_1's auc: 0.889599                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3990]\ttraining's auc: 0.948062\tvalid_1's auc: 0.890766\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.905004\tvalid_1's auc: 0.87688                                                                 \n",
      "[2000]\ttraining's auc: 0.927178\tvalid_1's auc: 0.892716                                                                \n",
      "[3000]\ttraining's auc: 0.937951\tvalid_1's auc: 0.896594                                                                \n",
      "[4000]\ttraining's auc: 0.946141\tvalid_1's auc: 0.897588                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttraining's auc: 0.953281\tvalid_1's auc: 0.898069                                                                \n",
      "[6000]\ttraining's auc: 0.959973\tvalid_1's auc: 0.897882                                                                \n",
      "[7000]\ttraining's auc: 0.965881\tvalid_1's auc: 0.897966                                                                \n",
      "[8000]\ttraining's auc: 0.971241\tvalid_1's auc: 0.897466                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5395]\ttraining's auc: 0.956006\tvalid_1's auc: 0.898351\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.906026\tvalid_1's auc: 0.87524                                                                 \n",
      "[2000]\ttraining's auc: 0.928253\tvalid_1's auc: 0.889305                                                                \n",
      "[3000]\ttraining's auc: 0.939104\tvalid_1's auc: 0.893434                                                                \n",
      "[4000]\ttraining's auc: 0.947223\tvalid_1's auc: 0.894845                                                                \n",
      "[5000]\ttraining's auc: 0.954365\tvalid_1's auc: 0.894765                                                                \n",
      "[6000]\ttraining's auc: 0.960697\tvalid_1's auc: 0.894525                                                                \n",
      "[7000]\ttraining's auc: 0.966587\tvalid_1's auc: 0.894127                                                                \n",
      "[8000]\ttraining's auc: 0.971813\tvalid_1's auc: 0.893805                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5323]\ttraining's auc: 0.956469\tvalid_1's auc: 0.895106\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.873628\tvalid_1's auc: 0.854281                                                                \n",
      "[2000]\ttraining's auc: 0.903559\tvalid_1's auc: 0.879364                                                                \n",
      "[3000]\ttraining's auc: 0.917559\tvalid_1's auc: 0.889699                                                                \n",
      "[4000]\ttraining's auc: 0.92587\tvalid_1's auc: 0.894319                                                                 \n",
      "[5000]\ttraining's auc: 0.931777\tvalid_1's auc: 0.896542                                                                \n",
      "[6000]\ttraining's auc: 0.936799\tvalid_1's auc: 0.897563                                                                \n",
      "[7000]\ttraining's auc: 0.941175\tvalid_1's auc: 0.89822                                                                 \n",
      "[8000]\ttraining's auc: 0.94527\tvalid_1's auc: 0.89846                                                                  \n",
      "[9000]\ttraining's auc: 0.949149\tvalid_1's auc: 0.898459                                                                \n",
      "[10000]\ttraining's auc: 0.952813\tvalid_1's auc: 0.898319                                                               \n",
      "[11000]\ttraining's auc: 0.956285\tvalid_1's auc: 0.898121                                                               \n",
      "[12000]\ttraining's auc: 0.959632\tvalid_1's auc: 0.897769                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9100]\ttraining's auc: 0.949534\tvalid_1's auc: 0.898512\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.876714\tvalid_1's auc: 0.846603                                                                \n",
      "[2000]\ttraining's auc: 0.907248\tvalid_1's auc: 0.871777                                                                \n",
      "[3000]\ttraining's auc: 0.920859\tvalid_1's auc: 0.882338                                                                \n",
      "[4000]\ttraining's auc: 0.929075\tvalid_1's auc: 0.886912                                                                \n",
      "[5000]\ttraining's auc: 0.93484\tvalid_1's auc: 0.889352                                                                 \n",
      "[6000]\ttraining's auc: 0.939525\tvalid_1's auc: 0.890441                                                                \n",
      "[7000]\ttraining's auc: 0.94365\tvalid_1's auc: 0.890888                                                                 \n",
      "[8000]\ttraining's auc: 0.947523\tvalid_1's auc: 0.891115                                                                \n",
      "[9000]\ttraining's auc: 0.951218\tvalid_1's auc: 0.890966                                                                \n",
      "[10000]\ttraining's auc: 0.954651\tvalid_1's auc: 0.890869                                                               \n",
      "[11000]\ttraining's auc: 0.958027\tvalid_1's auc: 0.890702                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8311]\ttraining's auc: 0.948677\tvalid_1's auc: 0.891177\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.875894\tvalid_1's auc: 0.852772                                                                \n",
      "[2000]\ttraining's auc: 0.904962\tvalid_1's auc: 0.878033                                                                \n",
      "[3000]\ttraining's auc: 0.918713\tvalid_1's auc: 0.888107                                                                \n",
      "[4000]\ttraining's auc: 0.926801\tvalid_1's auc: 0.893258                                                                \n",
      "[5000]\ttraining's auc: 0.932728\tvalid_1's auc: 0.895963                                                                \n",
      "[6000]\ttraining's auc: 0.937519\tvalid_1's auc: 0.897494                                                                \n",
      "[7000]\ttraining's auc: 0.941741\tvalid_1's auc: 0.89828                                                                 \n",
      "[8000]\ttraining's auc: 0.945756\tvalid_1's auc: 0.898741                                                                \n",
      "[9000]\ttraining's auc: 0.949593\tvalid_1's auc: 0.89876                                                                 \n",
      "[10000]\ttraining's auc: 0.953227\tvalid_1's auc: 0.898801                                                               \n",
      "[11000]\ttraining's auc: 0.95668\tvalid_1's auc: 0.898794                                                                \n",
      "[12000]\ttraining's auc: 0.959976\tvalid_1's auc: 0.898802                                                               \n",
      "[13000]\ttraining's auc: 0.963057\tvalid_1's auc: 0.898799                                                               \n",
      "[14000]\ttraining's auc: 0.966036\tvalid_1's auc: 0.898729                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11480]\ttraining's auc: 0.958291\tvalid_1's auc: 0.898895\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.877374\tvalid_1's auc: 0.852631                                                                \n",
      "[2000]\ttraining's auc: 0.905899\tvalid_1's auc: 0.875318                                                                \n",
      "[3000]\ttraining's auc: 0.919778\tvalid_1's auc: 0.885434                                                                \n",
      "[4000]\ttraining's auc: 0.928228\tvalid_1's auc: 0.890365                                                                \n",
      "[5000]\ttraining's auc: 0.934196\tvalid_1's auc: 0.892911                                                                \n",
      "[6000]\ttraining's auc: 0.938874\tvalid_1's auc: 0.894116                                                                \n",
      "[7000]\ttraining's auc: 0.943073\tvalid_1's auc: 0.894674                                                                \n",
      "[8000]\ttraining's auc: 0.946931\tvalid_1's auc: 0.894978                                                                \n",
      "[9000]\ttraining's auc: 0.950661\tvalid_1's auc: 0.895068                                                                \n",
      "[10000]\ttraining's auc: 0.954074\tvalid_1's auc: 0.895135                                                               \n",
      "[11000]\ttraining's auc: 0.957406\tvalid_1's auc: 0.895126                                                               \n",
      "[12000]\ttraining's auc: 0.960656\tvalid_1's auc: 0.894953                                                               \n",
      "[13000]\ttraining's auc: 0.963669\tvalid_1's auc: 0.894931                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10070]\ttraining's auc: 0.954303\tvalid_1's auc: 0.895178\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.893122\tvalid_1's auc: 0.875191                                                                \n",
      "[2000]\ttraining's auc: 0.914972\tvalid_1's auc: 0.89114                                                                 \n",
      "[3000]\ttraining's auc: 0.925386\tvalid_1's auc: 0.895826                                                                \n",
      "[4000]\ttraining's auc: 0.932461\tvalid_1's auc: 0.897442                                                                \n",
      "[5000]\ttraining's auc: 0.938394\tvalid_1's auc: 0.897337                                                                \n",
      "[6000]\ttraining's auc: 0.943789\tvalid_1's auc: 0.897589                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[3880]\ttraining's auc: 0.931751\tvalid_1's auc: 0.897675\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.895908\tvalid_1's auc: 0.866134                                                                \n",
      "[2000]\ttraining's auc: 0.918763\tvalid_1's auc: 0.883524                                                                \n",
      "[3000]\ttraining's auc: 0.928778\tvalid_1's auc: 0.888871                                                                \n",
      "[4000]\ttraining's auc: 0.935547\tvalid_1's auc: 0.890458                                                                \n",
      "[5000]\ttraining's auc: 0.941264\tvalid_1's auc: 0.891001                                                                \n",
      "[6000]\ttraining's auc: 0.946486\tvalid_1's auc: 0.890699                                                                \n",
      "[7000]\ttraining's auc: 0.951333\tvalid_1's auc: 0.890411                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4924]\ttraining's auc: 0.940856\tvalid_1's auc: 0.891165\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.894508\tvalid_1's auc: 0.873392                                                                \n",
      "[2000]\ttraining's auc: 0.916504\tvalid_1's auc: 0.890678                                                                \n",
      "[3000]\ttraining's auc: 0.926595\tvalid_1's auc: 0.896157                                                                \n",
      "[4000]\ttraining's auc: 0.933592\tvalid_1's auc: 0.897957                                                                \n",
      "[5000]\ttraining's auc: 0.939327\tvalid_1's auc: 0.898705                                                                \n",
      "[6000]\ttraining's auc: 0.944674\tvalid_1's auc: 0.899065                                                                \n",
      "[7000]\ttraining's auc: 0.949715\tvalid_1's auc: 0.899204                                                                \n",
      "[8000]\ttraining's auc: 0.954425\tvalid_1's auc: 0.899064                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5618]\ttraining's auc: 0.942584\tvalid_1's auc: 0.899294\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.895288\tvalid_1's auc: 0.871981                                                                \n",
      "[2000]\ttraining's auc: 0.917446\tvalid_1's auc: 0.888077                                                                \n",
      "[3000]\ttraining's auc: 0.927663\tvalid_1's auc: 0.893362                                                                \n",
      "[4000]\ttraining's auc: 0.934591\tvalid_1's auc: 0.894653                                                                \n",
      "[5000]\ttraining's auc: 0.940289\tvalid_1's auc: 0.895042                                                                \n",
      "[6000]\ttraining's auc: 0.945638\tvalid_1's auc: 0.89478                                                                 \n",
      "[7000]\ttraining's auc: 0.950697\tvalid_1's auc: 0.894589                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4755]\ttraining's auc: 0.938991\tvalid_1's auc: 0.895208\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.888937\tvalid_1's auc: 0.86856                                                                 \n",
      "[2000]\ttraining's auc: 0.913432\tvalid_1's auc: 0.887759                                                                \n",
      "[3000]\ttraining's auc: 0.924033\tvalid_1's auc: 0.89425                                                                 \n",
      "[4000]\ttraining's auc: 0.930762\tvalid_1's auc: 0.897022                                                                \n",
      "[5000]\ttraining's auc: 0.935764\tvalid_1's auc: 0.89793                                                                 \n",
      "[6000]\ttraining's auc: 0.940223\tvalid_1's auc: 0.898117                                                                \n",
      "[7000]\ttraining's auc: 0.944537\tvalid_1's auc: 0.897967                                                                \n",
      "[8000]\ttraining's auc: 0.948714\tvalid_1's auc: 0.897567                                                                \n",
      "[9000]\ttraining's auc: 0.952614\tvalid_1's auc: 0.896979                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6422]\ttraining's auc: 0.942034\tvalid_1's auc: 0.898284\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.890981\tvalid_1's auc: 0.859567                                                                \n",
      "[2000]\ttraining's auc: 0.916861\tvalid_1's auc: 0.879795                                                                \n",
      "[3000]\ttraining's auc: 0.927602\tvalid_1's auc: 0.887024                                                                \n",
      "[4000]\ttraining's auc: 0.934256\tvalid_1's auc: 0.890039                                                                \n",
      "[5000]\ttraining's auc: 0.939151\tvalid_1's auc: 0.890675                                                                \n",
      "[6000]\ttraining's auc: 0.94341\tvalid_1's auc: 0.890445                                                                 \n",
      "[7000]\ttraining's auc: 0.947509\tvalid_1's auc: 0.890583                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[4911]\ttraining's auc: 0.938803\tvalid_1's auc: 0.890736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.889229\tvalid_1's auc: 0.866074                                                                \n",
      "[2000]\ttraining's auc: 0.914301\tvalid_1's auc: 0.886695                                                                \n",
      "[3000]\ttraining's auc: 0.925227\tvalid_1's auc: 0.893641                                                                \n",
      "[4000]\ttraining's auc: 0.931903\tvalid_1's auc: 0.896613                                                                \n",
      "[5000]\ttraining's auc: 0.936642\tvalid_1's auc: 0.897867                                                                \n",
      "[6000]\ttraining's auc: 0.941234\tvalid_1's auc: 0.898485                                                                \n",
      "[7000]\ttraining's auc: 0.945439\tvalid_1's auc: 0.898482                                                                \n",
      "[8000]\ttraining's auc: 0.949488\tvalid_1's auc: 0.898303                                                                \n",
      "[9000]\ttraining's auc: 0.953325\tvalid_1's auc: 0.897911                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6058]\ttraining's auc: 0.941468\tvalid_1's auc: 0.898583\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.890418\tvalid_1's auc: 0.865251                                                                \n",
      "[2000]\ttraining's auc: 0.915275\tvalid_1's auc: 0.88457                                                                 \n",
      "[3000]\ttraining's auc: 0.926484\tvalid_1's auc: 0.890809                                                                \n",
      "[4000]\ttraining's auc: 0.932971\tvalid_1's auc: 0.89304                                                                 \n",
      "[5000]\ttraining's auc: 0.937852\tvalid_1's auc: 0.894104                                                                \n",
      "[6000]\ttraining's auc: 0.942336\tvalid_1's auc: 0.894573                                                                \n",
      "[7000]\ttraining's auc: 0.946527\tvalid_1's auc: 0.894503                                                                \n",
      "[8000]\ttraining's auc: 0.950616\tvalid_1's auc: 0.894377                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5996]\ttraining's auc: 0.942321\tvalid_1's auc: 0.894574\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.820011\tvalid_1's auc: 0.806062                                                                \n",
      "[2000]\ttraining's auc: 0.849215\tvalid_1's auc: 0.832743                                                                \n",
      "[3000]\ttraining's auc: 0.869073\tvalid_1's auc: 0.851559                                                                \n",
      "[4000]\ttraining's auc: 0.882437\tvalid_1's auc: 0.863636                                                                \n",
      "[5000]\ttraining's auc: 0.891925\tvalid_1's auc: 0.87173                                                                 \n",
      "[6000]\ttraining's auc: 0.89907\tvalid_1's auc: 0.877647                                                                 \n",
      "[7000]\ttraining's auc: 0.904628\tvalid_1's auc: 0.881973                                                                \n",
      "[8000]\ttraining's auc: 0.909176\tvalid_1's auc: 0.885427                                                                \n",
      "[9000]\ttraining's auc: 0.912945\tvalid_1's auc: 0.888132                                                                \n",
      "[10000]\ttraining's auc: 0.916277\tvalid_1's auc: 0.890362                                                               \n",
      "[11000]\ttraining's auc: 0.918915\tvalid_1's auc: 0.891986                                                               \n",
      "[12000]\ttraining's auc: 0.921344\tvalid_1's auc: 0.893417                                                               \n",
      "[13000]\ttraining's auc: 0.923597\tvalid_1's auc: 0.894634                                                               \n",
      "[14000]\ttraining's auc: 0.925562\tvalid_1's auc: 0.895476                                                               \n",
      "[15000]\ttraining's auc: 0.927335\tvalid_1's auc: 0.896215                                                               \n",
      "[16000]\ttraining's auc: 0.929007\tvalid_1's auc: 0.89686                                                                \n",
      "[17000]\ttraining's auc: 0.930542\tvalid_1's auc: 0.897326                                                               \n",
      "[18000]\ttraining's auc: 0.932013\tvalid_1's auc: 0.897668                                                               \n",
      "[19000]\ttraining's auc: 0.933393\tvalid_1's auc: 0.897987                                                               \n",
      "[20000]\ttraining's auc: 0.934703\tvalid_1's auc: 0.898242                                                               \n",
      "[21000]\ttraining's auc: 0.935968\tvalid_1's auc: 0.898502                                                               \n",
      "[22000]\ttraining's auc: 0.937199\tvalid_1's auc: 0.898628                                                               \n",
      "[23000]\ttraining's auc: 0.938413\tvalid_1's auc: 0.898643                                                               \n",
      "[24000]\ttraining's auc: 0.939606\tvalid_1's auc: 0.89872                                                                \n",
      "[25000]\ttraining's auc: 0.940776\tvalid_1's auc: 0.898779                                                               \n",
      "[26000]\ttraining's auc: 0.941942\tvalid_1's auc: 0.89886                                                                \n",
      "[27000]\ttraining's auc: 0.94307\tvalid_1's auc: 0.898872                                                                \n",
      "[28000]\ttraining's auc: 0.944171\tvalid_1's auc: 0.898834                                                               \n",
      "[29000]\ttraining's auc: 0.945256\tvalid_1's auc: 0.898823                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26819]\ttraining's auc: 0.942862\tvalid_1's auc: 0.898897\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.820207\tvalid_1's auc: 0.794228                                                                \n",
      "[2000]\ttraining's auc: 0.850605\tvalid_1's auc: 0.823504                                                                \n",
      "[3000]\ttraining's auc: 0.87143\tvalid_1's auc: 0.843196                                                                 \n",
      "[4000]\ttraining's auc: 0.885281\tvalid_1's auc: 0.855561                                                                \n",
      "[5000]\ttraining's auc: 0.894939\tvalid_1's auc: 0.863841                                                                \n",
      "[6000]\ttraining's auc: 0.902249\tvalid_1's auc: 0.87002                                                                 \n",
      "[7000]\ttraining's auc: 0.907839\tvalid_1's auc: 0.874439                                                                \n",
      "[8000]\ttraining's auc: 0.91245\tvalid_1's auc: 0.878039                                                                 \n",
      "[9000]\ttraining's auc: 0.916293\tvalid_1's auc: 0.880858                                                                \n",
      "[10000]\ttraining's auc: 0.919513\tvalid_1's auc: 0.883157                                                               \n",
      "[11000]\ttraining's auc: 0.922254\tvalid_1's auc: 0.88495                                                                \n",
      "[12000]\ttraining's auc: 0.924701\tvalid_1's auc: 0.886395                                                               \n",
      "[13000]\ttraining's auc: 0.926884\tvalid_1's auc: 0.887524                                                               \n",
      "[14000]\ttraining's auc: 0.928783\tvalid_1's auc: 0.888436                                                               \n",
      "[15000]\ttraining's auc: 0.930506\tvalid_1's auc: 0.889176                                                               \n",
      "[16000]\ttraining's auc: 0.932082\tvalid_1's auc: 0.889803                                                               \n",
      "[17000]\ttraining's auc: 0.933549\tvalid_1's auc: 0.890313                                                               \n",
      "[18000]\ttraining's auc: 0.934992\tvalid_1's auc: 0.890795                                                               \n",
      "[19000]\ttraining's auc: 0.936309\tvalid_1's auc: 0.891179                                                               \n",
      "[20000]\ttraining's auc: 0.937605\tvalid_1's auc: 0.891411                                                               \n",
      "[21000]\ttraining's auc: 0.938824\tvalid_1's auc: 0.891484                                                               \n",
      "[22000]\ttraining's auc: 0.940021\tvalid_1's auc: 0.891628                                                               \n",
      "[23000]\ttraining's auc: 0.941185\tvalid_1's auc: 0.891836                                                               \n",
      "[24000]\ttraining's auc: 0.942294\tvalid_1's auc: 0.891935                                                               \n",
      "[25000]\ttraining's auc: 0.943402\tvalid_1's auc: 0.891953                                                               \n",
      "[26000]\ttraining's auc: 0.944501\tvalid_1's auc: 0.891877                                                               \n",
      "[27000]\ttraining's auc: 0.945592\tvalid_1's auc: 0.89187                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24904]\ttraining's auc: 0.943298\tvalid_1's auc: 0.891968\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.821618\tvalid_1's auc: 0.804744                                                                \n",
      "[2000]\ttraining's auc: 0.850025\tvalid_1's auc: 0.830533                                                                \n",
      "[3000]\ttraining's auc: 0.870417\tvalid_1's auc: 0.849292                                                                \n",
      "[4000]\ttraining's auc: 0.883462\tvalid_1's auc: 0.860794                                                                \n",
      "[5000]\ttraining's auc: 0.893053\tvalid_1's auc: 0.868992                                                                \n",
      "[6000]\ttraining's auc: 0.900236\tvalid_1's auc: 0.875142                                                                \n",
      "[7000]\ttraining's auc: 0.905862\tvalid_1's auc: 0.879954                                                                \n",
      "[8000]\ttraining's auc: 0.910397\tvalid_1's auc: 0.883382                                                                \n",
      "[9000]\ttraining's auc: 0.914267\tvalid_1's auc: 0.886394                                                                \n",
      "[10000]\ttraining's auc: 0.91744\tvalid_1's auc: 0.888606                                                                \n",
      "[11000]\ttraining's auc: 0.920151\tvalid_1's auc: 0.890502                                                               \n",
      "[12000]\ttraining's auc: 0.922526\tvalid_1's auc: 0.891941                                                               \n",
      "[13000]\ttraining's auc: 0.924631\tvalid_1's auc: 0.893228                                                               \n",
      "[14000]\ttraining's auc: 0.926577\tvalid_1's auc: 0.894302                                                               \n",
      "[15000]\ttraining's auc: 0.928314\tvalid_1's auc: 0.895255                                                               \n",
      "[16000]\ttraining's auc: 0.929881\tvalid_1's auc: 0.895904                                                               \n",
      "[17000]\ttraining's auc: 0.931392\tvalid_1's auc: 0.896487                                                               \n",
      "[18000]\ttraining's auc: 0.93284\tvalid_1's auc: 0.896997                                                                \n",
      "[19000]\ttraining's auc: 0.934172\tvalid_1's auc: 0.897332                                                               \n",
      "[20000]\ttraining's auc: 0.935484\tvalid_1's auc: 0.897708                                                               \n",
      "[21000]\ttraining's auc: 0.936731\tvalid_1's auc: 0.897997                                                               \n",
      "[22000]\ttraining's auc: 0.937984\tvalid_1's auc: 0.898183                                                               \n",
      "[23000]\ttraining's auc: 0.939207\tvalid_1's auc: 0.898367                                                               \n",
      "[24000]\ttraining's auc: 0.940404\tvalid_1's auc: 0.898522                                                               \n",
      "[25000]\ttraining's auc: 0.941543\tvalid_1's auc: 0.898648                                                               \n",
      "[26000]\ttraining's auc: 0.942719\tvalid_1's auc: 0.898839                                                               \n",
      "[27000]\ttraining's auc: 0.943845\tvalid_1's auc: 0.898942                                                               \n",
      "[28000]\ttraining's auc: 0.944924\tvalid_1's auc: 0.899038                                                               \n",
      "[29000]\ttraining's auc: 0.945985\tvalid_1's auc: 0.899063                                                               \n",
      "[30000]\ttraining's auc: 0.947031\tvalid_1's auc: 0.899082                                                               \n",
      "[31000]\ttraining's auc: 0.948077\tvalid_1's auc: 0.899035                                                               \n",
      "[32000]\ttraining's auc: 0.949104\tvalid_1's auc: 0.899107                                                               \n",
      "[33000]\ttraining's auc: 0.950136\tvalid_1's auc: 0.899144                                                               \n",
      "[34000]\ttraining's auc: 0.951198\tvalid_1's auc: 0.899144                                                               \n",
      "[35000]\ttraining's auc: 0.952188\tvalid_1's auc: 0.89915                                                                \n",
      "[36000]\ttraining's auc: 0.953184\tvalid_1's auc: 0.899111                                                               \n",
      "[37000]\ttraining's auc: 0.954155\tvalid_1's auc: 0.899106                                                               \n",
      "[38000]\ttraining's auc: 0.955124\tvalid_1's auc: 0.899173                                                               \n",
      "[39000]\ttraining's auc: 0.956109\tvalid_1's auc: 0.899182                                                               \n",
      "[40000]\ttraining's auc: 0.95707\tvalid_1's auc: 0.899158                                                                \n",
      "[41000]\ttraining's auc: 0.958006\tvalid_1's auc: 0.899112                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38393]\ttraining's auc: 0.955508\tvalid_1's auc: 0.899211\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.819748\tvalid_1's auc: 0.804504                                                                \n",
      "[2000]\ttraining's auc: 0.850528\tvalid_1's auc: 0.831798                                                                \n",
      "[3000]\ttraining's auc: 0.870828\tvalid_1's auc: 0.849283                                                                \n",
      "[4000]\ttraining's auc: 0.884596\tvalid_1's auc: 0.860865                                                                \n",
      "[5000]\ttraining's auc: 0.894144\tvalid_1's auc: 0.868517                                                                \n",
      "[6000]\ttraining's auc: 0.901114\tvalid_1's auc: 0.874097                                                                \n",
      "[7000]\ttraining's auc: 0.906648\tvalid_1's auc: 0.878204                                                                \n",
      "[8000]\ttraining's auc: 0.911199\tvalid_1's auc: 0.881538                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9000]\ttraining's auc: 0.915012\tvalid_1's auc: 0.88418                                                                 \n",
      "[10000]\ttraining's auc: 0.91821\tvalid_1's auc: 0.886519                                                                \n",
      "[11000]\ttraining's auc: 0.921017\tvalid_1's auc: 0.888226                                                               \n",
      "[12000]\ttraining's auc: 0.923446\tvalid_1's auc: 0.889635                                                               \n",
      "[13000]\ttraining's auc: 0.925637\tvalid_1's auc: 0.890834                                                               \n",
      "[14000]\ttraining's auc: 0.927643\tvalid_1's auc: 0.891832                                                               \n",
      "[15000]\ttraining's auc: 0.929425\tvalid_1's auc: 0.892651                                                               \n",
      "[16000]\ttraining's auc: 0.931022\tvalid_1's auc: 0.893336                                                               \n",
      "[17000]\ttraining's auc: 0.932559\tvalid_1's auc: 0.893884                                                               \n",
      "[18000]\ttraining's auc: 0.934024\tvalid_1's auc: 0.894331                                                               \n",
      "[19000]\ttraining's auc: 0.935405\tvalid_1's auc: 0.894668                                                               \n",
      "[20000]\ttraining's auc: 0.936704\tvalid_1's auc: 0.895017                                                               \n",
      "[21000]\ttraining's auc: 0.937937\tvalid_1's auc: 0.895266                                                               \n",
      "[22000]\ttraining's auc: 0.939128\tvalid_1's auc: 0.895484                                                               \n",
      "[23000]\ttraining's auc: 0.940318\tvalid_1's auc: 0.895637                                                               \n",
      "[24000]\ttraining's auc: 0.94148\tvalid_1's auc: 0.895681                                                                \n",
      "[25000]\ttraining's auc: 0.942593\tvalid_1's auc: 0.895882                                                               \n",
      "[26000]\ttraining's auc: 0.943701\tvalid_1's auc: 0.895961                                                               \n",
      "[27000]\ttraining's auc: 0.944766\tvalid_1's auc: 0.896048                                                               \n",
      "[28000]\ttraining's auc: 0.945866\tvalid_1's auc: 0.896094                                                               \n",
      "[29000]\ttraining's auc: 0.946919\tvalid_1's auc: 0.896092                                                               \n",
      "[30000]\ttraining's auc: 0.947981\tvalid_1's auc: 0.896094                                                               \n",
      "[31000]\ttraining's auc: 0.949026\tvalid_1's auc: 0.896162                                                               \n",
      "[32000]\ttraining's auc: 0.950079\tvalid_1's auc: 0.896198                                                               \n",
      "[33000]\ttraining's auc: 0.951079\tvalid_1's auc: 0.896233                                                               \n",
      "[34000]\ttraining's auc: 0.952078\tvalid_1's auc: 0.896243                                                               \n",
      "[35000]\ttraining's auc: 0.953065\tvalid_1's auc: 0.896132                                                               \n",
      "[36000]\ttraining's auc: 0.954047\tvalid_1's auc: 0.896139                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33949]\ttraining's auc: 0.952025\tvalid_1's auc: 0.89625\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.857627\tvalid_1's auc: 0.844894                                                                \n",
      "[2000]\ttraining's auc: 0.887307\tvalid_1's auc: 0.871371                                                                \n",
      "[3000]\ttraining's auc: 0.901479\tvalid_1's auc: 0.883202                                                                \n",
      "[4000]\ttraining's auc: 0.910104\tvalid_1's auc: 0.889735                                                                \n",
      "[5000]\ttraining's auc: 0.915936\tvalid_1's auc: 0.89349                                                                 \n",
      "[6000]\ttraining's auc: 0.92036\tvalid_1's auc: 0.895913                                                                 \n",
      "[7000]\ttraining's auc: 0.924031\tvalid_1's auc: 0.897396                                                                \n",
      "[8000]\ttraining's auc: 0.927277\tvalid_1's auc: 0.898105                                                                \n",
      "[9000]\ttraining's auc: 0.93019\tvalid_1's auc: 0.898368                                                                 \n",
      "[10000]\ttraining's auc: 0.932891\tvalid_1's auc: 0.898517                                                               \n",
      "[11000]\ttraining's auc: 0.935536\tvalid_1's auc: 0.898561                                                               \n",
      "[12000]\ttraining's auc: 0.938042\tvalid_1's auc: 0.898583                                                               \n",
      "[13000]\ttraining's auc: 0.940445\tvalid_1's auc: 0.898523                                                               \n",
      "[14000]\ttraining's auc: 0.942806\tvalid_1's auc: 0.898479                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11653]\ttraining's auc: 0.937171\tvalid_1's auc: 0.898673\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.859975\tvalid_1's auc: 0.837057                                                                \n",
      "[2000]\ttraining's auc: 0.890317\tvalid_1's auc: 0.86445                                                                 \n",
      "[3000]\ttraining's auc: 0.904722\tvalid_1's auc: 0.875849                                                                \n",
      "[4000]\ttraining's auc: 0.913554\tvalid_1's auc: 0.882564                                                                \n",
      "[5000]\ttraining's auc: 0.91943\tvalid_1's auc: 0.886188                                                                 \n",
      "[6000]\ttraining's auc: 0.923743\tvalid_1's auc: 0.888319                                                                \n",
      "[7000]\ttraining's auc: 0.927237\tvalid_1's auc: 0.889645                                                                \n",
      "[8000]\ttraining's auc: 0.930321\tvalid_1's auc: 0.890429                                                                \n",
      "[9000]\ttraining's auc: 0.933153\tvalid_1's auc: 0.890922                                                                \n",
      "[10000]\ttraining's auc: 0.935732\tvalid_1's auc: 0.891254                                                               \n",
      "[11000]\ttraining's auc: 0.93822\tvalid_1's auc: 0.891264                                                                \n",
      "[12000]\ttraining's auc: 0.940714\tvalid_1's auc: 0.891306                                                               \n",
      "[13000]\ttraining's auc: 0.943031\tvalid_1's auc: 0.891234                                                               \n",
      "[14000]\ttraining's auc: 0.945295\tvalid_1's auc: 0.891202                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11197]\ttraining's auc: 0.938704\tvalid_1's auc: 0.891369\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.858867\tvalid_1's auc: 0.842412                                                                \n",
      "[2000]\ttraining's auc: 0.887975\tvalid_1's auc: 0.869369                                                                \n",
      "[3000]\ttraining's auc: 0.902547\tvalid_1's auc: 0.881595                                                                \n",
      "[4000]\ttraining's auc: 0.911214\tvalid_1's auc: 0.888053                                                                \n",
      "[5000]\ttraining's auc: 0.91699\tvalid_1's auc: 0.891955                                                                 \n",
      "[6000]\ttraining's auc: 0.921422\tvalid_1's auc: 0.894472                                                                \n",
      "[7000]\ttraining's auc: 0.924944\tvalid_1's auc: 0.89634                                                                 \n",
      "[8000]\ttraining's auc: 0.928071\tvalid_1's auc: 0.897243                                                                \n",
      "[9000]\ttraining's auc: 0.930992\tvalid_1's auc: 0.897968                                                                \n",
      "[10000]\ttraining's auc: 0.933731\tvalid_1's auc: 0.898496                                                               \n",
      "[11000]\ttraining's auc: 0.936302\tvalid_1's auc: 0.898747                                                               \n",
      "[12000]\ttraining's auc: 0.938797\tvalid_1's auc: 0.898839                                                               \n",
      "[13000]\ttraining's auc: 0.941224\tvalid_1's auc: 0.89882                                                                \n",
      "[14000]\ttraining's auc: 0.943552\tvalid_1's auc: 0.89878                                                                \n",
      "[15000]\ttraining's auc: 0.945789\tvalid_1's auc: 0.898783                                                               \n",
      "[16000]\ttraining's auc: 0.947968\tvalid_1's auc: 0.898684                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13229]\ttraining's auc: 0.941746\tvalid_1's auc: 0.898884\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.860017\tvalid_1's auc: 0.843869                                                                \n",
      "[2000]\ttraining's auc: 0.889481\tvalid_1's auc: 0.868723                                                                \n",
      "[3000]\ttraining's auc: 0.903613\tvalid_1's auc: 0.879988                                                                \n",
      "[4000]\ttraining's auc: 0.912287\tvalid_1's auc: 0.886203                                                                \n",
      "[5000]\ttraining's auc: 0.918217\tvalid_1's auc: 0.889925                                                                \n",
      "[6000]\ttraining's auc: 0.922715\tvalid_1's auc: 0.892179                                                                \n",
      "[7000]\ttraining's auc: 0.926311\tvalid_1's auc: 0.893721                                                                \n",
      "[8000]\ttraining's auc: 0.929474\tvalid_1's auc: 0.894522                                                                \n",
      "[9000]\ttraining's auc: 0.932308\tvalid_1's auc: 0.895285                                                                \n",
      "[10000]\ttraining's auc: 0.934997\tvalid_1's auc: 0.895708                                                               \n",
      "[11000]\ttraining's auc: 0.937563\tvalid_1's auc: 0.895866                                                               \n",
      "[12000]\ttraining's auc: 0.94004\tvalid_1's auc: 0.895902                                                                \n",
      "[13000]\ttraining's auc: 0.942439\tvalid_1's auc: 0.895934                                                               \n",
      "[14000]\ttraining's auc: 0.944721\tvalid_1's auc: 0.896058                                                               \n",
      "[15000]\ttraining's auc: 0.946936\tvalid_1's auc: 0.896123                                                               \n",
      "[16000]\ttraining's auc: 0.949139\tvalid_1's auc: 0.896054                                                               \n",
      "[17000]\ttraining's auc: 0.951241\tvalid_1's auc: 0.895966                                                               \n",
      "[18000]\ttraining's auc: 0.953279\tvalid_1's auc: 0.895884                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15191]\ttraining's auc: 0.947363\tvalid_1's auc: 0.896155\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.836619\tvalid_1's auc: 0.824308                                                                \n",
      "[2000]\ttraining's auc: 0.869509\tvalid_1's auc: 0.855948                                                                \n",
      "[3000]\ttraining's auc: 0.885988\tvalid_1's auc: 0.871267                                                                \n",
      "[4000]\ttraining's auc: 0.895949\tvalid_1's auc: 0.879453                                                                \n",
      "[5000]\ttraining's auc: 0.902632\tvalid_1's auc: 0.885154                                                                \n",
      "[6000]\ttraining's auc: 0.907635\tvalid_1's auc: 0.889153                                                                \n",
      "[7000]\ttraining's auc: 0.911568\tvalid_1's auc: 0.891943                                                                \n",
      "[8000]\ttraining's auc: 0.914591\tvalid_1's auc: 0.893665                                                                \n",
      "[9000]\ttraining's auc: 0.917131\tvalid_1's auc: 0.895379                                                                \n",
      "[10000]\ttraining's auc: 0.919177\tvalid_1's auc: 0.896347                                                               \n",
      "[11000]\ttraining's auc: 0.920903\tvalid_1's auc: 0.89705                                                                \n",
      "[12000]\ttraining's auc: 0.922504\tvalid_1's auc: 0.897607                                                               \n",
      "[13000]\ttraining's auc: 0.923947\tvalid_1's auc: 0.897952                                                               \n",
      "[14000]\ttraining's auc: 0.925306\tvalid_1's auc: 0.898151                                                               \n",
      "[15000]\ttraining's auc: 0.926647\tvalid_1's auc: 0.898443                                                               \n",
      "[16000]\ttraining's auc: 0.927883\tvalid_1's auc: 0.898438                                                               \n",
      "[17000]\ttraining's auc: 0.929061\tvalid_1's auc: 0.898269                                                               \n",
      "[18000]\ttraining's auc: 0.93025\tvalid_1's auc: 0.898254                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15045]\ttraining's auc: 0.926703\tvalid_1's auc: 0.898486\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.837803\tvalid_1's auc: 0.81637                                                                 \n",
      "[2000]\ttraining's auc: 0.871983\tvalid_1's auc: 0.848445                                                                \n",
      "[3000]\ttraining's auc: 0.888939\tvalid_1's auc: 0.863862                                                                \n",
      "[4000]\ttraining's auc: 0.899212\tvalid_1's auc: 0.872345                                                                \n",
      "[5000]\ttraining's auc: 0.906406\tvalid_1's auc: 0.878325                                                                \n",
      "[6000]\ttraining's auc: 0.911421\tvalid_1's auc: 0.882202                                                                \n",
      "[7000]\ttraining's auc: 0.915283\tvalid_1's auc: 0.884922                                                                \n",
      "[8000]\ttraining's auc: 0.918312\tvalid_1's auc: 0.886652                                                                \n",
      "[9000]\ttraining's auc: 0.920684\tvalid_1's auc: 0.887893                                                                \n",
      "[10000]\ttraining's auc: 0.922727\tvalid_1's auc: 0.889093                                                               \n",
      "[11000]\ttraining's auc: 0.924431\tvalid_1's auc: 0.889913                                                               \n",
      "[12000]\ttraining's auc: 0.925978\tvalid_1's auc: 0.890398                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13000]\ttraining's auc: 0.927386\tvalid_1's auc: 0.89063                                                                \n",
      "[14000]\ttraining's auc: 0.928689\tvalid_1's auc: 0.890808                                                               \n",
      "[15000]\ttraining's auc: 0.929934\tvalid_1's auc: 0.89088                                                                \n",
      "[16000]\ttraining's auc: 0.931097\tvalid_1's auc: 0.890898                                                               \n",
      "[17000]\ttraining's auc: 0.932223\tvalid_1's auc: 0.890994                                                               \n",
      "[18000]\ttraining's auc: 0.933358\tvalid_1's auc: 0.890963                                                               \n",
      "[19000]\ttraining's auc: 0.934464\tvalid_1's auc: 0.890899                                                               \n",
      "[20000]\ttraining's auc: 0.935529\tvalid_1's auc: 0.890746                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17307]\ttraining's auc: 0.932575\tvalid_1's auc: 0.891043\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.83838\tvalid_1's auc: 0.823305                                                                 \n",
      "[2000]\ttraining's auc: 0.870642\tvalid_1's auc: 0.853498                                                                \n",
      "[3000]\ttraining's auc: 0.886847\tvalid_1's auc: 0.868552                                                                \n",
      "[4000]\ttraining's auc: 0.897028\tvalid_1's auc: 0.877875                                                                \n",
      "[5000]\ttraining's auc: 0.903969\tvalid_1's auc: 0.88369                                                                 \n",
      "[6000]\ttraining's auc: 0.908979\tvalid_1's auc: 0.887794                                                                \n",
      "[7000]\ttraining's auc: 0.912615\tvalid_1's auc: 0.890774                                                                \n",
      "[8000]\ttraining's auc: 0.915613\tvalid_1's auc: 0.893013                                                                \n",
      "[9000]\ttraining's auc: 0.918107\tvalid_1's auc: 0.894892                                                                \n",
      "[10000]\ttraining's auc: 0.920169\tvalid_1's auc: 0.895919                                                               \n",
      "[11000]\ttraining's auc: 0.921922\tvalid_1's auc: 0.896932                                                               \n",
      "[12000]\ttraining's auc: 0.923477\tvalid_1's auc: 0.897516                                                               \n",
      "[13000]\ttraining's auc: 0.924919\tvalid_1's auc: 0.898251                                                               \n",
      "[14000]\ttraining's auc: 0.926237\tvalid_1's auc: 0.898668                                                               \n",
      "[15000]\ttraining's auc: 0.927471\tvalid_1's auc: 0.898836                                                               \n",
      "[16000]\ttraining's auc: 0.928732\tvalid_1's auc: 0.89898                                                                \n",
      "[17000]\ttraining's auc: 0.929918\tvalid_1's auc: 0.898983                                                               \n",
      "[18000]\ttraining's auc: 0.93103\tvalid_1's auc: 0.899105                                                                \n",
      "[19000]\ttraining's auc: 0.932109\tvalid_1's auc: 0.89921                                                                \n",
      "[20000]\ttraining's auc: 0.933247\tvalid_1's auc: 0.899354                                                               \n",
      "[21000]\ttraining's auc: 0.934276\tvalid_1's auc: 0.899245                                                               \n",
      "[22000]\ttraining's auc: 0.935312\tvalid_1's auc: 0.89912                                                                \n",
      "[23000]\ttraining's auc: 0.936371\tvalid_1's auc: 0.899107                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20123]\ttraining's auc: 0.933369\tvalid_1's auc: 0.899391\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.837601\tvalid_1's auc: 0.823102                                                                \n",
      "[2000]\ttraining's auc: 0.871669\tvalid_1's auc: 0.853006                                                                \n",
      "[3000]\ttraining's auc: 0.887923\tvalid_1's auc: 0.868034                                                                \n",
      "[4000]\ttraining's auc: 0.897937\tvalid_1's auc: 0.876631                                                                \n",
      "[5000]\ttraining's auc: 0.904599\tvalid_1's auc: 0.881991                                                                \n",
      "[6000]\ttraining's auc: 0.909584\tvalid_1's auc: 0.885854                                                                \n",
      "[7000]\ttraining's auc: 0.913513\tvalid_1's auc: 0.888669                                                                \n",
      "[8000]\ttraining's auc: 0.91663\tvalid_1's auc: 0.890507                                                                 \n",
      "[9000]\ttraining's auc: 0.91918\tvalid_1's auc: 0.892362                                                                 \n",
      "[10000]\ttraining's auc: 0.921315\tvalid_1's auc: 0.893728                                                               \n",
      "[11000]\ttraining's auc: 0.923156\tvalid_1's auc: 0.894503                                                               \n",
      "[12000]\ttraining's auc: 0.924813\tvalid_1's auc: 0.895237                                                               \n",
      "[13000]\ttraining's auc: 0.926263\tvalid_1's auc: 0.895579                                                               \n",
      "[14000]\ttraining's auc: 0.927641\tvalid_1's auc: 0.89603                                                                \n",
      "[15000]\ttraining's auc: 0.928923\tvalid_1's auc: 0.896155                                                               \n",
      "[16000]\ttraining's auc: 0.930138\tvalid_1's auc: 0.89633                                                                \n",
      "[17000]\ttraining's auc: 0.931258\tvalid_1's auc: 0.896357                                                               \n",
      "[18000]\ttraining's auc: 0.932353\tvalid_1's auc: 0.896397                                                               \n",
      "[19000]\ttraining's auc: 0.933428\tvalid_1's auc: 0.896312                                                               \n",
      "[20000]\ttraining's auc: 0.934521\tvalid_1's auc: 0.896255                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17770]\ttraining's auc: 0.932113\tvalid_1's auc: 0.896435\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.86942\tvalid_1's auc: 0.849795                                                                 \n",
      "[2000]\ttraining's auc: 0.900393\tvalid_1's auc: 0.875755                                                                \n",
      "[3000]\ttraining's auc: 0.914857\tvalid_1's auc: 0.8868                                                                  \n",
      "[4000]\ttraining's auc: 0.923842\tvalid_1's auc: 0.892618                                                                \n",
      "[5000]\ttraining's auc: 0.930076\tvalid_1's auc: 0.895349                                                                \n",
      "[6000]\ttraining's auc: 0.935009\tvalid_1's auc: 0.897121                                                                \n",
      "[7000]\ttraining's auc: 0.939303\tvalid_1's auc: 0.897946                                                                \n",
      "[8000]\ttraining's auc: 0.943228\tvalid_1's auc: 0.898291                                                                \n",
      "[9000]\ttraining's auc: 0.946856\tvalid_1's auc: 0.898504                                                                \n",
      "[10000]\ttraining's auc: 0.950275\tvalid_1's auc: 0.898557                                                               \n",
      "[11000]\ttraining's auc: 0.953559\tvalid_1's auc: 0.898692                                                               \n",
      "[12000]\ttraining's auc: 0.956787\tvalid_1's auc: 0.898528                                                               \n",
      "[13000]\ttraining's auc: 0.959795\tvalid_1's auc: 0.898394                                                               \n",
      "[14000]\ttraining's auc: 0.962688\tvalid_1's auc: 0.898181                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11337]\ttraining's auc: 0.954677\tvalid_1's auc: 0.898757\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.872027\tvalid_1's auc: 0.841852                                                                \n",
      "[2000]\ttraining's auc: 0.903488\tvalid_1's auc: 0.867644                                                                \n",
      "[3000]\ttraining's auc: 0.918015\tvalid_1's auc: 0.878665                                                                \n",
      "[4000]\ttraining's auc: 0.926898\tvalid_1's auc: 0.884465                                                                \n",
      "[5000]\ttraining's auc: 0.933031\tvalid_1's auc: 0.88757                                                                 \n",
      "[6000]\ttraining's auc: 0.937922\tvalid_1's auc: 0.889175                                                                \n",
      "[7000]\ttraining's auc: 0.941972\tvalid_1's auc: 0.889992                                                                \n",
      "[8000]\ttraining's auc: 0.945691\tvalid_1's auc: 0.890476                                                                \n",
      "[9000]\ttraining's auc: 0.94926\tvalid_1's auc: 0.890676                                                                 \n",
      "[10000]\ttraining's auc: 0.952556\tvalid_1's auc: 0.890652                                                               \n",
      "[11000]\ttraining's auc: 0.955746\tvalid_1's auc: 0.890645                                                               \n",
      "[12000]\ttraining's auc: 0.958718\tvalid_1's auc: 0.89054                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9395]\ttraining's auc: 0.950577\tvalid_1's auc: 0.890748\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.870654\tvalid_1's auc: 0.847071                                                                \n",
      "[2000]\ttraining's auc: 0.901407\tvalid_1's auc: 0.873879                                                                \n",
      "[3000]\ttraining's auc: 0.916127\tvalid_1's auc: 0.885085                                                                \n",
      "[4000]\ttraining's auc: 0.92495\tvalid_1's auc: 0.890758                                                                 \n",
      "[5000]\ttraining's auc: 0.93105\tvalid_1's auc: 0.893762                                                                 \n",
      "[6000]\ttraining's auc: 0.93592\tvalid_1's auc: 0.895755                                                                 \n",
      "[7000]\ttraining's auc: 0.940124\tvalid_1's auc: 0.896979                                                                \n",
      "[8000]\ttraining's auc: 0.943941\tvalid_1's auc: 0.897842                                                                \n",
      "[9000]\ttraining's auc: 0.947567\tvalid_1's auc: 0.898282                                                                \n",
      "[10000]\ttraining's auc: 0.950972\tvalid_1's auc: 0.898462                                                               \n",
      "[11000]\ttraining's auc: 0.954152\tvalid_1's auc: 0.898631                                                               \n",
      "[12000]\ttraining's auc: 0.957268\tvalid_1's auc: 0.898719                                                               \n",
      "[13000]\ttraining's auc: 0.960259\tvalid_1's auc: 0.898726                                                               \n",
      "[14000]\ttraining's auc: 0.963075\tvalid_1's auc: 0.898634                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11649]\ttraining's auc: 0.956206\tvalid_1's auc: 0.8988\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.871676\tvalid_1's auc: 0.848409                                                                \n",
      "[2000]\ttraining's auc: 0.90234\tvalid_1's auc: 0.872487                                                                 \n",
      "[3000]\ttraining's auc: 0.916785\tvalid_1's auc: 0.882922                                                                \n",
      "[4000]\ttraining's auc: 0.925788\tvalid_1's auc: 0.888566                                                                \n",
      "[5000]\ttraining's auc: 0.932084\tvalid_1's auc: 0.891798                                                                \n",
      "[6000]\ttraining's auc: 0.936926\tvalid_1's auc: 0.893499                                                                \n",
      "[7000]\ttraining's auc: 0.941087\tvalid_1's auc: 0.894397                                                                \n",
      "[8000]\ttraining's auc: 0.944929\tvalid_1's auc: 0.894995                                                                \n",
      "[9000]\ttraining's auc: 0.948512\tvalid_1's auc: 0.895375                                                                \n",
      "[10000]\ttraining's auc: 0.951786\tvalid_1's auc: 0.895587                                                               \n",
      "[11000]\ttraining's auc: 0.954989\tvalid_1's auc: 0.895494                                                               \n",
      "[12000]\ttraining's auc: 0.958034\tvalid_1's auc: 0.895405                                                               \n",
      "[13000]\ttraining's auc: 0.96092\tvalid_1's auc: 0.895273                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10439]\ttraining's auc: 0.953243\tvalid_1's auc: 0.895655\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.832585\tvalid_1's auc: 0.820972                                                                \n",
      "[2000]\ttraining's auc: 0.86348\tvalid_1's auc: 0.849807                                                                 \n",
      "[3000]\ttraining's auc: 0.881801\tvalid_1's auc: 0.866448                                                                \n",
      "[4000]\ttraining's auc: 0.892699\tvalid_1's auc: 0.875872                                                                \n",
      "[5000]\ttraining's auc: 0.900288\tvalid_1's auc: 0.882084                                                                \n",
      "[6000]\ttraining's auc: 0.905935\tvalid_1's auc: 0.886642                                                                \n",
      "[7000]\ttraining's auc: 0.910435\tvalid_1's auc: 0.889975                                                                \n",
      "[8000]\ttraining's auc: 0.913955\tvalid_1's auc: 0.892197                                                                \n",
      "[9000]\ttraining's auc: 0.916782\tvalid_1's auc: 0.893865                                                                \n",
      "[10000]\ttraining's auc: 0.919237\tvalid_1's auc: 0.895337                                                               \n",
      "[11000]\ttraining's auc: 0.921368\tvalid_1's auc: 0.896315                                                               \n",
      "[12000]\ttraining's auc: 0.923311\tvalid_1's auc: 0.897044                                                               \n",
      "[13000]\ttraining's auc: 0.925072\tvalid_1's auc: 0.897635                                                               \n",
      "[14000]\ttraining's auc: 0.926678\tvalid_1's auc: 0.897928                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000]\ttraining's auc: 0.928191\tvalid_1's auc: 0.898231                                                               \n",
      "[16000]\ttraining's auc: 0.929629\tvalid_1's auc: 0.898418                                                               \n",
      "[17000]\ttraining's auc: 0.93098\tvalid_1's auc: 0.898448                                                                \n",
      "[18000]\ttraining's auc: 0.932346\tvalid_1's auc: 0.898427                                                               \n",
      "[19000]\ttraining's auc: 0.933671\tvalid_1's auc: 0.898496                                                               \n",
      "[20000]\ttraining's auc: 0.934973\tvalid_1's auc: 0.89843                                                                \n",
      "[21000]\ttraining's auc: 0.93626\tvalid_1's auc: 0.898429                                                                \n",
      "[22000]\ttraining's auc: 0.937497\tvalid_1's auc: 0.898472                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19093]\ttraining's auc: 0.933802\tvalid_1's auc: 0.89853\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.833665\tvalid_1's auc: 0.811208                                                                \n",
      "[2000]\ttraining's auc: 0.866105\tvalid_1's auc: 0.842174                                                                \n",
      "[3000]\ttraining's auc: 0.884351\tvalid_1's auc: 0.858923                                                                \n",
      "[4000]\ttraining's auc: 0.89566\tvalid_1's auc: 0.868707                                                                 \n",
      "[5000]\ttraining's auc: 0.903693\tvalid_1's auc: 0.87514                                                                 \n",
      "[6000]\ttraining's auc: 0.909524\tvalid_1's auc: 0.879759                                                                \n",
      "[7000]\ttraining's auc: 0.913864\tvalid_1's auc: 0.882934                                                                \n",
      "[8000]\ttraining's auc: 0.917449\tvalid_1's auc: 0.885468                                                                \n",
      "[9000]\ttraining's auc: 0.920329\tvalid_1's auc: 0.887075                                                                \n",
      "[10000]\ttraining's auc: 0.922681\tvalid_1's auc: 0.888385                                                               \n",
      "[11000]\ttraining's auc: 0.924785\tvalid_1's auc: 0.889434                                                               \n",
      "[12000]\ttraining's auc: 0.926666\tvalid_1's auc: 0.890201                                                               \n",
      "[13000]\ttraining's auc: 0.928343\tvalid_1's auc: 0.890683                                                               \n",
      "[14000]\ttraining's auc: 0.929955\tvalid_1's auc: 0.891085                                                               \n",
      "[15000]\ttraining's auc: 0.931392\tvalid_1's auc: 0.89138                                                                \n",
      "[16000]\ttraining's auc: 0.932778\tvalid_1's auc: 0.89157                                                                \n",
      "[17000]\ttraining's auc: 0.934116\tvalid_1's auc: 0.891745                                                               \n",
      "[18000]\ttraining's auc: 0.935385\tvalid_1's auc: 0.891795                                                               \n",
      "[19000]\ttraining's auc: 0.936675\tvalid_1's auc: 0.891815                                                               \n",
      "[20000]\ttraining's auc: 0.937923\tvalid_1's auc: 0.891834                                                               \n",
      "[21000]\ttraining's auc: 0.939174\tvalid_1's auc: 0.89176                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18509]\ttraining's auc: 0.936049\tvalid_1's auc: 0.891869\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.833584\tvalid_1's auc: 0.818826                                                                \n",
      "[2000]\ttraining's auc: 0.865366\tvalid_1's auc: 0.848966                                                                \n",
      "[3000]\ttraining's auc: 0.882486\tvalid_1's auc: 0.864224                                                                \n",
      "[4000]\ttraining's auc: 0.893868\tvalid_1's auc: 0.874307                                                                \n",
      "[5000]\ttraining's auc: 0.901559\tvalid_1's auc: 0.880987                                                                \n",
      "[6000]\ttraining's auc: 0.907215\tvalid_1's auc: 0.885614                                                                \n",
      "[7000]\ttraining's auc: 0.911537\tvalid_1's auc: 0.889014                                                                \n",
      "[8000]\ttraining's auc: 0.915005\tvalid_1's auc: 0.891607                                                                \n",
      "[9000]\ttraining's auc: 0.917813\tvalid_1's auc: 0.893478                                                                \n",
      "[10000]\ttraining's auc: 0.920247\tvalid_1's auc: 0.894909                                                               \n",
      "[11000]\ttraining's auc: 0.922319\tvalid_1's auc: 0.895974                                                               \n",
      "[12000]\ttraining's auc: 0.924166\tvalid_1's auc: 0.896905                                                               \n",
      "[13000]\ttraining's auc: 0.925931\tvalid_1's auc: 0.89766                                                                \n",
      "[14000]\ttraining's auc: 0.927525\tvalid_1's auc: 0.89829                                                                \n",
      "[15000]\ttraining's auc: 0.928991\tvalid_1's auc: 0.898722                                                               \n",
      "[16000]\ttraining's auc: 0.930379\tvalid_1's auc: 0.899126                                                               \n",
      "[17000]\ttraining's auc: 0.931758\tvalid_1's auc: 0.899274                                                               \n",
      "[18000]\ttraining's auc: 0.933113\tvalid_1's auc: 0.899323                                                               \n",
      "[19000]\ttraining's auc: 0.934418\tvalid_1's auc: 0.899321                                                               \n",
      "[20000]\ttraining's auc: 0.935703\tvalid_1's auc: 0.899446                                                               \n",
      "[21000]\ttraining's auc: 0.936939\tvalid_1's auc: 0.899496                                                               \n",
      "[22000]\ttraining's auc: 0.938189\tvalid_1's auc: 0.899595                                                               \n",
      "[23000]\ttraining's auc: 0.939397\tvalid_1's auc: 0.899595                                                               \n",
      "[24000]\ttraining's auc: 0.940592\tvalid_1's auc: 0.899625                                                               \n",
      "[25000]\ttraining's auc: 0.941783\tvalid_1's auc: 0.899576                                                               \n",
      "[26000]\ttraining's auc: 0.942992\tvalid_1's auc: 0.899489                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23655]\ttraining's auc: 0.940203\tvalid_1's auc: 0.899667\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.83295\tvalid_1's auc: 0.818941                                                                 \n",
      "[2000]\ttraining's auc: 0.865997\tvalid_1's auc: 0.848148                                                                \n",
      "[3000]\ttraining's auc: 0.883359\tvalid_1's auc: 0.863192                                                                \n",
      "[4000]\ttraining's auc: 0.89466\tvalid_1's auc: 0.872822                                                                 \n",
      "[5000]\ttraining's auc: 0.902279\tvalid_1's auc: 0.878969                                                                \n",
      "[6000]\ttraining's auc: 0.907949\tvalid_1's auc: 0.883296                                                                \n",
      "[7000]\ttraining's auc: 0.912411\tvalid_1's auc: 0.886496                                                                \n",
      "[8000]\ttraining's auc: 0.916078\tvalid_1's auc: 0.888767                                                                \n",
      "[9000]\ttraining's auc: 0.918985\tvalid_1's auc: 0.890557                                                                \n",
      "[10000]\ttraining's auc: 0.921515\tvalid_1's auc: 0.89202                                                                \n",
      "[11000]\ttraining's auc: 0.923607\tvalid_1's auc: 0.892948                                                               \n",
      "[12000]\ttraining's auc: 0.925539\tvalid_1's auc: 0.893788                                                               \n",
      "[13000]\ttraining's auc: 0.927293\tvalid_1's auc: 0.894359                                                               \n",
      "[14000]\ttraining's auc: 0.92887\tvalid_1's auc: 0.89484                                                                 \n",
      "[15000]\ttraining's auc: 0.930298\tvalid_1's auc: 0.895275                                                               \n",
      "[16000]\ttraining's auc: 0.93169\tvalid_1's auc: 0.89552                                                                 \n",
      "[17000]\ttraining's auc: 0.933027\tvalid_1's auc: 0.895844                                                               \n",
      "[18000]\ttraining's auc: 0.934359\tvalid_1's auc: 0.895905                                                               \n",
      "[19000]\ttraining's auc: 0.935658\tvalid_1's auc: 0.895959                                                               \n",
      "[20000]\ttraining's auc: 0.936898\tvalid_1's auc: 0.896033                                                               \n",
      "[21000]\ttraining's auc: 0.93811\tvalid_1's auc: 0.896056                                                                \n",
      "[22000]\ttraining's auc: 0.939305\tvalid_1's auc: 0.896136                                                               \n",
      "[23000]\ttraining's auc: 0.940526\tvalid_1's auc: 0.896064                                                               \n",
      "[24000]\ttraining's auc: 0.941725\tvalid_1's auc: 0.89607                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21946]\ttraining's auc: 0.939239\tvalid_1's auc: 0.896152\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.854853\tvalid_1's auc: 0.841873                                                                \n",
      "[2000]\ttraining's auc: 0.884265\tvalid_1's auc: 0.868499                                                                \n",
      "[3000]\ttraining's auc: 0.89848\tvalid_1's auc: 0.880987                                                                 \n",
      "[4000]\ttraining's auc: 0.906981\tvalid_1's auc: 0.888254                                                                \n",
      "[5000]\ttraining's auc: 0.912575\tvalid_1's auc: 0.892155                                                                \n",
      "[6000]\ttraining's auc: 0.916584\tvalid_1's auc: 0.894782                                                                \n",
      "[7000]\ttraining's auc: 0.919575\tvalid_1's auc: 0.896051                                                                \n",
      "[8000]\ttraining's auc: 0.922044\tvalid_1's auc: 0.896986                                                                \n",
      "[9000]\ttraining's auc: 0.92424\tvalid_1's auc: 0.897644                                                                 \n",
      "[10000]\ttraining's auc: 0.926127\tvalid_1's auc: 0.898003                                                               \n",
      "[11000]\ttraining's auc: 0.927843\tvalid_1's auc: 0.898143                                                               \n",
      "[12000]\ttraining's auc: 0.929529\tvalid_1's auc: 0.89799                                                                \n",
      "[13000]\ttraining's auc: 0.931168\tvalid_1's auc: 0.897928                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10817]\ttraining's auc: 0.927544\tvalid_1's auc: 0.898168\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.856187\tvalid_1's auc: 0.832517                                                                \n",
      "[2000]\ttraining's auc: 0.887799\tvalid_1's auc: 0.861183                                                                \n",
      "[3000]\ttraining's auc: 0.902117\tvalid_1's auc: 0.873858                                                                \n",
      "[4000]\ttraining's auc: 0.910677\tvalid_1's auc: 0.880938                                                                \n",
      "[5000]\ttraining's auc: 0.916033\tvalid_1's auc: 0.885077                                                                \n",
      "[6000]\ttraining's auc: 0.920047\tvalid_1's auc: 0.887641                                                                \n",
      "[7000]\ttraining's auc: 0.923192\tvalid_1's auc: 0.889584                                                                \n",
      "[8000]\ttraining's auc: 0.925644\tvalid_1's auc: 0.890525                                                                \n",
      "[9000]\ttraining's auc: 0.927723\tvalid_1's auc: 0.891079                                                                \n",
      "[10000]\ttraining's auc: 0.929503\tvalid_1's auc: 0.891478                                                               \n",
      "[11000]\ttraining's auc: 0.931207\tvalid_1's auc: 0.891537                                                               \n",
      "[12000]\ttraining's auc: 0.932784\tvalid_1's auc: 0.891581                                                               \n",
      "[13000]\ttraining's auc: 0.934292\tvalid_1's auc: 0.891391                                                               \n",
      "[14000]\ttraining's auc: 0.935801\tvalid_1's auc: 0.891158                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11514]\ttraining's auc: 0.932024\tvalid_1's auc: 0.891661\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.856251\tvalid_1's auc: 0.840214                                                                \n",
      "[2000]\ttraining's auc: 0.885193\tvalid_1's auc: 0.867769                                                                \n",
      "[3000]\ttraining's auc: 0.899244\tvalid_1's auc: 0.879934                                                                \n",
      "[4000]\ttraining's auc: 0.90781\tvalid_1's auc: 0.887228                                                                 \n",
      "[5000]\ttraining's auc: 0.913285\tvalid_1's auc: 0.891079                                                                \n",
      "[6000]\ttraining's auc: 0.917284\tvalid_1's auc: 0.894224                                                                \n",
      "[7000]\ttraining's auc: 0.920302\tvalid_1's auc: 0.896248                                                                \n",
      "[8000]\ttraining's auc: 0.922741\tvalid_1's auc: 0.897754                                                                \n",
      "[9000]\ttraining's auc: 0.924878\tvalid_1's auc: 0.898351                                                                \n",
      "[10000]\ttraining's auc: 0.926781\tvalid_1's auc: 0.898957                                                               \n",
      "[11000]\ttraining's auc: 0.928485\tvalid_1's auc: 0.899075                                                               \n",
      "[12000]\ttraining's auc: 0.930092\tvalid_1's auc: 0.899383                                                               \n",
      "[13000]\ttraining's auc: 0.931739\tvalid_1's auc: 0.899456                                                               \n",
      "[14000]\ttraining's auc: 0.933252\tvalid_1's auc: 0.899515                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15000]\ttraining's auc: 0.934779\tvalid_1's auc: 0.89945                                                                \n",
      "[16000]\ttraining's auc: 0.936302\tvalid_1's auc: 0.899316                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13583]\ttraining's auc: 0.932585\tvalid_1's auc: 0.899577\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.855974\tvalid_1's auc: 0.839204                                                                \n",
      "[2000]\ttraining's auc: 0.886326\tvalid_1's auc: 0.866054                                                                \n",
      "[3000]\ttraining's auc: 0.9004\tvalid_1's auc: 0.877933                                                                  \n",
      "[4000]\ttraining's auc: 0.908738\tvalid_1's auc: 0.884559                                                                \n",
      "[5000]\ttraining's auc: 0.914439\tvalid_1's auc: 0.888767                                                                \n",
      "[6000]\ttraining's auc: 0.918479\tvalid_1's auc: 0.89108                                                                 \n",
      "[7000]\ttraining's auc: 0.921629\tvalid_1's auc: 0.892793                                                                \n",
      "[8000]\ttraining's auc: 0.924199\tvalid_1's auc: 0.893953                                                                \n",
      "[9000]\ttraining's auc: 0.926453\tvalid_1's auc: 0.894906                                                                \n",
      "[10000]\ttraining's auc: 0.928332\tvalid_1's auc: 0.895325                                                               \n",
      "[11000]\ttraining's auc: 0.930106\tvalid_1's auc: 0.895592                                                               \n",
      "[12000]\ttraining's auc: 0.931782\tvalid_1's auc: 0.895678                                                               \n",
      "[13000]\ttraining's auc: 0.93335\tvalid_1's auc: 0.895706                                                                \n",
      "[14000]\ttraining's auc: 0.934911\tvalid_1's auc: 0.895889                                                               \n",
      "[15000]\ttraining's auc: 0.936338\tvalid_1's auc: 0.895695                                                               \n",
      "[16000]\ttraining's auc: 0.937839\tvalid_1's auc: 0.895741                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13737]\ttraining's auc: 0.934487\tvalid_1's auc: 0.895912\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.853004\tvalid_1's auc: 0.839651                                                                \n",
      "[2000]\ttraining's auc: 0.882226\tvalid_1's auc: 0.866307                                                                \n",
      "[3000]\ttraining's auc: 0.897387\tvalid_1's auc: 0.879099                                                                \n",
      "[4000]\ttraining's auc: 0.906548\tvalid_1's auc: 0.886117                                                                \n",
      "[5000]\ttraining's auc: 0.912843\tvalid_1's auc: 0.890441                                                                \n",
      "[6000]\ttraining's auc: 0.917591\tvalid_1's auc: 0.893327                                                                \n",
      "[7000]\ttraining's auc: 0.92131\tvalid_1's auc: 0.895301                                                                 \n",
      "[8000]\ttraining's auc: 0.924497\tvalid_1's auc: 0.896423                                                                \n",
      "[9000]\ttraining's auc: 0.927249\tvalid_1's auc: 0.897112                                                                \n",
      "[10000]\ttraining's auc: 0.92976\tvalid_1's auc: 0.897631                                                                \n",
      "[11000]\ttraining's auc: 0.932212\tvalid_1's auc: 0.897962                                                               \n",
      "[12000]\ttraining's auc: 0.934617\tvalid_1's auc: 0.89824                                                                \n",
      "[13000]\ttraining's auc: 0.936942\tvalid_1's auc: 0.898394                                                               \n",
      "[14000]\ttraining's auc: 0.939105\tvalid_1's auc: 0.898337                                                               \n",
      "[15000]\ttraining's auc: 0.941199\tvalid_1's auc: 0.898398                                                               \n",
      "[16000]\ttraining's auc: 0.943205\tvalid_1's auc: 0.898155                                                               \n",
      "[17000]\ttraining's auc: 0.945254\tvalid_1's auc: 0.897947                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14595]\ttraining's auc: 0.94034\tvalid_1's auc: 0.898434\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.855429\tvalid_1's auc: 0.832411                                                                \n",
      "[2000]\ttraining's auc: 0.885271\tvalid_1's auc: 0.85896                                                                 \n",
      "[3000]\ttraining's auc: 0.900832\tvalid_1's auc: 0.872132                                                                \n",
      "[4000]\ttraining's auc: 0.910124\tvalid_1's auc: 0.879424                                                                \n",
      "[5000]\ttraining's auc: 0.916496\tvalid_1's auc: 0.883646                                                                \n",
      "[6000]\ttraining's auc: 0.921023\tvalid_1's auc: 0.886351                                                                \n",
      "[7000]\ttraining's auc: 0.924663\tvalid_1's auc: 0.888053                                                                \n",
      "[8000]\ttraining's auc: 0.927775\tvalid_1's auc: 0.889299                                                                \n",
      "[9000]\ttraining's auc: 0.930467\tvalid_1's auc: 0.88998                                                                 \n",
      "[10000]\ttraining's auc: 0.932894\tvalid_1's auc: 0.890385                                                               \n",
      "[11000]\ttraining's auc: 0.935255\tvalid_1's auc: 0.89065                                                                \n",
      "[12000]\ttraining's auc: 0.937502\tvalid_1's auc: 0.890672                                                               \n",
      "[13000]\ttraining's auc: 0.93966\tvalid_1's auc: 0.89081                                                                 \n",
      "[14000]\ttraining's auc: 0.941703\tvalid_1's auc: 0.890801                                                               \n",
      "[15000]\ttraining's auc: 0.943711\tvalid_1's auc: 0.890798                                                               \n",
      "[16000]\ttraining's auc: 0.945638\tvalid_1's auc: 0.890765                                                               \n",
      "[17000]\ttraining's auc: 0.947538\tvalid_1's auc: 0.890656                                                               \n",
      "[18000]\ttraining's auc: 0.949451\tvalid_1's auc: 0.890525                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15505]\ttraining's auc: 0.944701\tvalid_1's auc: 0.890847\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.854652\tvalid_1's auc: 0.83854                                                                 \n",
      "[2000]\ttraining's auc: 0.883657\tvalid_1's auc: 0.864797                                                                \n",
      "[3000]\ttraining's auc: 0.898778\tvalid_1's auc: 0.877992                                                                \n",
      "[4000]\ttraining's auc: 0.907881\tvalid_1's auc: 0.88525                                                                 \n",
      "[5000]\ttraining's auc: 0.914117\tvalid_1's auc: 0.889739                                                                \n",
      "[6000]\ttraining's auc: 0.918788\tvalid_1's auc: 0.892924                                                                \n",
      "[7000]\ttraining's auc: 0.922426\tvalid_1's auc: 0.895043                                                                \n",
      "[8000]\ttraining's auc: 0.925502\tvalid_1's auc: 0.89636                                                                 \n",
      "[9000]\ttraining's auc: 0.928291\tvalid_1's auc: 0.897333                                                                \n",
      "[10000]\ttraining's auc: 0.930784\tvalid_1's auc: 0.898049                                                               \n",
      "[11000]\ttraining's auc: 0.933213\tvalid_1's auc: 0.898511                                                               \n",
      "[12000]\ttraining's auc: 0.935463\tvalid_1's auc: 0.898654                                                               \n",
      "[13000]\ttraining's auc: 0.937685\tvalid_1's auc: 0.898813                                                               \n",
      "[14000]\ttraining's auc: 0.93981\tvalid_1's auc: 0.898923                                                                \n",
      "[15000]\ttraining's auc: 0.941879\tvalid_1's auc: 0.89903                                                                \n",
      "[16000]\ttraining's auc: 0.943911\tvalid_1's auc: 0.899099                                                               \n",
      "[17000]\ttraining's auc: 0.945911\tvalid_1's auc: 0.899128                                                               \n",
      "[18000]\ttraining's auc: 0.947832\tvalid_1's auc: 0.89915                                                                \n",
      "[19000]\ttraining's auc: 0.94968\tvalid_1's auc: 0.899224                                                                \n",
      "[20000]\ttraining's auc: 0.951504\tvalid_1's auc: 0.899247                                                               \n",
      "[21000]\ttraining's auc: 0.953292\tvalid_1's auc: 0.899155                                                               \n",
      "[22000]\ttraining's auc: 0.955002\tvalid_1's auc: 0.899084                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19809]\ttraining's auc: 0.951156\tvalid_1's auc: 0.899306\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.855462\tvalid_1's auc: 0.838604                                                                \n",
      "[2000]\ttraining's auc: 0.884849\tvalid_1's auc: 0.864146                                                                \n",
      "[3000]\ttraining's auc: 0.899537\tvalid_1's auc: 0.876411                                                                \n",
      "[4000]\ttraining's auc: 0.908575\tvalid_1's auc: 0.883337                                                                \n",
      "[5000]\ttraining's auc: 0.914777\tvalid_1's auc: 0.887652                                                                \n",
      "[6000]\ttraining's auc: 0.919604\tvalid_1's auc: 0.890516                                                                \n",
      "[7000]\ttraining's auc: 0.923359\tvalid_1's auc: 0.892546                                                                \n",
      "[8000]\ttraining's auc: 0.926565\tvalid_1's auc: 0.893793                                                                \n",
      "[9000]\ttraining's auc: 0.92942\tvalid_1's auc: 0.894816                                                                 \n",
      "[10000]\ttraining's auc: 0.931989\tvalid_1's auc: 0.895448                                                               \n",
      "[11000]\ttraining's auc: 0.934406\tvalid_1's auc: 0.895737                                                               \n",
      "[12000]\ttraining's auc: 0.936627\tvalid_1's auc: 0.89598                                                                \n",
      "[13000]\ttraining's auc: 0.938813\tvalid_1's auc: 0.8962                                                                 \n",
      "[14000]\ttraining's auc: 0.940892\tvalid_1's auc: 0.896373                                                               \n",
      "[15000]\ttraining's auc: 0.942965\tvalid_1's auc: 0.896561                                                               \n",
      "[16000]\ttraining's auc: 0.944939\tvalid_1's auc: 0.89656                                                                \n",
      "[17000]\ttraining's auc: 0.946843\tvalid_1's auc: 0.896631                                                               \n",
      "[18000]\ttraining's auc: 0.948706\tvalid_1's auc: 0.896658                                                               \n",
      "[19000]\ttraining's auc: 0.950548\tvalid_1's auc: 0.896667                                                               \n",
      "[20000]\ttraining's auc: 0.952291\tvalid_1's auc: 0.896597                                                               \n",
      "[21000]\ttraining's auc: 0.954032\tvalid_1's auc: 0.896602                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18967]\ttraining's auc: 0.950489\tvalid_1's auc: 0.896689\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.889458\tvalid_1's auc: 0.861187                                                                \n",
      "[2000]\ttraining's auc: 0.917342\tvalid_1's auc: 0.88242                                                                 \n",
      "[3000]\ttraining's auc: 0.931205\tvalid_1's auc: 0.891274                                                                \n",
      "[4000]\ttraining's auc: 0.93974\tvalid_1's auc: 0.895052                                                                 \n",
      "[5000]\ttraining's auc: 0.945916\tvalid_1's auc: 0.896723                                                                \n",
      "[6000]\ttraining's auc: 0.95112\tvalid_1's auc: 0.897625                                                                 \n",
      "[7000]\ttraining's auc: 0.955575\tvalid_1's auc: 0.897833                                                                \n",
      "[8000]\ttraining's auc: 0.959637\tvalid_1's auc: 0.897661                                                                \n",
      "[9000]\ttraining's auc: 0.963607\tvalid_1's auc: 0.897437                                                                \n",
      "[10000]\ttraining's auc: 0.967163\tvalid_1's auc: 0.897094                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7105]\ttraining's auc: 0.956004\tvalid_1's auc: 0.897912\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.892645\tvalid_1's auc: 0.852528                                                                \n",
      "[2000]\ttraining's auc: 0.920706\tvalid_1's auc: 0.874108                                                                \n",
      "[3000]\ttraining's auc: 0.934119\tvalid_1's auc: 0.883615                                                                \n",
      "[4000]\ttraining's auc: 0.942521\tvalid_1's auc: 0.88799                                                                 \n",
      "[5000]\ttraining's auc: 0.948422\tvalid_1's auc: 0.889755                                                                \n",
      "[6000]\ttraining's auc: 0.953333\tvalid_1's auc: 0.890429                                                                \n",
      "[7000]\ttraining's auc: 0.957607\tvalid_1's auc: 0.890469                                                                \n",
      "[8000]\ttraining's auc: 0.961639\tvalid_1's auc: 0.890254                                                                \n",
      "[9000]\ttraining's auc: 0.965193\tvalid_1's auc: 0.890108                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6788]\ttraining's auc: 0.956677\tvalid_1's auc: 0.89053\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.891874\tvalid_1's auc: 0.859795                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's auc: 0.919129\tvalid_1's auc: 0.881046                                                                \n",
      "[3000]\ttraining's auc: 0.932411\tvalid_1's auc: 0.889455                                                                \n",
      "[4000]\ttraining's auc: 0.940723\tvalid_1's auc: 0.893501                                                                \n",
      "[5000]\ttraining's auc: 0.94683\tvalid_1's auc: 0.895447                                                                 \n",
      "[6000]\ttraining's auc: 0.951756\tvalid_1's auc: 0.89648                                                                 \n",
      "[7000]\ttraining's auc: 0.95606\tvalid_1's auc: 0.897236                                                                 \n",
      "[8000]\ttraining's auc: 0.960106\tvalid_1's auc: 0.897363                                                                \n",
      "[9000]\ttraining's auc: 0.963994\tvalid_1's auc: 0.897345                                                                \n",
      "[10000]\ttraining's auc: 0.967502\tvalid_1's auc: 0.897207                                                               \n",
      "[11000]\ttraining's auc: 0.970833\tvalid_1's auc: 0.897084                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8022]\ttraining's auc: 0.960191\tvalid_1's auc: 0.89738\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.893622\tvalid_1's auc: 0.859666                                                                \n",
      "[2000]\ttraining's auc: 0.919995\tvalid_1's auc: 0.879332                                                                \n",
      "[3000]\ttraining's auc: 0.933227\tvalid_1's auc: 0.888039                                                                \n",
      "[4000]\ttraining's auc: 0.941811\tvalid_1's auc: 0.892157                                                                \n",
      "[5000]\ttraining's auc: 0.948032\tvalid_1's auc: 0.893826                                                                \n",
      "[6000]\ttraining's auc: 0.952952\tvalid_1's auc: 0.894381                                                                \n",
      "[7000]\ttraining's auc: 0.957205\tvalid_1's auc: 0.894571                                                                \n",
      "[8000]\ttraining's auc: 0.961045\tvalid_1's auc: 0.894674                                                                \n",
      "[9000]\ttraining's auc: 0.964777\tvalid_1's auc: 0.894355                                                                \n",
      "[10000]\ttraining's auc: 0.968098\tvalid_1's auc: 0.89422                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7795]\ttraining's auc: 0.960277\tvalid_1's auc: 0.894709\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.886847\tvalid_1's auc: 0.866244                                                                \n",
      "[2000]\ttraining's auc: 0.913059\tvalid_1's auc: 0.886516                                                                \n",
      "[3000]\ttraining's auc: 0.925245\tvalid_1's auc: 0.893864                                                                \n",
      "[4000]\ttraining's auc: 0.933105\tvalid_1's auc: 0.897177                                                                \n",
      "[5000]\ttraining's auc: 0.939175\tvalid_1's auc: 0.898063                                                                \n",
      "[6000]\ttraining's auc: 0.944532\tvalid_1's auc: 0.898301                                                                \n",
      "[7000]\ttraining's auc: 0.949623\tvalid_1's auc: 0.898381                                                                \n",
      "[8000]\ttraining's auc: 0.954355\tvalid_1's auc: 0.897947                                                                \n",
      "[9000]\ttraining's auc: 0.958721\tvalid_1's auc: 0.897698                                                                \n",
      "[10000]\ttraining's auc: 0.962911\tvalid_1's auc: 0.897407                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7101]\ttraining's auc: 0.950118\tvalid_1's auc: 0.898441\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.889581\tvalid_1's auc: 0.858358                                                                \n",
      "[2000]\ttraining's auc: 0.916551\tvalid_1's auc: 0.878987                                                                \n",
      "[3000]\ttraining's auc: 0.928552\tvalid_1's auc: 0.886362                                                                \n",
      "[4000]\ttraining's auc: 0.936057\tvalid_1's auc: 0.889448                                                                \n",
      "[5000]\ttraining's auc: 0.941797\tvalid_1's auc: 0.890564                                                                \n",
      "[6000]\ttraining's auc: 0.946972\tvalid_1's auc: 0.890677                                                                \n",
      "[7000]\ttraining's auc: 0.951796\tvalid_1's auc: 0.890569                                                                \n",
      "[8000]\ttraining's auc: 0.956378\tvalid_1's auc: 0.890246                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5334]\ttraining's auc: 0.943531\tvalid_1's auc: 0.890835\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.888078\tvalid_1's auc: 0.863863                                                                \n",
      "[2000]\ttraining's auc: 0.914633\tvalid_1's auc: 0.885492                                                                \n",
      "[3000]\ttraining's auc: 0.926414\tvalid_1's auc: 0.89305                                                                 \n",
      "[4000]\ttraining's auc: 0.933925\tvalid_1's auc: 0.896195                                                                \n",
      "[5000]\ttraining's auc: 0.939768\tvalid_1's auc: 0.89752                                                                 \n",
      "[6000]\ttraining's auc: 0.945173\tvalid_1's auc: 0.89808                                                                 \n",
      "[7000]\ttraining's auc: 0.950219\tvalid_1's auc: 0.898244                                                                \n",
      "[8000]\ttraining's auc: 0.954936\tvalid_1's auc: 0.898157                                                                \n",
      "[9000]\ttraining's auc: 0.95931\tvalid_1's auc: 0.897637                                                                 \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6916]\ttraining's auc: 0.949774\tvalid_1's auc: 0.898349\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.888965\tvalid_1's auc: 0.86383                                                                 \n",
      "[2000]\ttraining's auc: 0.915228\tvalid_1's auc: 0.883308                                                                \n",
      "[3000]\ttraining's auc: 0.927422\tvalid_1's auc: 0.890678                                                                \n",
      "[4000]\ttraining's auc: 0.93508\tvalid_1's auc: 0.893644                                                                 \n",
      "[5000]\ttraining's auc: 0.941036\tvalid_1's auc: 0.894958                                                                \n",
      "[6000]\ttraining's auc: 0.946286\tvalid_1's auc: 0.895606                                                                \n",
      "[7000]\ttraining's auc: 0.951121\tvalid_1's auc: 0.895586                                                                \n",
      "[8000]\ttraining's auc: 0.955757\tvalid_1's auc: 0.895492                                                                \n",
      "[9000]\ttraining's auc: 0.960106\tvalid_1's auc: 0.895196                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6665]\ttraining's auc: 0.949527\tvalid_1's auc: 0.895727\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.887291\tvalid_1's auc: 0.870045                                                                \n",
      "[2000]\ttraining's auc: 0.911339\tvalid_1's auc: 0.888308                                                                \n",
      "[3000]\ttraining's auc: 0.922316\tvalid_1's auc: 0.895022                                                                \n",
      "[4000]\ttraining's auc: 0.929624\tvalid_1's auc: 0.897752                                                                \n",
      "[5000]\ttraining's auc: 0.935603\tvalid_1's auc: 0.898424                                                                \n",
      "[6000]\ttraining's auc: 0.941004\tvalid_1's auc: 0.898471                                                                \n",
      "[7000]\ttraining's auc: 0.945963\tvalid_1's auc: 0.89848                                                                 \n",
      "[8000]\ttraining's auc: 0.950611\tvalid_1's auc: 0.898059                                                                \n",
      "[9000]\ttraining's auc: 0.95495\tvalid_1's auc: 0.897329                                                                 \n",
      "[10000]\ttraining's auc: 0.959056\tvalid_1's auc: 0.897217                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7101]\ttraining's auc: 0.946427\tvalid_1's auc: 0.898553\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.890231\tvalid_1's auc: 0.862184                                                                \n",
      "[2000]\ttraining's auc: 0.914757\tvalid_1's auc: 0.88127                                                                 \n",
      "[3000]\ttraining's auc: 0.925604\tvalid_1's auc: 0.887599                                                                \n",
      "[4000]\ttraining's auc: 0.932856\tvalid_1's auc: 0.890192                                                                \n",
      "[5000]\ttraining's auc: 0.938471\tvalid_1's auc: 0.890497                                                                \n",
      "[6000]\ttraining's auc: 0.943656\tvalid_1's auc: 0.890613                                                                \n",
      "[7000]\ttraining's auc: 0.948314\tvalid_1's auc: 0.890346                                                                \n",
      "[8000]\ttraining's auc: 0.952761\tvalid_1's auc: 0.890055                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[5387]\ttraining's auc: 0.940574\tvalid_1's auc: 0.890784\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.888455\tvalid_1's auc: 0.867875                                                                \n",
      "[2000]\ttraining's auc: 0.912373\tvalid_1's auc: 0.887553                                                                \n",
      "[3000]\ttraining's auc: 0.923196\tvalid_1's auc: 0.893665                                                                \n",
      "[4000]\ttraining's auc: 0.930356\tvalid_1's auc: 0.896538                                                                \n",
      "[5000]\ttraining's auc: 0.936189\tvalid_1's auc: 0.897519                                                                \n",
      "[6000]\ttraining's auc: 0.941509\tvalid_1's auc: 0.898117                                                                \n",
      "[7000]\ttraining's auc: 0.946484\tvalid_1's auc: 0.897989                                                                \n",
      "[8000]\ttraining's auc: 0.951133\tvalid_1's auc: 0.897883                                                                \n",
      "[9000]\ttraining's auc: 0.955421\tvalid_1's auc: 0.897624                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6306]\ttraining's auc: 0.94307\tvalid_1's auc: 0.89825\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.889582\tvalid_1's auc: 0.867149                                                                \n",
      "[2000]\ttraining's auc: 0.913204\tvalid_1's auc: 0.88536                                                                 \n",
      "[3000]\ttraining's auc: 0.924404\tvalid_1's auc: 0.891597                                                                \n",
      "[4000]\ttraining's auc: 0.93171\tvalid_1's auc: 0.894015                                                                 \n",
      "[5000]\ttraining's auc: 0.937583\tvalid_1's auc: 0.895059                                                                \n",
      "[6000]\ttraining's auc: 0.942849\tvalid_1's auc: 0.895265                                                                \n",
      "[7000]\ttraining's auc: 0.947622\tvalid_1's auc: 0.895547                                                                \n",
      "[8000]\ttraining's auc: 0.952139\tvalid_1's auc: 0.89534                                                                 \n",
      "[9000]\ttraining's auc: 0.956342\tvalid_1's auc: 0.895579                                                                \n",
      "[10000]\ttraining's auc: 0.960176\tvalid_1's auc: 0.895472                                                               \n",
      "[11000]\ttraining's auc: 0.963846\tvalid_1's auc: 0.895257                                                               \n",
      "[12000]\ttraining's auc: 0.967298\tvalid_1's auc: 0.894992                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9295]\ttraining's auc: 0.957489\tvalid_1's auc: 0.895621\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.841619\tvalid_1's auc: 0.831462                                                                \n",
      "[2000]\ttraining's auc: 0.852496\tvalid_1's auc: 0.842194                                                                \n",
      "[3000]\ttraining's auc: 0.863997\tvalid_1's auc: 0.853285                                                                \n",
      "[4000]\ttraining's auc: 0.873356\tvalid_1's auc: 0.861949                                                                \n",
      "[5000]\ttraining's auc: 0.880697\tvalid_1's auc: 0.868517                                                                \n",
      "[6000]\ttraining's auc: 0.886726\tvalid_1's auc: 0.873898                                                                \n",
      "[7000]\ttraining's auc: 0.891787\tvalid_1's auc: 0.878208                                                                \n",
      "[8000]\ttraining's auc: 0.895954\tvalid_1's auc: 0.881555                                                                \n",
      "[9000]\ttraining's auc: 0.899682\tvalid_1's auc: 0.884561                                                                \n",
      "[10000]\ttraining's auc: 0.902724\tvalid_1's auc: 0.886898                                                               \n",
      "[11000]\ttraining's auc: 0.905386\tvalid_1's auc: 0.888888                                                               \n",
      "[12000]\ttraining's auc: 0.907664\tvalid_1's auc: 0.89052                                                                \n",
      "[13000]\ttraining's auc: 0.9098\tvalid_1's auc: 0.892007                                                                 \n",
      "[14000]\ttraining's auc: 0.91168\tvalid_1's auc: 0.893268                                                                \n",
      "[15000]\ttraining's auc: 0.913371\tvalid_1's auc: 0.894267                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16000]\ttraining's auc: 0.914839\tvalid_1's auc: 0.895088                                                               \n",
      "[17000]\ttraining's auc: 0.916236\tvalid_1's auc: 0.895807                                                               \n",
      "[18000]\ttraining's auc: 0.917521\tvalid_1's auc: 0.896302                                                               \n",
      "[19000]\ttraining's auc: 0.918741\tvalid_1's auc: 0.896764                                                               \n",
      "[20000]\ttraining's auc: 0.919875\tvalid_1's auc: 0.897164                                                               \n",
      "[21000]\ttraining's auc: 0.920953\tvalid_1's auc: 0.897476                                                               \n",
      "[22000]\ttraining's auc: 0.921993\tvalid_1's auc: 0.897741                                                               \n",
      "[23000]\ttraining's auc: 0.923028\tvalid_1's auc: 0.897968                                                               \n",
      "[24000]\ttraining's auc: 0.924011\tvalid_1's auc: 0.898193                                                               \n",
      "[25000]\ttraining's auc: 0.924935\tvalid_1's auc: 0.898328                                                               \n",
      "[26000]\ttraining's auc: 0.92583\tvalid_1's auc: 0.898486                                                                \n",
      "[27000]\ttraining's auc: 0.926717\tvalid_1's auc: 0.898555                                                               \n",
      "[28000]\ttraining's auc: 0.927586\tvalid_1's auc: 0.898739                                                               \n",
      "[29000]\ttraining's auc: 0.928446\tvalid_1's auc: 0.898819                                                               \n",
      "[30000]\ttraining's auc: 0.929266\tvalid_1's auc: 0.898933                                                               \n",
      "[31000]\ttraining's auc: 0.930077\tvalid_1's auc: 0.89898                                                                \n",
      "[32000]\ttraining's auc: 0.930867\tvalid_1's auc: 0.899005                                                               \n",
      "[33000]\ttraining's auc: 0.931658\tvalid_1's auc: 0.899051                                                               \n",
      "[34000]\ttraining's auc: 0.932433\tvalid_1's auc: 0.899105                                                               \n",
      "[35000]\ttraining's auc: 0.933219\tvalid_1's auc: 0.899141                                                               \n",
      "[36000]\ttraining's auc: 0.93397\tvalid_1's auc: 0.899195                                                                \n",
      "[37000]\ttraining's auc: 0.934728\tvalid_1's auc: 0.899151                                                               \n",
      "[38000]\ttraining's auc: 0.935471\tvalid_1's auc: 0.899131                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35848]\ttraining's auc: 0.93386\tvalid_1's auc: 0.899213\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.843812\tvalid_1's auc: 0.824088                                                                \n",
      "[2000]\ttraining's auc: 0.855357\tvalid_1's auc: 0.834806                                                                \n",
      "[3000]\ttraining's auc: 0.866183\tvalid_1's auc: 0.845056                                                                \n",
      "[4000]\ttraining's auc: 0.875755\tvalid_1's auc: 0.85396                                                                 \n",
      "[5000]\ttraining's auc: 0.883484\tvalid_1's auc: 0.860611                                                                \n",
      "[6000]\ttraining's auc: 0.889921\tvalid_1's auc: 0.866034                                                                \n",
      "[7000]\ttraining's auc: 0.895069\tvalid_1's auc: 0.870404                                                                \n",
      "[8000]\ttraining's auc: 0.89939\tvalid_1's auc: 0.874006                                                                 \n",
      "[9000]\ttraining's auc: 0.903099\tvalid_1's auc: 0.876872                                                                \n",
      "[10000]\ttraining's auc: 0.906165\tvalid_1's auc: 0.879134                                                               \n",
      "[11000]\ttraining's auc: 0.90887\tvalid_1's auc: 0.881293                                                                \n",
      "[12000]\ttraining's auc: 0.9113\tvalid_1's auc: 0.882975                                                                 \n",
      "[13000]\ttraining's auc: 0.913326\tvalid_1's auc: 0.884427                                                               \n",
      "[14000]\ttraining's auc: 0.915183\tvalid_1's auc: 0.885665                                                               \n",
      "[15000]\ttraining's auc: 0.916837\tvalid_1's auc: 0.886657                                                               \n",
      "[16000]\ttraining's auc: 0.918381\tvalid_1's auc: 0.887609                                                               \n",
      "[17000]\ttraining's auc: 0.919778\tvalid_1's auc: 0.888333                                                               \n",
      "[18000]\ttraining's auc: 0.921056\tvalid_1's auc: 0.888921                                                               \n",
      "[19000]\ttraining's auc: 0.922235\tvalid_1's auc: 0.889505                                                               \n",
      "[20000]\ttraining's auc: 0.923356\tvalid_1's auc: 0.889912                                                               \n",
      "[21000]\ttraining's auc: 0.924438\tvalid_1's auc: 0.890304                                                               \n",
      "[22000]\ttraining's auc: 0.92545\tvalid_1's auc: 0.890625                                                                \n",
      "[23000]\ttraining's auc: 0.926432\tvalid_1's auc: 0.890878                                                               \n",
      "[24000]\ttraining's auc: 0.92738\tvalid_1's auc: 0.891117                                                                \n",
      "[25000]\ttraining's auc: 0.928271\tvalid_1's auc: 0.891279                                                               \n",
      "[26000]\ttraining's auc: 0.929147\tvalid_1's auc: 0.891364                                                               \n",
      "[27000]\ttraining's auc: 0.929977\tvalid_1's auc: 0.891455                                                               \n",
      "[28000]\ttraining's auc: 0.930782\tvalid_1's auc: 0.891612                                                               \n",
      "[29000]\ttraining's auc: 0.931571\tvalid_1's auc: 0.891708                                                               \n",
      "[30000]\ttraining's auc: 0.932347\tvalid_1's auc: 0.89178                                                                \n",
      "[31000]\ttraining's auc: 0.933122\tvalid_1's auc: 0.891873                                                               \n",
      "[32000]\ttraining's auc: 0.933887\tvalid_1's auc: 0.891919                                                               \n",
      "[33000]\ttraining's auc: 0.934639\tvalid_1's auc: 0.891941                                                               \n",
      "[34000]\ttraining's auc: 0.935355\tvalid_1's auc: 0.891997                                                               \n",
      "[35000]\ttraining's auc: 0.93606\tvalid_1's auc: 0.891926                                                                \n",
      "[36000]\ttraining's auc: 0.936782\tvalid_1's auc: 0.891919                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33524]\ttraining's auc: 0.935041\tvalid_1's auc: 0.892007\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.842243\tvalid_1's auc: 0.832055                                                                \n",
      "[2000]\ttraining's auc: 0.853575\tvalid_1's auc: 0.841479                                                                \n",
      "[3000]\ttraining's auc: 0.864636\tvalid_1's auc: 0.851222                                                                \n",
      "[4000]\ttraining's auc: 0.873983\tvalid_1's auc: 0.859539                                                                \n",
      "[5000]\ttraining's auc: 0.881469\tvalid_1's auc: 0.86598                                                                 \n",
      "[6000]\ttraining's auc: 0.888007\tvalid_1's auc: 0.871747                                                                \n",
      "[7000]\ttraining's auc: 0.892991\tvalid_1's auc: 0.876117                                                                \n",
      "[8000]\ttraining's auc: 0.897231\tvalid_1's auc: 0.879769                                                                \n",
      "[9000]\ttraining's auc: 0.900827\tvalid_1's auc: 0.882703                                                                \n",
      "[10000]\ttraining's auc: 0.90371\tvalid_1's auc: 0.885023                                                                \n",
      "[11000]\ttraining's auc: 0.906451\tvalid_1's auc: 0.887247                                                               \n",
      "[12000]\ttraining's auc: 0.908841\tvalid_1's auc: 0.889097                                                               \n",
      "[13000]\ttraining's auc: 0.910869\tvalid_1's auc: 0.890535                                                               \n",
      "[14000]\ttraining's auc: 0.912761\tvalid_1's auc: 0.891907                                                               \n",
      "[15000]\ttraining's auc: 0.914383\tvalid_1's auc: 0.892972                                                               \n",
      "[16000]\ttraining's auc: 0.915863\tvalid_1's auc: 0.893912                                                               \n",
      "[17000]\ttraining's auc: 0.917268\tvalid_1's auc: 0.894737                                                               \n",
      "[18000]\ttraining's auc: 0.918572\tvalid_1's auc: 0.895371                                                               \n",
      "[19000]\ttraining's auc: 0.919788\tvalid_1's auc: 0.895924                                                               \n",
      "[20000]\ttraining's auc: 0.920864\tvalid_1's auc: 0.896331                                                               \n",
      "[21000]\ttraining's auc: 0.921938\tvalid_1's auc: 0.896745                                                               \n",
      "[22000]\ttraining's auc: 0.922966\tvalid_1's auc: 0.897124                                                               \n",
      "[23000]\ttraining's auc: 0.923961\tvalid_1's auc: 0.89748                                                                \n",
      "[24000]\ttraining's auc: 0.924903\tvalid_1's auc: 0.897745                                                               \n",
      "[25000]\ttraining's auc: 0.925786\tvalid_1's auc: 0.898031                                                               \n",
      "[26000]\ttraining's auc: 0.926692\tvalid_1's auc: 0.898212                                                               \n",
      "[27000]\ttraining's auc: 0.927546\tvalid_1's auc: 0.898413                                                               \n",
      "[28000]\ttraining's auc: 0.928395\tvalid_1's auc: 0.898654                                                               \n",
      "[29000]\ttraining's auc: 0.929224\tvalid_1's auc: 0.898775                                                               \n",
      "[30000]\ttraining's auc: 0.930018\tvalid_1's auc: 0.898941                                                               \n",
      "[31000]\ttraining's auc: 0.930818\tvalid_1's auc: 0.899084                                                               \n",
      "[32000]\ttraining's auc: 0.931602\tvalid_1's auc: 0.899164                                                               \n",
      "[33000]\ttraining's auc: 0.932378\tvalid_1's auc: 0.899226                                                               \n",
      "[34000]\ttraining's auc: 0.933157\tvalid_1's auc: 0.899263                                                               \n",
      "[35000]\ttraining's auc: 0.933884\tvalid_1's auc: 0.899282                                                               \n",
      "[36000]\ttraining's auc: 0.934629\tvalid_1's auc: 0.899323                                                               \n",
      "[37000]\ttraining's auc: 0.935366\tvalid_1's auc: 0.899415                                                               \n",
      "[38000]\ttraining's auc: 0.936081\tvalid_1's auc: 0.899501                                                               \n",
      "[39000]\ttraining's auc: 0.936811\tvalid_1's auc: 0.899547                                                               \n",
      "[40000]\ttraining's auc: 0.937509\tvalid_1's auc: 0.899573                                                               \n",
      "[41000]\ttraining's auc: 0.938204\tvalid_1's auc: 0.899553                                                               \n",
      "[42000]\ttraining's auc: 0.938906\tvalid_1's auc: 0.899598                                                               \n",
      "[43000]\ttraining's auc: 0.939599\tvalid_1's auc: 0.899612                                                               \n",
      "[44000]\ttraining's auc: 0.940293\tvalid_1's auc: 0.89961                                                                \n",
      "[45000]\ttraining's auc: 0.940965\tvalid_1's auc: 0.899594                                                               \n",
      "[46000]\ttraining's auc: 0.941637\tvalid_1's auc: 0.899573                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43675]\ttraining's auc: 0.940074\tvalid_1's auc: 0.899634\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.842044\tvalid_1's auc: 0.829419                                                                \n",
      "[2000]\ttraining's auc: 0.854649\tvalid_1's auc: 0.841051                                                                \n",
      "[3000]\ttraining's auc: 0.865852\tvalid_1's auc: 0.850872                                                                \n",
      "[4000]\ttraining's auc: 0.875522\tvalid_1's auc: 0.858932                                                                \n",
      "[5000]\ttraining's auc: 0.88293\tvalid_1's auc: 0.865352                                                                 \n",
      "[6000]\ttraining's auc: 0.889118\tvalid_1's auc: 0.870826                                                                \n",
      "[7000]\ttraining's auc: 0.894069\tvalid_1's auc: 0.874742                                                                \n",
      "[8000]\ttraining's auc: 0.89827\tvalid_1's auc: 0.878109                                                                 \n",
      "[9000]\ttraining's auc: 0.901931\tvalid_1's auc: 0.881023                                                                \n",
      "[10000]\ttraining's auc: 0.905007\tvalid_1's auc: 0.883289                                                               \n",
      "[11000]\ttraining's auc: 0.907644\tvalid_1's auc: 0.885263                                                               \n",
      "[12000]\ttraining's auc: 0.909985\tvalid_1's auc: 0.88687                                                                \n",
      "[13000]\ttraining's auc: 0.91201\tvalid_1's auc: 0.88828                                                                 \n",
      "[14000]\ttraining's auc: 0.913845\tvalid_1's auc: 0.889414                                                               \n",
      "[15000]\ttraining's auc: 0.915486\tvalid_1's auc: 0.890383                                                               \n",
      "[16000]\ttraining's auc: 0.917029\tvalid_1's auc: 0.891319                                                               \n",
      "[17000]\ttraining's auc: 0.918454\tvalid_1's auc: 0.891984                                                               \n",
      "[18000]\ttraining's auc: 0.919733\tvalid_1's auc: 0.892704                                                               \n",
      "[19000]\ttraining's auc: 0.920937\tvalid_1's auc: 0.893259                                                               \n",
      "[20000]\ttraining's auc: 0.922111\tvalid_1's auc: 0.893788                                                               \n",
      "[21000]\ttraining's auc: 0.92323\tvalid_1's auc: 0.894179                                                                \n",
      "[22000]\ttraining's auc: 0.924259\tvalid_1's auc: 0.894562                                                               \n",
      "[23000]\ttraining's auc: 0.925253\tvalid_1's auc: 0.894874                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24000]\ttraining's auc: 0.926195\tvalid_1's auc: 0.895147                                                               \n",
      "[25000]\ttraining's auc: 0.927097\tvalid_1's auc: 0.895305                                                               \n",
      "[26000]\ttraining's auc: 0.927988\tvalid_1's auc: 0.895445                                                               \n",
      "[27000]\ttraining's auc: 0.928855\tvalid_1's auc: 0.895567                                                               \n",
      "[28000]\ttraining's auc: 0.929686\tvalid_1's auc: 0.895787                                                               \n",
      "[29000]\ttraining's auc: 0.930516\tvalid_1's auc: 0.895923                                                               \n",
      "[30000]\ttraining's auc: 0.931318\tvalid_1's auc: 0.896047                                                               \n",
      "[31000]\ttraining's auc: 0.932112\tvalid_1's auc: 0.896084                                                               \n",
      "[32000]\ttraining's auc: 0.932889\tvalid_1's auc: 0.896095                                                               \n",
      "[33000]\ttraining's auc: 0.933644\tvalid_1's auc: 0.896211                                                               \n",
      "[34000]\ttraining's auc: 0.934371\tvalid_1's auc: 0.896234                                                               \n",
      "[35000]\ttraining's auc: 0.935084\tvalid_1's auc: 0.896217                                                               \n",
      "[36000]\ttraining's auc: 0.935818\tvalid_1's auc: 0.896269                                                               \n",
      "[37000]\ttraining's auc: 0.936546\tvalid_1's auc: 0.896288                                                               \n",
      "[38000]\ttraining's auc: 0.937261\tvalid_1's auc: 0.896269                                                               \n",
      "[39000]\ttraining's auc: 0.937961\tvalid_1's auc: 0.896234                                                               \n",
      "[40000]\ttraining's auc: 0.938661\tvalid_1's auc: 0.896194                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37005]\ttraining's auc: 0.936549\tvalid_1's auc: 0.89629\n",
      "new best:                                                                                                              \n",
      "0.8968079325141863                                                                                                     \n",
      "{'bagging_fraction': 0.12929061871631042, 'bagging_freq': 4, 'boost': 'gbdt', 'boost_from_average': False, 'feature_fraction': 0.13614273767981244, 'is_unbalance': False, 'learning_rate': 0.0021819646014504374, 'max_depth': 6, 'metric': 'auc', 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 5, 'num_leaves': 7, 'objective': 'binary', 'tree_learner': 'serial'}\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.87571\tvalid_1's auc: 0.863894                                                                 \n",
      "[2000]\ttraining's auc: 0.895064\tvalid_1's auc: 0.880435                                                                \n",
      "[3000]\ttraining's auc: 0.905734\tvalid_1's auc: 0.888676                                                                \n",
      "[4000]\ttraining's auc: 0.91266\tvalid_1's auc: 0.893484                                                                 \n",
      "[5000]\ttraining's auc: 0.91766\tvalid_1's auc: 0.895835                                                                 \n",
      "[6000]\ttraining's auc: 0.921594\tvalid_1's auc: 0.897241                                                                \n",
      "[7000]\ttraining's auc: 0.924992\tvalid_1's auc: 0.897997                                                                \n",
      "[8000]\ttraining's auc: 0.927951\tvalid_1's auc: 0.898407                                                                \n",
      "[9000]\ttraining's auc: 0.93078\tvalid_1's auc: 0.898723                                                                 \n",
      "[10000]\ttraining's auc: 0.933394\tvalid_1's auc: 0.898656                                                               \n",
      "[11000]\ttraining's auc: 0.93596\tvalid_1's auc: 0.898711                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8635]\ttraining's auc: 0.929779\tvalid_1's auc: 0.898808\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.87835\tvalid_1's auc: 0.856404                                                                 \n",
      "[2000]\ttraining's auc: 0.898101\tvalid_1's auc: 0.873022                                                                \n",
      "[3000]\ttraining's auc: 0.908803\tvalid_1's auc: 0.881375                                                                \n",
      "[4000]\ttraining's auc: 0.91583\tvalid_1's auc: 0.885854                                                                 \n",
      "[5000]\ttraining's auc: 0.920879\tvalid_1's auc: 0.888197                                                                \n",
      "[6000]\ttraining's auc: 0.924714\tvalid_1's auc: 0.889746                                                                \n",
      "[7000]\ttraining's auc: 0.928\tvalid_1's auc: 0.890382                                                                   \n",
      "[8000]\ttraining's auc: 0.93086\tvalid_1's auc: 0.890826                                                                 \n",
      "[9000]\ttraining's auc: 0.933585\tvalid_1's auc: 0.891024                                                                \n",
      "[10000]\ttraining's auc: 0.936223\tvalid_1's auc: 0.89109                                                                \n",
      "[11000]\ttraining's auc: 0.938635\tvalid_1's auc: 0.891041                                                               \n",
      "[12000]\ttraining's auc: 0.941087\tvalid_1's auc: 0.890961                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9642]\ttraining's auc: 0.93528\tvalid_1's auc: 0.891171\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.876485\tvalid_1's auc: 0.862712                                                                \n",
      "[2000]\ttraining's auc: 0.895772\tvalid_1's auc: 0.878901                                                                \n",
      "[3000]\ttraining's auc: 0.90655\tvalid_1's auc: 0.887535                                                                 \n",
      "[4000]\ttraining's auc: 0.913439\tvalid_1's auc: 0.892915                                                                \n",
      "[5000]\ttraining's auc: 0.918355\tvalid_1's auc: 0.895748                                                                \n",
      "[6000]\ttraining's auc: 0.922341\tvalid_1's auc: 0.897314                                                                \n",
      "[7000]\ttraining's auc: 0.92555\tvalid_1's auc: 0.898515                                                                 \n",
      "[8000]\ttraining's auc: 0.928492\tvalid_1's auc: 0.898842                                                                \n",
      "[9000]\ttraining's auc: 0.931314\tvalid_1's auc: 0.899275                                                                \n",
      "[10000]\ttraining's auc: 0.933885\tvalid_1's auc: 0.899584                                                               \n",
      "[11000]\ttraining's auc: 0.936405\tvalid_1's auc: 0.899793                                                               \n",
      "[12000]\ttraining's auc: 0.938917\tvalid_1's auc: 0.899736                                                               \n",
      "[13000]\ttraining's auc: 0.941315\tvalid_1's auc: 0.899612                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10952]\ttraining's auc: 0.936278\tvalid_1's auc: 0.899846\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.87737\tvalid_1's auc: 0.860653                                                                 \n",
      "[2000]\ttraining's auc: 0.896807\tvalid_1's auc: 0.877137                                                                \n",
      "[3000]\ttraining's auc: 0.907581\tvalid_1's auc: 0.8859                                                                  \n",
      "[4000]\ttraining's auc: 0.914582\tvalid_1's auc: 0.890472                                                                \n",
      "[5000]\ttraining's auc: 0.91954\tvalid_1's auc: 0.892744                                                                 \n",
      "[6000]\ttraining's auc: 0.923368\tvalid_1's auc: 0.894122                                                                \n",
      "[7000]\ttraining's auc: 0.926705\tvalid_1's auc: 0.894734                                                                \n",
      "[8000]\ttraining's auc: 0.929817\tvalid_1's auc: 0.895199                                                                \n",
      "[9000]\ttraining's auc: 0.932584\tvalid_1's auc: 0.895313                                                                \n",
      "[10000]\ttraining's auc: 0.935219\tvalid_1's auc: 0.895398                                                               \n",
      "[11000]\ttraining's auc: 0.937675\tvalid_1's auc: 0.895273                                                               \n",
      "[12000]\ttraining's auc: 0.940079\tvalid_1's auc: 0.895396                                                               \n",
      "[13000]\ttraining's auc: 0.942378\tvalid_1's auc: 0.895365                                                               \n",
      "[14000]\ttraining's auc: 0.944674\tvalid_1's auc: 0.895294                                                               \n",
      "[15000]\ttraining's auc: 0.946874\tvalid_1's auc: 0.895382                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12504]\ttraining's auc: 0.941244\tvalid_1's auc: 0.895543\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.853531\tvalid_1's auc: 0.839373                                                                \n",
      "[2000]\ttraining's auc: 0.879158\tvalid_1's auc: 0.862437                                                                \n",
      "[3000]\ttraining's auc: 0.894599\tvalid_1's auc: 0.875769                                                                \n",
      "[4000]\ttraining's auc: 0.904398\tvalid_1's auc: 0.88373                                                                 \n",
      "[5000]\ttraining's auc: 0.91097\tvalid_1's auc: 0.888495                                                                 \n",
      "[6000]\ttraining's auc: 0.915957\tvalid_1's auc: 0.891748                                                                \n",
      "[7000]\ttraining's auc: 0.919837\tvalid_1's auc: 0.893967                                                                \n",
      "[8000]\ttraining's auc: 0.923178\tvalid_1's auc: 0.895496                                                                \n",
      "[9000]\ttraining's auc: 0.926084\tvalid_1's auc: 0.896617                                                                \n",
      "[10000]\ttraining's auc: 0.928736\tvalid_1's auc: 0.897327                                                               \n",
      "[11000]\ttraining's auc: 0.931168\tvalid_1's auc: 0.897804                                                               \n",
      "[12000]\ttraining's auc: 0.933538\tvalid_1's auc: 0.89815                                                                \n",
      "[13000]\ttraining's auc: 0.935851\tvalid_1's auc: 0.898269                                                               \n",
      "[14000]\ttraining's auc: 0.938089\tvalid_1's auc: 0.898388                                                               \n",
      "[15000]\ttraining's auc: 0.940234\tvalid_1's auc: 0.89854                                                                \n",
      "[16000]\ttraining's auc: 0.942337\tvalid_1's auc: 0.898566                                                               \n",
      "[17000]\ttraining's auc: 0.944367\tvalid_1's auc: 0.898504                                                               \n",
      "[18000]\ttraining's auc: 0.946402\tvalid_1's auc: 0.898447                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[15496]\ttraining's auc: 0.941273\tvalid_1's auc: 0.898613\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.856671\tvalid_1's auc: 0.833662                                                                \n",
      "[2000]\ttraining's auc: 0.882659\tvalid_1's auc: 0.856476                                                                \n",
      "[3000]\ttraining's auc: 0.89833\tvalid_1's auc: 0.869716                                                                 \n",
      "[4000]\ttraining's auc: 0.90801\tvalid_1's auc: 0.877211                                                                 \n",
      "[5000]\ttraining's auc: 0.914559\tvalid_1's auc: 0.881634                                                                \n",
      "[6000]\ttraining's auc: 0.919455\tvalid_1's auc: 0.884716                                                                \n",
      "[7000]\ttraining's auc: 0.923261\tvalid_1's auc: 0.886951                                                                \n",
      "[8000]\ttraining's auc: 0.926454\tvalid_1's auc: 0.888167                                                                \n",
      "[9000]\ttraining's auc: 0.929279\tvalid_1's auc: 0.889175                                                                \n",
      "[10000]\ttraining's auc: 0.931746\tvalid_1's auc: 0.889961                                                               \n",
      "[11000]\ttraining's auc: 0.93411\tvalid_1's auc: 0.890357                                                                \n",
      "[12000]\ttraining's auc: 0.936363\tvalid_1's auc: 0.890651                                                               \n",
      "[13000]\ttraining's auc: 0.938605\tvalid_1's auc: 0.890802                                                               \n",
      "[14000]\ttraining's auc: 0.940751\tvalid_1's auc: 0.890771                                                               \n",
      "[15000]\ttraining's auc: 0.942802\tvalid_1's auc: 0.890844                                                               \n",
      "[16000]\ttraining's auc: 0.944814\tvalid_1's auc: 0.890881                                                               \n",
      "[17000]\ttraining's auc: 0.946775\tvalid_1's auc: 0.890904                                                               \n",
      "[18000]\ttraining's auc: 0.948664\tvalid_1's auc: 0.890887                                                               \n",
      "[19000]\ttraining's auc: 0.950544\tvalid_1's auc: 0.890891                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16724]\ttraining's auc: 0.946238\tvalid_1's auc: 0.890949\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.854998\tvalid_1's auc: 0.839182                                                                \n",
      "[2000]\ttraining's auc: 0.880771\tvalid_1's auc: 0.861781                                                                \n",
      "[3000]\ttraining's auc: 0.896287\tvalid_1's auc: 0.874854                                                                \n",
      "[4000]\ttraining's auc: 0.905778\tvalid_1's auc: 0.882576                                                                \n",
      "[5000]\ttraining's auc: 0.912318\tvalid_1's auc: 0.887331                                                                \n",
      "[6000]\ttraining's auc: 0.917118\tvalid_1's auc: 0.890553                                                                \n",
      "[7000]\ttraining's auc: 0.92099\tvalid_1's auc: 0.892944                                                                 \n",
      "[8000]\ttraining's auc: 0.924207\tvalid_1's auc: 0.894649                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9000]\ttraining's auc: 0.926996\tvalid_1's auc: 0.895879                                                                \n",
      "[10000]\ttraining's auc: 0.929524\tvalid_1's auc: 0.896602                                                               \n",
      "[11000]\ttraining's auc: 0.931926\tvalid_1's auc: 0.897283                                                               \n",
      "[12000]\ttraining's auc: 0.934268\tvalid_1's auc: 0.897828                                                               \n",
      "[13000]\ttraining's auc: 0.936518\tvalid_1's auc: 0.898248                                                               \n",
      "[14000]\ttraining's auc: 0.938671\tvalid_1's auc: 0.898551                                                               \n",
      "[15000]\ttraining's auc: 0.940813\tvalid_1's auc: 0.898719                                                               \n",
      "[16000]\ttraining's auc: 0.942898\tvalid_1's auc: 0.898816                                                               \n",
      "[17000]\ttraining's auc: 0.944912\tvalid_1's auc: 0.898919                                                               \n",
      "[18000]\ttraining's auc: 0.946864\tvalid_1's auc: 0.898947                                                               \n",
      "[19000]\ttraining's auc: 0.948773\tvalid_1's auc: 0.899063                                                               \n",
      "[20000]\ttraining's auc: 0.950619\tvalid_1's auc: 0.899075                                                               \n",
      "[21000]\ttraining's auc: 0.952389\tvalid_1's auc: 0.899091                                                               \n",
      "[22000]\ttraining's auc: 0.954131\tvalid_1's auc: 0.89909                                                                \n",
      "[23000]\ttraining's auc: 0.955828\tvalid_1's auc: 0.899059                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20618]\ttraining's auc: 0.951722\tvalid_1's auc: 0.899122\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.855271\tvalid_1's auc: 0.8379                                                                  \n",
      "[2000]\ttraining's auc: 0.881724\tvalid_1's auc: 0.860552                                                                \n",
      "[3000]\ttraining's auc: 0.897014\tvalid_1's auc: 0.873168                                                                \n",
      "[4000]\ttraining's auc: 0.906468\tvalid_1's auc: 0.880173                                                                \n",
      "[5000]\ttraining's auc: 0.913142\tvalid_1's auc: 0.885087                                                                \n",
      "[6000]\ttraining's auc: 0.91816\tvalid_1's auc: 0.88834                                                                  \n",
      "[7000]\ttraining's auc: 0.922074\tvalid_1's auc: 0.890652                                                                \n",
      "[8000]\ttraining's auc: 0.925357\tvalid_1's auc: 0.892318                                                                \n",
      "[9000]\ttraining's auc: 0.928218\tvalid_1's auc: 0.893385                                                                \n",
      "[10000]\ttraining's auc: 0.930829\tvalid_1's auc: 0.894171                                                               \n",
      "[11000]\ttraining's auc: 0.93324\tvalid_1's auc: 0.894876                                                                \n",
      "[12000]\ttraining's auc: 0.935516\tvalid_1's auc: 0.895319                                                               \n",
      "[13000]\ttraining's auc: 0.937798\tvalid_1's auc: 0.895492                                                               \n",
      "[14000]\ttraining's auc: 0.939963\tvalid_1's auc: 0.895702                                                               \n",
      "[15000]\ttraining's auc: 0.942081\tvalid_1's auc: 0.895812                                                               \n",
      "[16000]\ttraining's auc: 0.944071\tvalid_1's auc: 0.895914                                                               \n",
      "[17000]\ttraining's auc: 0.946034\tvalid_1's auc: 0.896046                                                               \n",
      "[18000]\ttraining's auc: 0.947953\tvalid_1's auc: 0.895962                                                               \n",
      "[19000]\ttraining's auc: 0.949805\tvalid_1's auc: 0.896041                                                               \n",
      "[20000]\ttraining's auc: 0.951625\tvalid_1's auc: 0.895974                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17217]\ttraining's auc: 0.946443\tvalid_1's auc: 0.89607\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.883837\tvalid_1's auc: 0.869863                                                                \n",
      "[2000]\ttraining's auc: 0.905305\tvalid_1's auc: 0.887575                                                                \n",
      "[3000]\ttraining's auc: 0.915381\tvalid_1's auc: 0.894086                                                                \n",
      "[4000]\ttraining's auc: 0.921861\tvalid_1's auc: 0.896794                                                                \n",
      "[5000]\ttraining's auc: 0.926912\tvalid_1's auc: 0.897749                                                                \n",
      "[6000]\ttraining's auc: 0.931342\tvalid_1's auc: 0.89816                                                                 \n",
      "[7000]\ttraining's auc: 0.935547\tvalid_1's auc: 0.898091                                                                \n",
      "[8000]\ttraining's auc: 0.939567\tvalid_1's auc: 0.89767                                                                 \n",
      "[9000]\ttraining's auc: 0.943425\tvalid_1's auc: 0.897286                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6610]\ttraining's auc: 0.934022\tvalid_1's auc: 0.898226\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.886668\tvalid_1's auc: 0.862534                                                                \n",
      "[2000]\ttraining's auc: 0.908805\tvalid_1's auc: 0.881134                                                                \n",
      "[3000]\ttraining's auc: 0.918952\tvalid_1's auc: 0.887268                                                                \n",
      "[4000]\ttraining's auc: 0.925101\tvalid_1's auc: 0.889987                                                                \n",
      "[5000]\ttraining's auc: 0.930088\tvalid_1's auc: 0.890684                                                                \n",
      "[6000]\ttraining's auc: 0.934372\tvalid_1's auc: 0.890818                                                                \n",
      "[7000]\ttraining's auc: 0.938301\tvalid_1's auc: 0.890755                                                                \n",
      "[8000]\ttraining's auc: 0.942116\tvalid_1's auc: 0.890159                                                                \n",
      "[9000]\ttraining's auc: 0.945675\tvalid_1's auc: 0.889713                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6762]\ttraining's auc: 0.937433\tvalid_1's auc: 0.89093\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.88461\tvalid_1's auc: 0.868825                                                                 \n",
      "[2000]\ttraining's auc: 0.906487\tvalid_1's auc: 0.886367                                                                \n",
      "[3000]\ttraining's auc: 0.916313\tvalid_1's auc: 0.89341                                                                 \n",
      "[4000]\ttraining's auc: 0.922782\tvalid_1's auc: 0.89698                                                                 \n",
      "[5000]\ttraining's auc: 0.92765\tvalid_1's auc: 0.898585                                                                 \n",
      "[6000]\ttraining's auc: 0.932127\tvalid_1's auc: 0.898859                                                                \n",
      "[7000]\ttraining's auc: 0.936179\tvalid_1's auc: 0.898762                                                                \n",
      "[8000]\ttraining's auc: 0.940059\tvalid_1's auc: 0.899058                                                                \n",
      "[9000]\ttraining's auc: 0.943752\tvalid_1's auc: 0.898912                                                                \n",
      "[10000]\ttraining's auc: 0.947225\tvalid_1's auc: 0.898439                                                               \n",
      "[11000]\ttraining's auc: 0.95059\tvalid_1's auc: 0.898253                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8656]\ttraining's auc: 0.942494\tvalid_1's auc: 0.89908\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.885791\tvalid_1's auc: 0.868086                                                                \n",
      "[2000]\ttraining's auc: 0.907174\tvalid_1's auc: 0.884961                                                                \n",
      "[3000]\ttraining's auc: 0.917457\tvalid_1's auc: 0.89157                                                                 \n",
      "[4000]\ttraining's auc: 0.924128\tvalid_1's auc: 0.894111                                                                \n",
      "[5000]\ttraining's auc: 0.929201\tvalid_1's auc: 0.895105                                                                \n",
      "[6000]\ttraining's auc: 0.93354\tvalid_1's auc: 0.895363                                                                 \n",
      "[7000]\ttraining's auc: 0.937563\tvalid_1's auc: 0.895617                                                                \n",
      "[8000]\ttraining's auc: 0.941467\tvalid_1's auc: 0.895853                                                                \n",
      "[9000]\ttraining's auc: 0.945142\tvalid_1's auc: 0.895586                                                                \n",
      "[10000]\ttraining's auc: 0.948508\tvalid_1's auc: 0.895344                                                               \n",
      "[11000]\ttraining's auc: 0.95172\tvalid_1's auc: 0.894868                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[8434]\ttraining's auc: 0.943064\tvalid_1's auc: 0.896001\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.850888\tvalid_1's auc: 0.841683                                                                \n",
      "[2000]\ttraining's auc: 0.874785\tvalid_1's auc: 0.864059                                                                \n",
      "[3000]\ttraining's auc: 0.888057\tvalid_1's auc: 0.875901                                                                \n",
      "[4000]\ttraining's auc: 0.897113\tvalid_1's auc: 0.883941                                                                \n",
      "[5000]\ttraining's auc: 0.90297\tvalid_1's auc: 0.888955                                                                 \n",
      "[6000]\ttraining's auc: 0.907084\tvalid_1's auc: 0.892262                                                                \n",
      "[7000]\ttraining's auc: 0.910437\tvalid_1's auc: 0.894652                                                                \n",
      "[8000]\ttraining's auc: 0.912977\tvalid_1's auc: 0.896253                                                                \n",
      "[9000]\ttraining's auc: 0.915083\tvalid_1's auc: 0.897412                                                                \n",
      "[10000]\ttraining's auc: 0.916845\tvalid_1's auc: 0.897944                                                               \n",
      "[11000]\ttraining's auc: 0.918394\tvalid_1's auc: 0.89858                                                                \n",
      "[12000]\ttraining's auc: 0.919835\tvalid_1's auc: 0.898799                                                               \n",
      "[13000]\ttraining's auc: 0.921137\tvalid_1's auc: 0.898843                                                               \n",
      "[14000]\ttraining's auc: 0.922327\tvalid_1's auc: 0.89903                                                                \n",
      "[15000]\ttraining's auc: 0.923502\tvalid_1's auc: 0.898967                                                               \n",
      "[16000]\ttraining's auc: 0.924595\tvalid_1's auc: 0.898797                                                               \n",
      "[17000]\ttraining's auc: 0.925661\tvalid_1's auc: 0.898816                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14066]\ttraining's auc: 0.922414\tvalid_1's auc: 0.899096\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.852587\tvalid_1's auc: 0.832697                                                                \n",
      "[2000]\ttraining's auc: 0.877626\tvalid_1's auc: 0.856019                                                                \n",
      "[3000]\ttraining's auc: 0.891447\tvalid_1's auc: 0.868677                                                                \n",
      "[4000]\ttraining's auc: 0.900365\tvalid_1's auc: 0.876563                                                                \n",
      "[5000]\ttraining's auc: 0.906492\tvalid_1's auc: 0.881893                                                                \n",
      "[6000]\ttraining's auc: 0.910863\tvalid_1's auc: 0.885489                                                                \n",
      "[7000]\ttraining's auc: 0.913922\tvalid_1's auc: 0.887656                                                                \n",
      "[8000]\ttraining's auc: 0.916472\tvalid_1's auc: 0.889085                                                                \n",
      "[9000]\ttraining's auc: 0.918652\tvalid_1's auc: 0.890432                                                                \n",
      "[10000]\ttraining's auc: 0.920482\tvalid_1's auc: 0.891045                                                               \n",
      "[11000]\ttraining's auc: 0.921982\tvalid_1's auc: 0.891486                                                               \n",
      "[12000]\ttraining's auc: 0.923401\tvalid_1's auc: 0.891444                                                               \n",
      "[13000]\ttraining's auc: 0.924598\tvalid_1's auc: 0.891384                                                               \n",
      "[14000]\ttraining's auc: 0.925743\tvalid_1's auc: 0.891621                                                               \n",
      "[15000]\ttraining's auc: 0.926817\tvalid_1's auc: 0.891562                                                               \n",
      "[16000]\ttraining's auc: 0.927862\tvalid_1's auc: 0.891411                                                               \n",
      "[17000]\ttraining's auc: 0.928885\tvalid_1's auc: 0.891201                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14116]\ttraining's auc: 0.925871\tvalid_1's auc: 0.891669\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.851901\tvalid_1's auc: 0.839218                                                                \n",
      "[2000]\ttraining's auc: 0.874965\tvalid_1's auc: 0.862322                                                                \n",
      "[3000]\ttraining's auc: 0.888791\tvalid_1's auc: 0.87446                                                                 \n",
      "[4000]\ttraining's auc: 0.897641\tvalid_1's auc: 0.882877                                                                \n",
      "[5000]\ttraining's auc: 0.903851\tvalid_1's auc: 0.888067                                                                \n",
      "[6000]\ttraining's auc: 0.908085\tvalid_1's auc: 0.891652                                                                \n",
      "[7000]\ttraining's auc: 0.911218\tvalid_1's auc: 0.894193                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000]\ttraining's auc: 0.913783\tvalid_1's auc: 0.895989                                                                \n",
      "[9000]\ttraining's auc: 0.91583\tvalid_1's auc: 0.897259                                                                 \n",
      "[10000]\ttraining's auc: 0.917612\tvalid_1's auc: 0.898074                                                               \n",
      "[11000]\ttraining's auc: 0.919134\tvalid_1's auc: 0.898548                                                               \n",
      "[12000]\ttraining's auc: 0.920538\tvalid_1's auc: 0.898931                                                               \n",
      "[13000]\ttraining's auc: 0.921792\tvalid_1's auc: 0.899345                                                               \n",
      "[14000]\ttraining's auc: 0.922941\tvalid_1's auc: 0.899744                                                               \n",
      "[15000]\ttraining's auc: 0.924091\tvalid_1's auc: 0.899751                                                               \n",
      "[16000]\ttraining's auc: 0.925167\tvalid_1's auc: 0.899803                                                               \n",
      "[17000]\ttraining's auc: 0.926251\tvalid_1's auc: 0.899825                                                               \n",
      "[18000]\ttraining's auc: 0.927249\tvalid_1's auc: 0.899781                                                               \n",
      "[19000]\ttraining's auc: 0.92827\tvalid_1's auc: 0.899746                                                                \n",
      "[20000]\ttraining's auc: 0.92925\tvalid_1's auc: 0.899742                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[17438]\ttraining's auc: 0.9267\tvalid_1's auc: 0.899885\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.851708\tvalid_1's auc: 0.839494                                                                \n",
      "[2000]\ttraining's auc: 0.877081\tvalid_1's auc: 0.861826                                                                \n",
      "[3000]\ttraining's auc: 0.890413\tvalid_1's auc: 0.873615                                                                \n",
      "[4000]\ttraining's auc: 0.899254\tvalid_1's auc: 0.88124                                                                 \n",
      "[5000]\ttraining's auc: 0.905135\tvalid_1's auc: 0.885971                                                                \n",
      "[6000]\ttraining's auc: 0.909442\tvalid_1's auc: 0.888864                                                                \n",
      "[7000]\ttraining's auc: 0.912593\tvalid_1's auc: 0.891067                                                                \n",
      "[8000]\ttraining's auc: 0.915191\tvalid_1's auc: 0.892797                                                                \n",
      "[9000]\ttraining's auc: 0.917273\tvalid_1's auc: 0.894139                                                                \n",
      "[10000]\ttraining's auc: 0.919167\tvalid_1's auc: 0.894882                                                               \n",
      "[11000]\ttraining's auc: 0.920704\tvalid_1's auc: 0.895567                                                               \n",
      "[12000]\ttraining's auc: 0.922078\tvalid_1's auc: 0.895913                                                               \n",
      "[13000]\ttraining's auc: 0.923274\tvalid_1's auc: 0.896007                                                               \n",
      "[14000]\ttraining's auc: 0.924516\tvalid_1's auc: 0.896219                                                               \n",
      "[15000]\ttraining's auc: 0.925591\tvalid_1's auc: 0.896024                                                               \n",
      "[16000]\ttraining's auc: 0.926663\tvalid_1's auc: 0.896119                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[13830]\ttraining's auc: 0.924305\tvalid_1's auc: 0.896266\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.823057\tvalid_1's auc: 0.81424                                                                 \n",
      "[2000]\ttraining's auc: 0.843111\tvalid_1's auc: 0.833413                                                                \n",
      "[3000]\ttraining's auc: 0.856507\tvalid_1's auc: 0.845804                                                                \n",
      "[4000]\ttraining's auc: 0.867802\tvalid_1's auc: 0.85655                                                                 \n",
      "[5000]\ttraining's auc: 0.876132\tvalid_1's auc: 0.864305                                                                \n",
      "[6000]\ttraining's auc: 0.882778\tvalid_1's auc: 0.870429                                                                \n",
      "[7000]\ttraining's auc: 0.888092\tvalid_1's auc: 0.875176                                                                \n",
      "[8000]\ttraining's auc: 0.892348\tvalid_1's auc: 0.878796                                                                \n",
      "[9000]\ttraining's auc: 0.896002\tvalid_1's auc: 0.88178                                                                 \n",
      "[10000]\ttraining's auc: 0.899046\tvalid_1's auc: 0.88446                                                                \n",
      "[11000]\ttraining's auc: 0.901682\tvalid_1's auc: 0.886677                                                               \n",
      "[12000]\ttraining's auc: 0.903939\tvalid_1's auc: 0.888512                                                               \n",
      "[13000]\ttraining's auc: 0.905967\tvalid_1's auc: 0.89001                                                                \n",
      "[14000]\ttraining's auc: 0.907779\tvalid_1's auc: 0.891442                                                               \n",
      "[15000]\ttraining's auc: 0.909422\tvalid_1's auc: 0.892548                                                               \n",
      "[16000]\ttraining's auc: 0.91087\tvalid_1's auc: 0.89355                                                                 \n",
      "[17000]\ttraining's auc: 0.912197\tvalid_1's auc: 0.894477                                                               \n",
      "[18000]\ttraining's auc: 0.913292\tvalid_1's auc: 0.895195                                                               \n",
      "[19000]\ttraining's auc: 0.914372\tvalid_1's auc: 0.895889                                                               \n",
      "[20000]\ttraining's auc: 0.915343\tvalid_1's auc: 0.896348                                                               \n",
      "[21000]\ttraining's auc: 0.916242\tvalid_1's auc: 0.896809                                                               \n",
      "[22000]\ttraining's auc: 0.917056\tvalid_1's auc: 0.897198                                                               \n",
      "[23000]\ttraining's auc: 0.917843\tvalid_1's auc: 0.897575                                                               \n",
      "[24000]\ttraining's auc: 0.918621\tvalid_1's auc: 0.897833                                                               \n",
      "[25000]\ttraining's auc: 0.919351\tvalid_1's auc: 0.898118                                                               \n",
      "[26000]\ttraining's auc: 0.920022\tvalid_1's auc: 0.898314                                                               \n",
      "[27000]\ttraining's auc: 0.920647\tvalid_1's auc: 0.898503                                                               \n",
      "[28000]\ttraining's auc: 0.921248\tvalid_1's auc: 0.898641                                                               \n",
      "[29000]\ttraining's auc: 0.921865\tvalid_1's auc: 0.898795                                                               \n",
      "[30000]\ttraining's auc: 0.922454\tvalid_1's auc: 0.898878                                                               \n",
      "[31000]\ttraining's auc: 0.923026\tvalid_1's auc: 0.898947                                                               \n",
      "[32000]\ttraining's auc: 0.923623\tvalid_1's auc: 0.899016                                                               \n",
      "[33000]\ttraining's auc: 0.92416\tvalid_1's auc: 0.899063                                                                \n",
      "[34000]\ttraining's auc: 0.924684\tvalid_1's auc: 0.89907                                                                \n",
      "[35000]\ttraining's auc: 0.925197\tvalid_1's auc: 0.899078                                                               \n",
      "[36000]\ttraining's auc: 0.925694\tvalid_1's auc: 0.899091                                                               \n",
      "[37000]\ttraining's auc: 0.926224\tvalid_1's auc: 0.899062                                                               \n",
      "[38000]\ttraining's auc: 0.926691\tvalid_1's auc: 0.899088                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35733]\ttraining's auc: 0.925556\tvalid_1's auc: 0.899133\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.826369\tvalid_1's auc: 0.807192                                                                \n",
      "[2000]\ttraining's auc: 0.845142\tvalid_1's auc: 0.82514                                                                 \n",
      "[3000]\ttraining's auc: 0.85931\tvalid_1's auc: 0.838571                                                                 \n",
      "[4000]\ttraining's auc: 0.870406\tvalid_1's auc: 0.848973                                                                \n",
      "[5000]\ttraining's auc: 0.87943\tvalid_1's auc: 0.857137                                                                 \n",
      "[6000]\ttraining's auc: 0.88616\tvalid_1's auc: 0.863353                                                                 \n",
      "[7000]\ttraining's auc: 0.891507\tvalid_1's auc: 0.867834                                                                \n",
      "[8000]\ttraining's auc: 0.895746\tvalid_1's auc: 0.871585                                                                \n",
      "[9000]\ttraining's auc: 0.899518\tvalid_1's auc: 0.87477                                                                 \n",
      "[10000]\ttraining's auc: 0.902815\tvalid_1's auc: 0.877537                                                               \n",
      "[11000]\ttraining's auc: 0.905435\tvalid_1's auc: 0.87971                                                                \n",
      "[12000]\ttraining's auc: 0.907736\tvalid_1's auc: 0.881397                                                               \n",
      "[13000]\ttraining's auc: 0.909643\tvalid_1's auc: 0.882934                                                               \n",
      "[14000]\ttraining's auc: 0.911436\tvalid_1's auc: 0.884227                                                               \n",
      "[15000]\ttraining's auc: 0.913003\tvalid_1's auc: 0.88535                                                                \n",
      "[16000]\ttraining's auc: 0.914459\tvalid_1's auc: 0.88624                                                                \n",
      "[17000]\ttraining's auc: 0.915757\tvalid_1's auc: 0.887026                                                               \n",
      "[18000]\ttraining's auc: 0.916863\tvalid_1's auc: 0.887728                                                               \n",
      "[19000]\ttraining's auc: 0.91793\tvalid_1's auc: 0.888407                                                                \n",
      "[20000]\ttraining's auc: 0.918874\tvalid_1's auc: 0.889008                                                               \n",
      "[21000]\ttraining's auc: 0.919779\tvalid_1's auc: 0.889457                                                               \n",
      "[22000]\ttraining's auc: 0.920603\tvalid_1's auc: 0.889952                                                               \n",
      "[23000]\ttraining's auc: 0.92141\tvalid_1's auc: 0.890275                                                                \n",
      "[24000]\ttraining's auc: 0.922156\tvalid_1's auc: 0.89049                                                                \n",
      "[25000]\ttraining's auc: 0.922874\tvalid_1's auc: 0.890769                                                               \n",
      "[26000]\ttraining's auc: 0.923549\tvalid_1's auc: 0.890966                                                               \n",
      "[27000]\ttraining's auc: 0.9242\tvalid_1's auc: 0.891213                                                                 \n",
      "[28000]\ttraining's auc: 0.924804\tvalid_1's auc: 0.89127                                                                \n",
      "[29000]\ttraining's auc: 0.925404\tvalid_1's auc: 0.891456                                                               \n",
      "[30000]\ttraining's auc: 0.925955\tvalid_1's auc: 0.891538                                                               \n",
      "[31000]\ttraining's auc: 0.926494\tvalid_1's auc: 0.891635                                                               \n",
      "[32000]\ttraining's auc: 0.927014\tvalid_1's auc: 0.891697                                                               \n",
      "[33000]\ttraining's auc: 0.927503\tvalid_1's auc: 0.891788                                                               \n",
      "[34000]\ttraining's auc: 0.927997\tvalid_1's auc: 0.891765                                                               \n",
      "[35000]\ttraining's auc: 0.928483\tvalid_1's auc: 0.891806                                                               \n",
      "[36000]\ttraining's auc: 0.928981\tvalid_1's auc: 0.891838                                                               \n",
      "[37000]\ttraining's auc: 0.92944\tvalid_1's auc: 0.8917                                                                  \n",
      "[38000]\ttraining's auc: 0.929899\tvalid_1's auc: 0.891651                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35770]\ttraining's auc: 0.928867\tvalid_1's auc: 0.891862\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.824492\tvalid_1's auc: 0.813393                                                                \n",
      "[2000]\ttraining's auc: 0.843467\tvalid_1's auc: 0.831092                                                                \n",
      "[3000]\ttraining's auc: 0.857653\tvalid_1's auc: 0.844217                                                                \n",
      "[4000]\ttraining's auc: 0.868768\tvalid_1's auc: 0.85508                                                                 \n",
      "[5000]\ttraining's auc: 0.877108\tvalid_1's auc: 0.862344                                                                \n",
      "[6000]\ttraining's auc: 0.883659\tvalid_1's auc: 0.868411                                                                \n",
      "[7000]\ttraining's auc: 0.889035\tvalid_1's auc: 0.87321                                                                 \n",
      "[8000]\ttraining's auc: 0.89331\tvalid_1's auc: 0.877054                                                                 \n",
      "[9000]\ttraining's auc: 0.89701\tvalid_1's auc: 0.880455                                                                 \n",
      "[10000]\ttraining's auc: 0.900074\tvalid_1's auc: 0.883293                                                               \n",
      "[11000]\ttraining's auc: 0.902729\tvalid_1's auc: 0.885502                                                               \n",
      "[12000]\ttraining's auc: 0.904968\tvalid_1's auc: 0.88734                                                                \n",
      "[13000]\ttraining's auc: 0.90692\tvalid_1's auc: 0.889038                                                                \n",
      "[14000]\ttraining's auc: 0.908708\tvalid_1's auc: 0.89039                                                                \n",
      "[15000]\ttraining's auc: 0.910294\tvalid_1's auc: 0.891528                                                               \n",
      "[16000]\ttraining's auc: 0.911689\tvalid_1's auc: 0.892611                                                               \n",
      "[17000]\ttraining's auc: 0.912932\tvalid_1's auc: 0.893521                                                               \n",
      "[18000]\ttraining's auc: 0.914107\tvalid_1's auc: 0.894275                                                               \n",
      "[19000]\ttraining's auc: 0.915142\tvalid_1's auc: 0.895                                                                  \n",
      "[20000]\ttraining's auc: 0.916105\tvalid_1's auc: 0.895646                                                               \n",
      "[21000]\ttraining's auc: 0.917026\tvalid_1's auc: 0.896166                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22000]\ttraining's auc: 0.917828\tvalid_1's auc: 0.896656                                                               \n",
      "[23000]\ttraining's auc: 0.918607\tvalid_1's auc: 0.897083                                                               \n",
      "[24000]\ttraining's auc: 0.919357\tvalid_1's auc: 0.897524                                                               \n",
      "[25000]\ttraining's auc: 0.92003\tvalid_1's auc: 0.897816                                                                \n",
      "[26000]\ttraining's auc: 0.920716\tvalid_1's auc: 0.898094                                                               \n",
      "[27000]\ttraining's auc: 0.92136\tvalid_1's auc: 0.898367                                                                \n",
      "[28000]\ttraining's auc: 0.921974\tvalid_1's auc: 0.898546                                                               \n",
      "[29000]\ttraining's auc: 0.922548\tvalid_1's auc: 0.898737                                                               \n",
      "[30000]\ttraining's auc: 0.9231\tvalid_1's auc: 0.898934                                                                 \n",
      "[31000]\ttraining's auc: 0.923657\tvalid_1's auc: 0.899046                                                               \n",
      "[32000]\ttraining's auc: 0.924217\tvalid_1's auc: 0.899092                                                               \n",
      "[33000]\ttraining's auc: 0.924759\tvalid_1's auc: 0.899182                                                               \n",
      "[34000]\ttraining's auc: 0.925298\tvalid_1's auc: 0.899275                                                               \n",
      "[35000]\ttraining's auc: 0.925816\tvalid_1's auc: 0.899323                                                               \n",
      "[36000]\ttraining's auc: 0.926299\tvalid_1's auc: 0.899364                                                               \n",
      "[37000]\ttraining's auc: 0.926795\tvalid_1's auc: 0.899346                                                               \n",
      "[38000]\ttraining's auc: 0.927278\tvalid_1's auc: 0.899377                                                               \n",
      "[39000]\ttraining's auc: 0.927767\tvalid_1's auc: 0.899353                                                               \n",
      "[40000]\ttraining's auc: 0.928251\tvalid_1's auc: 0.899468                                                               \n",
      "[41000]\ttraining's auc: 0.928734\tvalid_1's auc: 0.899473                                                               \n",
      "[42000]\ttraining's auc: 0.929197\tvalid_1's auc: 0.899544                                                               \n",
      "[43000]\ttraining's auc: 0.929643\tvalid_1's auc: 0.899547                                                               \n",
      "[44000]\ttraining's auc: 0.930099\tvalid_1's auc: 0.899575                                                               \n",
      "[45000]\ttraining's auc: 0.930543\tvalid_1's auc: 0.899576                                                               \n",
      "[46000]\ttraining's auc: 0.931004\tvalid_1's auc: 0.899538                                                               \n",
      "[47000]\ttraining's auc: 0.931476\tvalid_1's auc: 0.899578                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[44132]\ttraining's auc: 0.930157\tvalid_1's auc: 0.899595\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.821341\tvalid_1's auc: 0.809495                                                                \n",
      "[2000]\ttraining's auc: 0.843819\tvalid_1's auc: 0.830628                                                                \n",
      "[3000]\ttraining's auc: 0.858691\tvalid_1's auc: 0.844104                                                                \n",
      "[4000]\ttraining's auc: 0.870533\tvalid_1's auc: 0.85446                                                                 \n",
      "[5000]\ttraining's auc: 0.878582\tvalid_1's auc: 0.861374                                                                \n",
      "[6000]\ttraining's auc: 0.884829\tvalid_1's auc: 0.866728                                                                \n",
      "[7000]\ttraining's auc: 0.890032\tvalid_1's auc: 0.871527                                                                \n",
      "[8000]\ttraining's auc: 0.894302\tvalid_1's auc: 0.875259                                                                \n",
      "[9000]\ttraining's auc: 0.897911\tvalid_1's auc: 0.878291                                                                \n",
      "[10000]\ttraining's auc: 0.900941\tvalid_1's auc: 0.880968                                                               \n",
      "[11000]\ttraining's auc: 0.903576\tvalid_1's auc: 0.883242                                                               \n",
      "[12000]\ttraining's auc: 0.905818\tvalid_1's auc: 0.884974                                                               \n",
      "[13000]\ttraining's auc: 0.907904\tvalid_1's auc: 0.886615                                                               \n",
      "[14000]\ttraining's auc: 0.90973\tvalid_1's auc: 0.888049                                                                \n",
      "[15000]\ttraining's auc: 0.911364\tvalid_1's auc: 0.889258                                                               \n",
      "[16000]\ttraining's auc: 0.912698\tvalid_1's auc: 0.890245                                                               \n",
      "[17000]\ttraining's auc: 0.914006\tvalid_1's auc: 0.89111                                                                \n",
      "[18000]\ttraining's auc: 0.915162\tvalid_1's auc: 0.891894                                                               \n",
      "[19000]\ttraining's auc: 0.916289\tvalid_1's auc: 0.892624                                                               \n",
      "[20000]\ttraining's auc: 0.917329\tvalid_1's auc: 0.893233                                                               \n",
      "[21000]\ttraining's auc: 0.918278\tvalid_1's auc: 0.893803                                                               \n",
      "[22000]\ttraining's auc: 0.919086\tvalid_1's auc: 0.894217                                                               \n",
      "[23000]\ttraining's auc: 0.919918\tvalid_1's auc: 0.894574                                                               \n",
      "[24000]\ttraining's auc: 0.920701\tvalid_1's auc: 0.894978                                                               \n",
      "[25000]\ttraining's auc: 0.92146\tvalid_1's auc: 0.895275                                                                \n",
      "[26000]\ttraining's auc: 0.922159\tvalid_1's auc: 0.895552                                                               \n",
      "[27000]\ttraining's auc: 0.922802\tvalid_1's auc: 0.895794                                                               \n",
      "[28000]\ttraining's auc: 0.923453\tvalid_1's auc: 0.89593                                                                \n",
      "[29000]\ttraining's auc: 0.924042\tvalid_1's auc: 0.896148                                                               \n",
      "[30000]\ttraining's auc: 0.924618\tvalid_1's auc: 0.896239                                                               \n",
      "[31000]\ttraining's auc: 0.92517\tvalid_1's auc: 0.896375                                                                \n",
      "[32000]\ttraining's auc: 0.925717\tvalid_1's auc: 0.896547                                                               \n",
      "[33000]\ttraining's auc: 0.92625\tvalid_1's auc: 0.896585                                                                \n",
      "[34000]\ttraining's auc: 0.926744\tvalid_1's auc: 0.896587                                                               \n",
      "[35000]\ttraining's auc: 0.927245\tvalid_1's auc: 0.89659                                                                \n",
      "[36000]\ttraining's auc: 0.927731\tvalid_1's auc: 0.89662                                                                \n",
      "[37000]\ttraining's auc: 0.928191\tvalid_1's auc: 0.896574                                                               \n",
      "[38000]\ttraining's auc: 0.928667\tvalid_1's auc: 0.896562                                                               \n",
      "[39000]\ttraining's auc: 0.929139\tvalid_1's auc: 0.89658                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36313]\ttraining's auc: 0.927874\tvalid_1's auc: 0.896642\n",
      "new best:                                                                                                              \n",
      "0.8968124198655064                                                                                                     \n",
      "{'bagging_fraction': 0.15930937931218367, 'bagging_freq': 4, 'boost': 'gbdt', 'boost_from_average': True, 'feature_fraction': 0.10934091906403476, 'is_unbalance': False, 'learning_rate': 0.0038612742122311576, 'max_depth': 2, 'metric': 'auc', 'min_data_in_leaf': 50, 'min_sum_hessian_in_leaf': 5, 'num_leaves': 7, 'objective': 'binary', 'tree_learner': 'serial'}\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.823777\tvalid_1's auc: 0.813414                                                                \n",
      "[2000]\ttraining's auc: 0.842514\tvalid_1's auc: 0.831377                                                                \n",
      "[3000]\ttraining's auc: 0.856855\tvalid_1's auc: 0.845299                                                                \n",
      "[4000]\ttraining's auc: 0.868303\tvalid_1's auc: 0.856388                                                                \n",
      "[5000]\ttraining's auc: 0.876854\tvalid_1's auc: 0.864308                                                                \n",
      "[6000]\ttraining's auc: 0.883315\tvalid_1's auc: 0.870166                                                                \n",
      "[7000]\ttraining's auc: 0.888533\tvalid_1's auc: 0.874893                                                                \n",
      "[8000]\ttraining's auc: 0.89279\tvalid_1's auc: 0.878477                                                                 \n",
      "[9000]\ttraining's auc: 0.896477\tvalid_1's auc: 0.881495                                                                \n",
      "[10000]\ttraining's auc: 0.899527\tvalid_1's auc: 0.884123                                                               \n",
      "[11000]\ttraining's auc: 0.902158\tvalid_1's auc: 0.886153                                                               \n",
      "[12000]\ttraining's auc: 0.904406\tvalid_1's auc: 0.888037                                                               \n",
      "[13000]\ttraining's auc: 0.906468\tvalid_1's auc: 0.889655                                                               \n",
      "[14000]\ttraining's auc: 0.908277\tvalid_1's auc: 0.891093                                                               \n",
      "[15000]\ttraining's auc: 0.909897\tvalid_1's auc: 0.892295                                                               \n",
      "[16000]\ttraining's auc: 0.911313\tvalid_1's auc: 0.893397                                                               \n",
      "[17000]\ttraining's auc: 0.912634\tvalid_1's auc: 0.894238                                                               \n",
      "[18000]\ttraining's auc: 0.913757\tvalid_1's auc: 0.894929                                                               \n",
      "[19000]\ttraining's auc: 0.914854\tvalid_1's auc: 0.895564                                                               \n",
      "[20000]\ttraining's auc: 0.915884\tvalid_1's auc: 0.896085                                                               \n",
      "[21000]\ttraining's auc: 0.916815\tvalid_1's auc: 0.896656                                                               \n",
      "[22000]\ttraining's auc: 0.917636\tvalid_1's auc: 0.897047                                                               \n",
      "[23000]\ttraining's auc: 0.918434\tvalid_1's auc: 0.897457                                                               \n",
      "[24000]\ttraining's auc: 0.919204\tvalid_1's auc: 0.897758                                                               \n",
      "[25000]\ttraining's auc: 0.919953\tvalid_1's auc: 0.898063                                                               \n",
      "[26000]\ttraining's auc: 0.920647\tvalid_1's auc: 0.898224                                                               \n",
      "[27000]\ttraining's auc: 0.921337\tvalid_1's auc: 0.898395                                                               \n",
      "[28000]\ttraining's auc: 0.921966\tvalid_1's auc: 0.898511                                                               \n",
      "[29000]\ttraining's auc: 0.922605\tvalid_1's auc: 0.898598                                                               \n",
      "[30000]\ttraining's auc: 0.923196\tvalid_1's auc: 0.898666                                                               \n",
      "[31000]\ttraining's auc: 0.923772\tvalid_1's auc: 0.898779                                                               \n",
      "[32000]\ttraining's auc: 0.924339\tvalid_1's auc: 0.898845                                                               \n",
      "[33000]\ttraining's auc: 0.924905\tvalid_1's auc: 0.898848                                                               \n",
      "[34000]\ttraining's auc: 0.925466\tvalid_1's auc: 0.898916                                                               \n",
      "[35000]\ttraining's auc: 0.926012\tvalid_1's auc: 0.898888                                                               \n",
      "[36000]\ttraining's auc: 0.926547\tvalid_1's auc: 0.898899                                                               \n",
      "[37000]\ttraining's auc: 0.927074\tvalid_1's auc: 0.898928                                                               \n",
      "[38000]\ttraining's auc: 0.927597\tvalid_1's auc: 0.898926                                                               \n",
      "[39000]\ttraining's auc: 0.928118\tvalid_1's auc: 0.89892                                                                \n",
      "[40000]\ttraining's auc: 0.928613\tvalid_1's auc: 0.898865                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37276]\ttraining's auc: 0.927211\tvalid_1's auc: 0.898984\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.824281\tvalid_1's auc: 0.804905                                                                \n",
      "[2000]\ttraining's auc: 0.844788\tvalid_1's auc: 0.824487                                                                \n",
      "[3000]\ttraining's auc: 0.859255\tvalid_1's auc: 0.838064                                                                \n",
      "[4000]\ttraining's auc: 0.870989\tvalid_1's auc: 0.848846                                                                \n",
      "[5000]\ttraining's auc: 0.87977\tvalid_1's auc: 0.856959                                                                 \n",
      "[6000]\ttraining's auc: 0.886822\tvalid_1's auc: 0.863202                                                                \n",
      "[7000]\ttraining's auc: 0.892207\tvalid_1's auc: 0.867953                                                                \n",
      "[8000]\ttraining's auc: 0.896548\tvalid_1's auc: 0.871748                                                                \n",
      "[9000]\ttraining's auc: 0.900185\tvalid_1's auc: 0.874776                                                                \n",
      "[10000]\ttraining's auc: 0.903288\tvalid_1's auc: 0.877374                                                               \n",
      "[11000]\ttraining's auc: 0.905926\tvalid_1's auc: 0.879646                                                               \n",
      "[12000]\ttraining's auc: 0.908354\tvalid_1's auc: 0.881469                                                               \n",
      "[13000]\ttraining's auc: 0.9103\tvalid_1's auc: 0.883101                                                                 \n",
      "[14000]\ttraining's auc: 0.912153\tvalid_1's auc: 0.884557                                                               \n",
      "[15000]\ttraining's auc: 0.913731\tvalid_1's auc: 0.885594                                                               \n",
      "[16000]\ttraining's auc: 0.915247\tvalid_1's auc: 0.886644                                                               \n",
      "[17000]\ttraining's auc: 0.916513\tvalid_1's auc: 0.887448                                                               \n",
      "[18000]\ttraining's auc: 0.917631\tvalid_1's auc: 0.888101                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19000]\ttraining's auc: 0.918698\tvalid_1's auc: 0.888763                                                               \n",
      "[20000]\ttraining's auc: 0.919686\tvalid_1's auc: 0.889359                                                               \n",
      "[21000]\ttraining's auc: 0.920591\tvalid_1's auc: 0.889811                                                               \n",
      "[22000]\ttraining's auc: 0.921406\tvalid_1's auc: 0.890129                                                               \n",
      "[23000]\ttraining's auc: 0.922217\tvalid_1's auc: 0.890415                                                               \n",
      "[24000]\ttraining's auc: 0.922951\tvalid_1's auc: 0.890703                                                               \n",
      "[25000]\ttraining's auc: 0.923643\tvalid_1's auc: 0.890932                                                               \n",
      "[26000]\ttraining's auc: 0.924352\tvalid_1's auc: 0.891154                                                               \n",
      "[27000]\ttraining's auc: 0.925013\tvalid_1's auc: 0.891381                                                               \n",
      "[28000]\ttraining's auc: 0.925625\tvalid_1's auc: 0.891501                                                               \n",
      "[29000]\ttraining's auc: 0.926198\tvalid_1's auc: 0.891632                                                               \n",
      "[30000]\ttraining's auc: 0.926771\tvalid_1's auc: 0.891705                                                               \n",
      "[31000]\ttraining's auc: 0.927335\tvalid_1's auc: 0.891745                                                               \n",
      "[32000]\ttraining's auc: 0.927879\tvalid_1's auc: 0.891818                                                               \n",
      "[33000]\ttraining's auc: 0.928396\tvalid_1's auc: 0.891883                                                               \n",
      "[34000]\ttraining's auc: 0.928912\tvalid_1's auc: 0.891915                                                               \n",
      "[35000]\ttraining's auc: 0.929409\tvalid_1's auc: 0.891906                                                               \n",
      "[36000]\ttraining's auc: 0.929908\tvalid_1's auc: 0.891955                                                               \n",
      "[37000]\ttraining's auc: 0.930381\tvalid_1's auc: 0.891898                                                               \n",
      "[38000]\ttraining's auc: 0.930879\tvalid_1's auc: 0.891851                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35880]\ttraining's auc: 0.929857\tvalid_1's auc: 0.891972\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.823684\tvalid_1's auc: 0.811487                                                                \n",
      "[2000]\ttraining's auc: 0.843201\tvalid_1's auc: 0.83046                                                                 \n",
      "[3000]\ttraining's auc: 0.85803\tvalid_1's auc: 0.844445                                                                 \n",
      "[4000]\ttraining's auc: 0.869189\tvalid_1's auc: 0.854745                                                                \n",
      "[5000]\ttraining's auc: 0.877384\tvalid_1's auc: 0.862401                                                                \n",
      "[6000]\ttraining's auc: 0.8841\tvalid_1's auc: 0.868537                                                                  \n",
      "[7000]\ttraining's auc: 0.889539\tvalid_1's auc: 0.873366                                                                \n",
      "[8000]\ttraining's auc: 0.8939\tvalid_1's auc: 0.877295                                                                  \n",
      "[9000]\ttraining's auc: 0.897563\tvalid_1's auc: 0.880708                                                                \n",
      "[10000]\ttraining's auc: 0.900588\tvalid_1's auc: 0.88325                                                                \n",
      "[11000]\ttraining's auc: 0.903276\tvalid_1's auc: 0.885505                                                               \n",
      "[12000]\ttraining's auc: 0.905676\tvalid_1's auc: 0.887375                                                               \n",
      "[13000]\ttraining's auc: 0.907588\tvalid_1's auc: 0.889022                                                               \n",
      "[14000]\ttraining's auc: 0.909439\tvalid_1's auc: 0.890483                                                               \n",
      "[15000]\ttraining's auc: 0.911013\tvalid_1's auc: 0.891668                                                               \n",
      "[16000]\ttraining's auc: 0.912402\tvalid_1's auc: 0.892751                                                               \n",
      "[17000]\ttraining's auc: 0.913586\tvalid_1's auc: 0.893616                                                               \n",
      "[18000]\ttraining's auc: 0.914798\tvalid_1's auc: 0.894386                                                               \n",
      "[19000]\ttraining's auc: 0.9158\tvalid_1's auc: 0.895102                                                                 \n",
      "[20000]\ttraining's auc: 0.916786\tvalid_1's auc: 0.8958                                                                 \n",
      "[21000]\ttraining's auc: 0.917685\tvalid_1's auc: 0.89633                                                                \n",
      "[22000]\ttraining's auc: 0.918527\tvalid_1's auc: 0.896797                                                               \n",
      "[23000]\ttraining's auc: 0.919297\tvalid_1's auc: 0.897217                                                               \n",
      "[24000]\ttraining's auc: 0.920043\tvalid_1's auc: 0.897642                                                               \n",
      "[25000]\ttraining's auc: 0.92081\tvalid_1's auc: 0.898046                                                                \n",
      "[26000]\ttraining's auc: 0.921525\tvalid_1's auc: 0.898321                                                               \n",
      "[27000]\ttraining's auc: 0.922189\tvalid_1's auc: 0.89859                                                                \n",
      "[28000]\ttraining's auc: 0.922818\tvalid_1's auc: 0.898781                                                               \n",
      "[29000]\ttraining's auc: 0.923397\tvalid_1's auc: 0.89892                                                                \n",
      "[30000]\ttraining's auc: 0.923976\tvalid_1's auc: 0.899013                                                               \n",
      "[31000]\ttraining's auc: 0.924534\tvalid_1's auc: 0.899124                                                               \n",
      "[32000]\ttraining's auc: 0.925088\tvalid_1's auc: 0.899225                                                               \n",
      "[33000]\ttraining's auc: 0.925606\tvalid_1's auc: 0.899332                                                               \n",
      "[34000]\ttraining's auc: 0.926118\tvalid_1's auc: 0.899367                                                               \n",
      "[35000]\ttraining's auc: 0.926638\tvalid_1's auc: 0.899459                                                               \n",
      "[36000]\ttraining's auc: 0.927156\tvalid_1's auc: 0.899613                                                               \n",
      "[37000]\ttraining's auc: 0.927665\tvalid_1's auc: 0.899619                                                               \n",
      "[38000]\ttraining's auc: 0.928168\tvalid_1's auc: 0.899709                                                               \n",
      "[39000]\ttraining's auc: 0.928667\tvalid_1's auc: 0.899786                                                               \n",
      "[40000]\ttraining's auc: 0.929149\tvalid_1's auc: 0.899823                                                               \n",
      "[41000]\ttraining's auc: 0.929643\tvalid_1's auc: 0.899812                                                               \n",
      "[42000]\ttraining's auc: 0.930141\tvalid_1's auc: 0.899815                                                               \n",
      "[43000]\ttraining's auc: 0.930605\tvalid_1's auc: 0.899764                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40667]\ttraining's auc: 0.929483\tvalid_1's auc: 0.899847\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.823112\tvalid_1's auc: 0.810426                                                                \n",
      "[2000]\ttraining's auc: 0.844093\tvalid_1's auc: 0.829998                                                                \n",
      "[3000]\ttraining's auc: 0.859369\tvalid_1's auc: 0.843969                                                                \n",
      "[4000]\ttraining's auc: 0.871194\tvalid_1's auc: 0.854649                                                                \n",
      "[5000]\ttraining's auc: 0.879264\tvalid_1's auc: 0.86162                                                                 \n",
      "[6000]\ttraining's auc: 0.885779\tvalid_1's auc: 0.86752                                                                 \n",
      "[7000]\ttraining's auc: 0.890692\tvalid_1's auc: 0.871732                                                                \n",
      "[8000]\ttraining's auc: 0.894921\tvalid_1's auc: 0.875188                                                                \n",
      "[9000]\ttraining's auc: 0.898469\tvalid_1's auc: 0.878383                                                                \n",
      "[10000]\ttraining's auc: 0.901528\tvalid_1's auc: 0.880938                                                               \n",
      "[11000]\ttraining's auc: 0.904128\tvalid_1's auc: 0.882984                                                               \n",
      "[12000]\ttraining's auc: 0.906525\tvalid_1's auc: 0.884959                                                               \n",
      "[13000]\ttraining's auc: 0.908495\tvalid_1's auc: 0.886459                                                               \n",
      "[14000]\ttraining's auc: 0.910392\tvalid_1's auc: 0.887935                                                               \n",
      "[15000]\ttraining's auc: 0.911991\tvalid_1's auc: 0.88924                                                                \n",
      "[16000]\ttraining's auc: 0.913438\tvalid_1's auc: 0.89026                                                                \n",
      "[17000]\ttraining's auc: 0.914761\tvalid_1's auc: 0.891039                                                               \n",
      "[18000]\ttraining's auc: 0.915962\tvalid_1's auc: 0.891811                                                               \n",
      "[19000]\ttraining's auc: 0.917073\tvalid_1's auc: 0.892544                                                               \n",
      "[20000]\ttraining's auc: 0.918096\tvalid_1's auc: 0.893115                                                               \n",
      "[21000]\ttraining's auc: 0.919028\tvalid_1's auc: 0.893544                                                               \n",
      "[22000]\ttraining's auc: 0.919884\tvalid_1's auc: 0.893946                                                               \n",
      "[23000]\ttraining's auc: 0.920703\tvalid_1's auc: 0.89425                                                                \n",
      "[24000]\ttraining's auc: 0.921513\tvalid_1's auc: 0.894588                                                               \n",
      "[25000]\ttraining's auc: 0.922218\tvalid_1's auc: 0.894838                                                               \n",
      "[26000]\ttraining's auc: 0.92292\tvalid_1's auc: 0.895106                                                                \n",
      "[27000]\ttraining's auc: 0.923578\tvalid_1's auc: 0.895316                                                               \n",
      "[28000]\ttraining's auc: 0.924215\tvalid_1's auc: 0.895582                                                               \n",
      "[29000]\ttraining's auc: 0.924825\tvalid_1's auc: 0.895752                                                               \n",
      "[30000]\ttraining's auc: 0.925417\tvalid_1's auc: 0.895891                                                               \n",
      "[31000]\ttraining's auc: 0.926\tvalid_1's auc: 0.896013                                                                  \n",
      "[32000]\ttraining's auc: 0.926567\tvalid_1's auc: 0.896172                                                               \n",
      "[33000]\ttraining's auc: 0.92711\tvalid_1's auc: 0.896176                                                                \n",
      "[34000]\ttraining's auc: 0.92767\tvalid_1's auc: 0.896297                                                                \n",
      "[35000]\ttraining's auc: 0.928185\tvalid_1's auc: 0.896317                                                               \n",
      "[36000]\ttraining's auc: 0.928701\tvalid_1's auc: 0.896387                                                               \n",
      "[37000]\ttraining's auc: 0.929211\tvalid_1's auc: 0.89641                                                                \n",
      "[38000]\ttraining's auc: 0.929685\tvalid_1's auc: 0.896394                                                               \n",
      "[39000]\ttraining's auc: 0.930161\tvalid_1's auc: 0.896413                                                               \n",
      "[40000]\ttraining's auc: 0.930644\tvalid_1's auc: 0.896374                                                               \n",
      "[41000]\ttraining's auc: 0.931123\tvalid_1's auc: 0.896377                                                               \n",
      "[42000]\ttraining's auc: 0.931597\tvalid_1's auc: 0.896329                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[39192]\ttraining's auc: 0.930248\tvalid_1's auc: 0.89643\n",
      "new best:                                                                                                              \n",
      "0.8968215843151981                                                                                                     \n",
      "{'bagging_fraction': 0.19181305535487048, 'bagging_freq': 4, 'boost': 'gbdt', 'boost_from_average': True, 'feature_fraction': 0.10113026661097753, 'is_unbalance': False, 'learning_rate': 0.0040412491234661126, 'max_depth': 2, 'metric': 'auc', 'min_data_in_leaf': 50, 'min_sum_hessian_in_leaf': 5, 'num_leaves': 17, 'objective': 'binary', 'tree_learner': 'serial'}\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.807212\tvalid_1's auc: 0.795852                                                                \n",
      "[2000]\ttraining's auc: 0.835107\tvalid_1's auc: 0.8226                                                                  \n",
      "[3000]\ttraining's auc: 0.853546\tvalid_1's auc: 0.84034                                                                 \n",
      "[4000]\ttraining's auc: 0.865281\tvalid_1's auc: 0.85166                                                                 \n",
      "[5000]\ttraining's auc: 0.874317\tvalid_1's auc: 0.859895                                                                \n",
      "[6000]\ttraining's auc: 0.881578\tvalid_1's auc: 0.866451                                                                \n",
      "[7000]\ttraining's auc: 0.887378\tvalid_1's auc: 0.871824                                                                \n",
      "[8000]\ttraining's auc: 0.892078\tvalid_1's auc: 0.875943                                                                \n",
      "[9000]\ttraining's auc: 0.895962\tvalid_1's auc: 0.879387                                                                \n",
      "[10000]\ttraining's auc: 0.899135\tvalid_1's auc: 0.882233                                                               \n",
      "[11000]\ttraining's auc: 0.901971\tvalid_1's auc: 0.884587                                                               \n",
      "[12000]\ttraining's auc: 0.904333\tvalid_1's auc: 0.886462                                                               \n",
      "[13000]\ttraining's auc: 0.906515\tvalid_1's auc: 0.888206                                                               \n",
      "[14000]\ttraining's auc: 0.908409\tvalid_1's auc: 0.889608                                                               \n",
      "[15000]\ttraining's auc: 0.910119\tvalid_1's auc: 0.890844                                                               \n",
      "[16000]\ttraining's auc: 0.911675\tvalid_1's auc: 0.892021                                                               \n",
      "[17000]\ttraining's auc: 0.913025\tvalid_1's auc: 0.892916                                                               \n",
      "[18000]\ttraining's auc: 0.914343\tvalid_1's auc: 0.893814                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19000]\ttraining's auc: 0.915455\tvalid_1's auc: 0.894532                                                               \n",
      "[20000]\ttraining's auc: 0.916553\tvalid_1's auc: 0.895256                                                               \n",
      "[21000]\ttraining's auc: 0.917535\tvalid_1's auc: 0.89577                                                                \n",
      "[22000]\ttraining's auc: 0.918474\tvalid_1's auc: 0.896203                                                               \n",
      "[23000]\ttraining's auc: 0.919349\tvalid_1's auc: 0.89667                                                                \n",
      "[24000]\ttraining's auc: 0.920161\tvalid_1's auc: 0.89706                                                                \n",
      "[25000]\ttraining's auc: 0.92093\tvalid_1's auc: 0.897315                                                                \n",
      "[26000]\ttraining's auc: 0.921638\tvalid_1's auc: 0.897573                                                               \n",
      "[27000]\ttraining's auc: 0.922369\tvalid_1's auc: 0.897856                                                               \n",
      "[28000]\ttraining's auc: 0.923043\tvalid_1's auc: 0.898102                                                               \n",
      "[29000]\ttraining's auc: 0.923681\tvalid_1's auc: 0.898244                                                               \n",
      "[30000]\ttraining's auc: 0.924321\tvalid_1's auc: 0.898344                                                               \n",
      "[31000]\ttraining's auc: 0.92492\tvalid_1's auc: 0.898509                                                                \n",
      "[32000]\ttraining's auc: 0.925524\tvalid_1's auc: 0.89865                                                                \n",
      "[33000]\ttraining's auc: 0.92611\tvalid_1's auc: 0.898709                                                                \n",
      "[34000]\ttraining's auc: 0.926666\tvalid_1's auc: 0.898781                                                               \n",
      "[35000]\ttraining's auc: 0.927225\tvalid_1's auc: 0.898763                                                               \n",
      "[36000]\ttraining's auc: 0.927767\tvalid_1's auc: 0.898804                                                               \n",
      "[37000]\ttraining's auc: 0.928289\tvalid_1's auc: 0.898771                                                               \n",
      "[38000]\ttraining's auc: 0.928832\tvalid_1's auc: 0.898801                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35866]\ttraining's auc: 0.927691\tvalid_1's auc: 0.898822\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.804975\tvalid_1's auc: 0.78343                                                                 \n",
      "[2000]\ttraining's auc: 0.836356\tvalid_1's auc: 0.814985                                                                \n",
      "[3000]\ttraining's auc: 0.855583\tvalid_1's auc: 0.833451                                                                \n",
      "[4000]\ttraining's auc: 0.867726\tvalid_1's auc: 0.844888                                                                \n",
      "[5000]\ttraining's auc: 0.877564\tvalid_1's auc: 0.853397                                                                \n",
      "[6000]\ttraining's auc: 0.885041\tvalid_1's auc: 0.860205                                                                \n",
      "[7000]\ttraining's auc: 0.890662\tvalid_1's auc: 0.865136                                                                \n",
      "[8000]\ttraining's auc: 0.895237\tvalid_1's auc: 0.869194                                                                \n",
      "[9000]\ttraining's auc: 0.899132\tvalid_1's auc: 0.872362                                                                \n",
      "[10000]\ttraining's auc: 0.902616\tvalid_1's auc: 0.875298                                                               \n",
      "[11000]\ttraining's auc: 0.905407\tvalid_1's auc: 0.877561                                                               \n",
      "[12000]\ttraining's auc: 0.907867\tvalid_1's auc: 0.879486                                                               \n",
      "[13000]\ttraining's auc: 0.910044\tvalid_1's auc: 0.881334                                                               \n",
      "[14000]\ttraining's auc: 0.912056\tvalid_1's auc: 0.882781                                                               \n",
      "[15000]\ttraining's auc: 0.913795\tvalid_1's auc: 0.88397                                                                \n",
      "[16000]\ttraining's auc: 0.915347\tvalid_1's auc: 0.885144                                                               \n",
      "[17000]\ttraining's auc: 0.916757\tvalid_1's auc: 0.886072                                                               \n",
      "[18000]\ttraining's auc: 0.918004\tvalid_1's auc: 0.88687                                                                \n",
      "[19000]\ttraining's auc: 0.91914\tvalid_1's auc: 0.887559                                                                \n",
      "[20000]\ttraining's auc: 0.920177\tvalid_1's auc: 0.888099                                                               \n",
      "[21000]\ttraining's auc: 0.92114\tvalid_1's auc: 0.888634                                                                \n",
      "[22000]\ttraining's auc: 0.922046\tvalid_1's auc: 0.889103                                                               \n",
      "[23000]\ttraining's auc: 0.922888\tvalid_1's auc: 0.889532                                                               \n",
      "[24000]\ttraining's auc: 0.923658\tvalid_1's auc: 0.889847                                                               \n",
      "[25000]\ttraining's auc: 0.924405\tvalid_1's auc: 0.890142                                                               \n",
      "[26000]\ttraining's auc: 0.92508\tvalid_1's auc: 0.890457                                                                \n",
      "[27000]\ttraining's auc: 0.925762\tvalid_1's auc: 0.890732                                                               \n",
      "[28000]\ttraining's auc: 0.926416\tvalid_1's auc: 0.890864                                                               \n",
      "[29000]\ttraining's auc: 0.927036\tvalid_1's auc: 0.891058                                                               \n",
      "[30000]\ttraining's auc: 0.927629\tvalid_1's auc: 0.89117                                                                \n",
      "[31000]\ttraining's auc: 0.928205\tvalid_1's auc: 0.891358                                                               \n",
      "[32000]\ttraining's auc: 0.928803\tvalid_1's auc: 0.891485                                                               \n",
      "[33000]\ttraining's auc: 0.929359\tvalid_1's auc: 0.891558                                                               \n",
      "[34000]\ttraining's auc: 0.92989\tvalid_1's auc: 0.891603                                                                \n",
      "[35000]\ttraining's auc: 0.930421\tvalid_1's auc: 0.891623                                                               \n",
      "[36000]\ttraining's auc: 0.930949\tvalid_1's auc: 0.891627                                                               \n",
      "[37000]\ttraining's auc: 0.931447\tvalid_1's auc: 0.89165                                                                \n",
      "[38000]\ttraining's auc: 0.931949\tvalid_1's auc: 0.891606                                                               \n",
      "[39000]\ttraining's auc: 0.932443\tvalid_1's auc: 0.891554                                                               \n",
      "[40000]\ttraining's auc: 0.932933\tvalid_1's auc: 0.891546                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[37322]\ttraining's auc: 0.931613\tvalid_1's auc: 0.891673\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.805731\tvalid_1's auc: 0.792529                                                                \n",
      "[2000]\ttraining's auc: 0.836328\tvalid_1's auc: 0.821567                                                                \n",
      "[3000]\ttraining's auc: 0.854383\tvalid_1's auc: 0.838724                                                                \n",
      "[4000]\ttraining's auc: 0.866465\tvalid_1's auc: 0.850143                                                                \n",
      "[5000]\ttraining's auc: 0.875341\tvalid_1's auc: 0.858519                                                                \n",
      "[6000]\ttraining's auc: 0.882571\tvalid_1's auc: 0.86524                                                                 \n",
      "[7000]\ttraining's auc: 0.888337\tvalid_1's auc: 0.870321                                                                \n",
      "[8000]\ttraining's auc: 0.892926\tvalid_1's auc: 0.8746                                                                  \n",
      "[9000]\ttraining's auc: 0.89688\tvalid_1's auc: 0.878092                                                                 \n",
      "[10000]\ttraining's auc: 0.900151\tvalid_1's auc: 0.880772                                                               \n",
      "[11000]\ttraining's auc: 0.903033\tvalid_1's auc: 0.883255                                                               \n",
      "[12000]\ttraining's auc: 0.905498\tvalid_1's auc: 0.885182                                                               \n",
      "[13000]\ttraining's auc: 0.907563\tvalid_1's auc: 0.886755                                                               \n",
      "[14000]\ttraining's auc: 0.909502\tvalid_1's auc: 0.888238                                                               \n",
      "[15000]\ttraining's auc: 0.911184\tvalid_1's auc: 0.889558                                                               \n",
      "[16000]\ttraining's auc: 0.912674\tvalid_1's auc: 0.890741                                                               \n",
      "[17000]\ttraining's auc: 0.914085\tvalid_1's auc: 0.891809                                                               \n",
      "[18000]\ttraining's auc: 0.915307\tvalid_1's auc: 0.892706                                                               \n",
      "[19000]\ttraining's auc: 0.916426\tvalid_1's auc: 0.893589                                                               \n",
      "[20000]\ttraining's auc: 0.917438\tvalid_1's auc: 0.894383                                                               \n",
      "[21000]\ttraining's auc: 0.918391\tvalid_1's auc: 0.894963                                                               \n",
      "[22000]\ttraining's auc: 0.919284\tvalid_1's auc: 0.895472                                                               \n",
      "[23000]\ttraining's auc: 0.920106\tvalid_1's auc: 0.895988                                                               \n",
      "[24000]\ttraining's auc: 0.920938\tvalid_1's auc: 0.896427                                                               \n",
      "[25000]\ttraining's auc: 0.921721\tvalid_1's auc: 0.896832                                                               \n",
      "[26000]\ttraining's auc: 0.922466\tvalid_1's auc: 0.897221                                                               \n",
      "[27000]\ttraining's auc: 0.923167\tvalid_1's auc: 0.897511                                                               \n",
      "[28000]\ttraining's auc: 0.923828\tvalid_1's auc: 0.897749                                                               \n",
      "[29000]\ttraining's auc: 0.924479\tvalid_1's auc: 0.898002                                                               \n",
      "[30000]\ttraining's auc: 0.925095\tvalid_1's auc: 0.898201                                                               \n",
      "[31000]\ttraining's auc: 0.925692\tvalid_1's auc: 0.898398                                                               \n",
      "[32000]\ttraining's auc: 0.926269\tvalid_1's auc: 0.898603                                                               \n",
      "[33000]\ttraining's auc: 0.926831\tvalid_1's auc: 0.89874                                                                \n",
      "[34000]\ttraining's auc: 0.92739\tvalid_1's auc: 0.898844                                                                \n",
      "[35000]\ttraining's auc: 0.927944\tvalid_1's auc: 0.899004                                                               \n",
      "[36000]\ttraining's auc: 0.928483\tvalid_1's auc: 0.899053                                                               \n",
      "[37000]\ttraining's auc: 0.929034\tvalid_1's auc: 0.899151                                                               \n",
      "[38000]\ttraining's auc: 0.929552\tvalid_1's auc: 0.899206                                                               \n",
      "[39000]\ttraining's auc: 0.930074\tvalid_1's auc: 0.89925                                                                \n",
      "[40000]\ttraining's auc: 0.930547\tvalid_1's auc: 0.899342                                                               \n",
      "[41000]\ttraining's auc: 0.931045\tvalid_1's auc: 0.8994                                                                 \n",
      "[42000]\ttraining's auc: 0.931536\tvalid_1's auc: 0.89939                                                                \n",
      "[43000]\ttraining's auc: 0.932025\tvalid_1's auc: 0.899414                                                               \n",
      "[44000]\ttraining's auc: 0.932504\tvalid_1's auc: 0.899384                                                               \n",
      "[45000]\ttraining's auc: 0.932984\tvalid_1's auc: 0.89939                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42729]\ttraining's auc: 0.931895\tvalid_1's auc: 0.899434\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.803432\tvalid_1's auc: 0.791636                                                                \n",
      "[2000]\ttraining's auc: 0.836004\tvalid_1's auc: 0.821563                                                                \n",
      "[3000]\ttraining's auc: 0.855798\tvalid_1's auc: 0.839432                                                                \n",
      "[4000]\ttraining's auc: 0.868478\tvalid_1's auc: 0.850613                                                                \n",
      "[5000]\ttraining's auc: 0.877142\tvalid_1's auc: 0.858417                                                                \n",
      "[6000]\ttraining's auc: 0.883827\tvalid_1's auc: 0.864171                                                                \n",
      "[7000]\ttraining's auc: 0.889463\tvalid_1's auc: 0.869069                                                                \n",
      "[8000]\ttraining's auc: 0.893932\tvalid_1's auc: 0.87284                                                                 \n",
      "[9000]\ttraining's auc: 0.897682\tvalid_1's auc: 0.876065                                                                \n",
      "[10000]\ttraining's auc: 0.900938\tvalid_1's auc: 0.878774                                                               \n",
      "[11000]\ttraining's auc: 0.903767\tvalid_1's auc: 0.881104                                                               \n",
      "[12000]\ttraining's auc: 0.906276\tvalid_1's auc: 0.883092                                                               \n",
      "[13000]\ttraining's auc: 0.908406\tvalid_1's auc: 0.884724                                                               \n",
      "[14000]\ttraining's auc: 0.910445\tvalid_1's auc: 0.886166                                                               \n",
      "[15000]\ttraining's auc: 0.912253\tvalid_1's auc: 0.887514                                                               \n",
      "[16000]\ttraining's auc: 0.913821\tvalid_1's auc: 0.888661                                                               \n",
      "[17000]\ttraining's auc: 0.915213\tvalid_1's auc: 0.889638                                                               \n",
      "[18000]\ttraining's auc: 0.916566\tvalid_1's auc: 0.890482                                                               \n",
      "[19000]\ttraining's auc: 0.917779\tvalid_1's auc: 0.891268                                                               \n",
      "[20000]\ttraining's auc: 0.918863\tvalid_1's auc: 0.89191                                                                \n",
      "[21000]\ttraining's auc: 0.91989\tvalid_1's auc: 0.892508                                                                \n",
      "[22000]\ttraining's auc: 0.920844\tvalid_1's auc: 0.893063                                                               \n",
      "[23000]\ttraining's auc: 0.921692\tvalid_1's auc: 0.893516                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24000]\ttraining's auc: 0.922546\tvalid_1's auc: 0.894062                                                               \n",
      "[25000]\ttraining's auc: 0.923304\tvalid_1's auc: 0.894382                                                               \n",
      "[26000]\ttraining's auc: 0.924042\tvalid_1's auc: 0.894675                                                               \n",
      "[27000]\ttraining's auc: 0.924705\tvalid_1's auc: 0.894802                                                               \n",
      "[28000]\ttraining's auc: 0.925355\tvalid_1's auc: 0.895052                                                               \n",
      "[29000]\ttraining's auc: 0.925983\tvalid_1's auc: 0.895235                                                               \n",
      "[30000]\ttraining's auc: 0.926639\tvalid_1's auc: 0.895449                                                               \n",
      "[31000]\ttraining's auc: 0.927249\tvalid_1's auc: 0.895556                                                               \n",
      "[32000]\ttraining's auc: 0.927874\tvalid_1's auc: 0.895717                                                               \n",
      "[33000]\ttraining's auc: 0.928437\tvalid_1's auc: 0.895838                                                               \n",
      "[34000]\ttraining's auc: 0.928957\tvalid_1's auc: 0.895906                                                               \n",
      "[35000]\ttraining's auc: 0.929511\tvalid_1's auc: 0.895984                                                               \n",
      "[36000]\ttraining's auc: 0.93002\tvalid_1's auc: 0.896052                                                                \n",
      "[37000]\ttraining's auc: 0.93053\tvalid_1's auc: 0.896086                                                                \n",
      "[38000]\ttraining's auc: 0.931027\tvalid_1's auc: 0.896119                                                               \n",
      "[39000]\ttraining's auc: 0.931516\tvalid_1's auc: 0.896164                                                               \n",
      "[40000]\ttraining's auc: 0.932004\tvalid_1's auc: 0.89617                                                                \n",
      "[41000]\ttraining's auc: 0.932492\tvalid_1's auc: 0.896254                                                               \n",
      "[42000]\ttraining's auc: 0.932985\tvalid_1's auc: 0.896281                                                               \n",
      "[43000]\ttraining's auc: 0.933463\tvalid_1's auc: 0.896284                                                               \n",
      "[44000]\ttraining's auc: 0.933938\tvalid_1's auc: 0.896269                                                               \n",
      "[45000]\ttraining's auc: 0.934388\tvalid_1's auc: 0.896265                                                               \n",
      "[46000]\ttraining's auc: 0.934864\tvalid_1's auc: 0.896196                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43041]\ttraining's auc: 0.933481\tvalid_1's auc: 0.896294\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.811882\tvalid_1's auc: 0.802114                                                                \n",
      "[2000]\ttraining's auc: 0.837168\tvalid_1's auc: 0.826273                                                                \n",
      "[3000]\ttraining's auc: 0.854714\tvalid_1's auc: 0.842696                                                                \n",
      "[4000]\ttraining's auc: 0.866461\tvalid_1's auc: 0.853883                                                                \n",
      "[5000]\ttraining's auc: 0.874965\tvalid_1's auc: 0.861838                                                                \n",
      "[6000]\ttraining's auc: 0.882011\tvalid_1's auc: 0.868211                                                                \n",
      "[7000]\ttraining's auc: 0.88779\tvalid_1's auc: 0.873218                                                                 \n",
      "[8000]\ttraining's auc: 0.89237\tvalid_1's auc: 0.877057                                                                 \n",
      "[9000]\ttraining's auc: 0.896389\tvalid_1's auc: 0.880387                                                                \n",
      "[10000]\ttraining's auc: 0.89969\tvalid_1's auc: 0.883271                                                                \n",
      "[11000]\ttraining's auc: 0.902428\tvalid_1's auc: 0.885316                                                               \n",
      "[12000]\ttraining's auc: 0.904873\tvalid_1's auc: 0.887223                                                               \n",
      "[13000]\ttraining's auc: 0.906946\tvalid_1's auc: 0.888809                                                               \n",
      "[14000]\ttraining's auc: 0.908811\tvalid_1's auc: 0.890207                                                               \n",
      "[15000]\ttraining's auc: 0.910575\tvalid_1's auc: 0.891459                                                               \n",
      "[16000]\ttraining's auc: 0.91219\tvalid_1's auc: 0.892422                                                                \n",
      "[17000]\ttraining's auc: 0.913558\tvalid_1's auc: 0.893203                                                               \n",
      "[18000]\ttraining's auc: 0.914793\tvalid_1's auc: 0.893931                                                               \n",
      "[19000]\ttraining's auc: 0.915949\tvalid_1's auc: 0.894524                                                               \n",
      "[20000]\ttraining's auc: 0.917048\tvalid_1's auc: 0.895077                                                               \n",
      "[21000]\ttraining's auc: 0.918055\tvalid_1's auc: 0.895424                                                               \n",
      "[22000]\ttraining's auc: 0.918999\tvalid_1's auc: 0.895859                                                               \n",
      "[23000]\ttraining's auc: 0.919876\tvalid_1's auc: 0.89617                                                                \n",
      "[24000]\ttraining's auc: 0.920742\tvalid_1's auc: 0.89648                                                                \n",
      "[25000]\ttraining's auc: 0.921573\tvalid_1's auc: 0.896709                                                               \n",
      "[26000]\ttraining's auc: 0.922356\tvalid_1's auc: 0.896913                                                               \n",
      "[27000]\ttraining's auc: 0.923076\tvalid_1's auc: 0.897071                                                               \n",
      "[28000]\ttraining's auc: 0.923792\tvalid_1's auc: 0.897187                                                               \n",
      "[29000]\ttraining's auc: 0.924474\tvalid_1's auc: 0.897293                                                               \n",
      "[30000]\ttraining's auc: 0.925155\tvalid_1's auc: 0.897393                                                               \n",
      "[31000]\ttraining's auc: 0.925803\tvalid_1's auc: 0.897366                                                               \n",
      "[32000]\ttraining's auc: 0.926476\tvalid_1's auc: 0.897381                                                               \n",
      "[33000]\ttraining's auc: 0.927129\tvalid_1's auc: 0.897438                                                               \n",
      "[34000]\ttraining's auc: 0.927771\tvalid_1's auc: 0.897429                                                               \n",
      "[35000]\ttraining's auc: 0.928408\tvalid_1's auc: 0.897404                                                               \n",
      "[36000]\ttraining's auc: 0.929015\tvalid_1's auc: 0.897404                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33055]\ttraining's auc: 0.927167\tvalid_1's auc: 0.897447\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.811384\tvalid_1's auc: 0.791338                                                                \n",
      "[2000]\ttraining's auc: 0.838286\tvalid_1's auc: 0.817928                                                                \n",
      "[3000]\ttraining's auc: 0.856314\tvalid_1's auc: 0.835365                                                                \n",
      "[4000]\ttraining's auc: 0.868666\tvalid_1's auc: 0.846951                                                                \n",
      "[5000]\ttraining's auc: 0.878239\tvalid_1's auc: 0.855271                                                                \n",
      "[6000]\ttraining's auc: 0.885554\tvalid_1's auc: 0.861677                                                                \n",
      "[7000]\ttraining's auc: 0.891327\tvalid_1's auc: 0.866638                                                                \n",
      "[8000]\ttraining's auc: 0.896037\tvalid_1's auc: 0.870627                                                                \n",
      "[9000]\ttraining's auc: 0.899907\tvalid_1's auc: 0.873894                                                                \n",
      "[10000]\ttraining's auc: 0.903076\tvalid_1's auc: 0.876525                                                               \n",
      "[11000]\ttraining's auc: 0.905847\tvalid_1's auc: 0.878645                                                               \n",
      "[12000]\ttraining's auc: 0.908403\tvalid_1's auc: 0.880687                                                               \n",
      "[13000]\ttraining's auc: 0.910505\tvalid_1's auc: 0.882492                                                               \n",
      "[14000]\ttraining's auc: 0.912419\tvalid_1's auc: 0.884007                                                               \n",
      "[15000]\ttraining's auc: 0.91414\tvalid_1's auc: 0.885266                                                                \n",
      "[16000]\ttraining's auc: 0.915736\tvalid_1's auc: 0.886181                                                               \n",
      "[17000]\ttraining's auc: 0.917078\tvalid_1's auc: 0.886826                                                               \n",
      "[18000]\ttraining's auc: 0.918298\tvalid_1's auc: 0.887531                                                               \n",
      "[19000]\ttraining's auc: 0.919486\tvalid_1's auc: 0.888094                                                               \n",
      "[20000]\ttraining's auc: 0.920554\tvalid_1's auc: 0.888663                                                               \n",
      "[21000]\ttraining's auc: 0.921522\tvalid_1's auc: 0.889128                                                               \n",
      "[22000]\ttraining's auc: 0.922425\tvalid_1's auc: 0.889439                                                               \n",
      "[23000]\ttraining's auc: 0.923328\tvalid_1's auc: 0.889737                                                               \n",
      "[24000]\ttraining's auc: 0.924108\tvalid_1's auc: 0.889949                                                               \n",
      "[25000]\ttraining's auc: 0.924858\tvalid_1's auc: 0.890137                                                               \n",
      "[26000]\ttraining's auc: 0.925616\tvalid_1's auc: 0.890268                                                               \n",
      "[27000]\ttraining's auc: 0.926335\tvalid_1's auc: 0.890455                                                               \n",
      "[28000]\ttraining's auc: 0.927037\tvalid_1's auc: 0.890608                                                               \n",
      "[29000]\ttraining's auc: 0.927724\tvalid_1's auc: 0.89063                                                                \n",
      "[30000]\ttraining's auc: 0.928358\tvalid_1's auc: 0.890571                                                               \n",
      "[31000]\ttraining's auc: 0.928978\tvalid_1's auc: 0.89058                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28663]\ttraining's auc: 0.927488\tvalid_1's auc: 0.890669\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.809517\tvalid_1's auc: 0.795445                                                                \n",
      "[2000]\ttraining's auc: 0.837338\tvalid_1's auc: 0.822737                                                                \n",
      "[3000]\ttraining's auc: 0.854742\tvalid_1's auc: 0.839626                                                                \n",
      "[4000]\ttraining's auc: 0.866971\tvalid_1's auc: 0.851328                                                                \n",
      "[5000]\ttraining's auc: 0.87635\tvalid_1's auc: 0.860094                                                                 \n",
      "[6000]\ttraining's auc: 0.883506\tvalid_1's auc: 0.866666                                                                \n",
      "[7000]\ttraining's auc: 0.889053\tvalid_1's auc: 0.871492                                                                \n",
      "[8000]\ttraining's auc: 0.893592\tvalid_1's auc: 0.875439                                                                \n",
      "[9000]\ttraining's auc: 0.897496\tvalid_1's auc: 0.878882                                                                \n",
      "[10000]\ttraining's auc: 0.900686\tvalid_1's auc: 0.881596                                                               \n",
      "[11000]\ttraining's auc: 0.903527\tvalid_1's auc: 0.883895                                                               \n",
      "[12000]\ttraining's auc: 0.906063\tvalid_1's auc: 0.885978                                                               \n",
      "[13000]\ttraining's auc: 0.908091\tvalid_1's auc: 0.887578                                                               \n",
      "[14000]\ttraining's auc: 0.910005\tvalid_1's auc: 0.889094                                                               \n",
      "[15000]\ttraining's auc: 0.911643\tvalid_1's auc: 0.890243                                                               \n",
      "[16000]\ttraining's auc: 0.913109\tvalid_1's auc: 0.891071                                                               \n",
      "[17000]\ttraining's auc: 0.914419\tvalid_1's auc: 0.891951                                                               \n",
      "[18000]\ttraining's auc: 0.915646\tvalid_1's auc: 0.892809                                                               \n",
      "[19000]\ttraining's auc: 0.916876\tvalid_1's auc: 0.893491                                                               \n",
      "[20000]\ttraining's auc: 0.917909\tvalid_1's auc: 0.894069                                                               \n",
      "[21000]\ttraining's auc: 0.918894\tvalid_1's auc: 0.894586                                                               \n",
      "[22000]\ttraining's auc: 0.919777\tvalid_1's auc: 0.895048                                                               \n",
      "[23000]\ttraining's auc: 0.920629\tvalid_1's auc: 0.895432                                                               \n",
      "[24000]\ttraining's auc: 0.921463\tvalid_1's auc: 0.895812                                                               \n",
      "[25000]\ttraining's auc: 0.922255\tvalid_1's auc: 0.896071                                                               \n",
      "[26000]\ttraining's auc: 0.923018\tvalid_1's auc: 0.896362                                                               \n",
      "[27000]\ttraining's auc: 0.923746\tvalid_1's auc: 0.896619                                                               \n",
      "[28000]\ttraining's auc: 0.924417\tvalid_1's auc: 0.89682                                                                \n",
      "[29000]\ttraining's auc: 0.925071\tvalid_1's auc: 0.896991                                                               \n",
      "[30000]\ttraining's auc: 0.925731\tvalid_1's auc: 0.897196                                                               \n",
      "[31000]\ttraining's auc: 0.926386\tvalid_1's auc: 0.897333                                                               \n",
      "[32000]\ttraining's auc: 0.927018\tvalid_1's auc: 0.897484                                                               \n",
      "[33000]\ttraining's auc: 0.927647\tvalid_1's auc: 0.897542                                                               \n",
      "[34000]\ttraining's auc: 0.92826\tvalid_1's auc: 0.897601                                                                \n",
      "[35000]\ttraining's auc: 0.928843\tvalid_1's auc: 0.897628                                                               \n",
      "[36000]\ttraining's auc: 0.929443\tvalid_1's auc: 0.897675                                                               \n",
      "[37000]\ttraining's auc: 0.930047\tvalid_1's auc: 0.89773                                                                \n",
      "[38000]\ttraining's auc: 0.930627\tvalid_1's auc: 0.897698                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39000]\ttraining's auc: 0.931228\tvalid_1's auc: 0.897802                                                               \n",
      "[40000]\ttraining's auc: 0.931803\tvalid_1's auc: 0.897815                                                               \n",
      "[41000]\ttraining's auc: 0.932362\tvalid_1's auc: 0.89785                                                                \n",
      "[42000]\ttraining's auc: 0.932906\tvalid_1's auc: 0.897875                                                               \n",
      "[43000]\ttraining's auc: 0.933462\tvalid_1's auc: 0.897879                                                               \n",
      "[44000]\ttraining's auc: 0.934019\tvalid_1's auc: 0.897825                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41590]\ttraining's auc: 0.932691\tvalid_1's auc: 0.897896\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.810219\tvalid_1's auc: 0.798618                                                                \n",
      "[2000]\ttraining's auc: 0.837999\tvalid_1's auc: 0.823683                                                                \n",
      "[3000]\ttraining's auc: 0.855875\tvalid_1's auc: 0.839535                                                                \n",
      "[4000]\ttraining's auc: 0.868613\tvalid_1's auc: 0.851039                                                                \n",
      "[5000]\ttraining's auc: 0.877115\tvalid_1's auc: 0.858317                                                                \n",
      "[6000]\ttraining's auc: 0.883877\tvalid_1's auc: 0.864236                                                                \n",
      "[7000]\ttraining's auc: 0.889481\tvalid_1's auc: 0.869266                                                                \n",
      "[8000]\ttraining's auc: 0.89409\tvalid_1's auc: 0.873421                                                                 \n",
      "[9000]\ttraining's auc: 0.898026\tvalid_1's auc: 0.876697                                                                \n",
      "[10000]\ttraining's auc: 0.901389\tvalid_1's auc: 0.87953                                                                \n",
      "[11000]\ttraining's auc: 0.904152\tvalid_1's auc: 0.881658                                                               \n",
      "[12000]\ttraining's auc: 0.90653\tvalid_1's auc: 0.88348                                                                 \n",
      "[13000]\ttraining's auc: 0.908756\tvalid_1's auc: 0.885168                                                               \n",
      "[14000]\ttraining's auc: 0.910657\tvalid_1's auc: 0.886533                                                               \n",
      "[15000]\ttraining's auc: 0.912388\tvalid_1's auc: 0.887753                                                               \n",
      "[16000]\ttraining's auc: 0.913948\tvalid_1's auc: 0.888903                                                               \n",
      "[17000]\ttraining's auc: 0.915427\tvalid_1's auc: 0.88981                                                                \n",
      "[18000]\ttraining's auc: 0.916774\tvalid_1's auc: 0.890716                                                               \n",
      "[19000]\ttraining's auc: 0.918008\tvalid_1's auc: 0.891358                                                               \n",
      "[20000]\ttraining's auc: 0.919104\tvalid_1's auc: 0.891894                                                               \n",
      "[21000]\ttraining's auc: 0.920147\tvalid_1's auc: 0.892407                                                               \n",
      "[22000]\ttraining's auc: 0.921041\tvalid_1's auc: 0.892916                                                               \n",
      "[23000]\ttraining's auc: 0.921922\tvalid_1's auc: 0.893232                                                               \n",
      "[24000]\ttraining's auc: 0.92279\tvalid_1's auc: 0.893606                                                                \n",
      "[25000]\ttraining's auc: 0.923608\tvalid_1's auc: 0.893821                                                               \n",
      "[26000]\ttraining's auc: 0.924387\tvalid_1's auc: 0.894048                                                               \n",
      "[27000]\ttraining's auc: 0.925118\tvalid_1's auc: 0.894271                                                               \n",
      "[28000]\ttraining's auc: 0.925812\tvalid_1's auc: 0.894286                                                               \n",
      "[29000]\ttraining's auc: 0.926471\tvalid_1's auc: 0.894479                                                               \n",
      "[30000]\ttraining's auc: 0.927121\tvalid_1's auc: 0.89461                                                                \n",
      "[31000]\ttraining's auc: 0.927818\tvalid_1's auc: 0.894631                                                               \n",
      "[32000]\ttraining's auc: 0.928462\tvalid_1's auc: 0.894695                                                               \n",
      "[33000]\ttraining's auc: 0.929081\tvalid_1's auc: 0.894791                                                               \n",
      "[34000]\ttraining's auc: 0.929684\tvalid_1's auc: 0.89481                                                                \n",
      "[35000]\ttraining's auc: 0.93027\tvalid_1's auc: 0.894822                                                                \n",
      "[36000]\ttraining's auc: 0.930859\tvalid_1's auc: 0.894829                                                               \n",
      "[37000]\ttraining's auc: 0.931445\tvalid_1's auc: 0.894805                                                               \n",
      "[38000]\ttraining's auc: 0.932017\tvalid_1's auc: 0.894844                                                               \n",
      "[39000]\ttraining's auc: 0.932599\tvalid_1's auc: 0.894893                                                               \n",
      "[40000]\ttraining's auc: 0.933168\tvalid_1's auc: 0.8949                                                                 \n",
      "[41000]\ttraining's auc: 0.933738\tvalid_1's auc: 0.894925                                                               \n",
      "[42000]\ttraining's auc: 0.934276\tvalid_1's auc: 0.894882                                                               \n",
      "[43000]\ttraining's auc: 0.934833\tvalid_1's auc: 0.894753                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40743]\ttraining's auc: 0.933595\tvalid_1's auc: 0.894957\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.829123\tvalid_1's auc: 0.817784                                                                \n",
      "[2000]\ttraining's auc: 0.853201\tvalid_1's auc: 0.841593                                                                \n",
      "[3000]\ttraining's auc: 0.869641\tvalid_1's auc: 0.85712                                                                 \n",
      "[4000]\ttraining's auc: 0.88082\tvalid_1's auc: 0.867406                                                                 \n",
      "[5000]\ttraining's auc: 0.88872\tvalid_1's auc: 0.874664                                                                 \n",
      "[6000]\ttraining's auc: 0.894407\tvalid_1's auc: 0.879759                                                                \n",
      "[7000]\ttraining's auc: 0.898953\tvalid_1's auc: 0.883716                                                                \n",
      "[8000]\ttraining's auc: 0.902643\tvalid_1's auc: 0.886838                                                                \n",
      "[9000]\ttraining's auc: 0.905821\tvalid_1's auc: 0.889443                                                                \n",
      "[10000]\ttraining's auc: 0.908412\tvalid_1's auc: 0.891524                                                               \n",
      "[11000]\ttraining's auc: 0.910574\tvalid_1's auc: 0.893014                                                               \n",
      "[12000]\ttraining's auc: 0.912481\tvalid_1's auc: 0.894188                                                               \n",
      "[13000]\ttraining's auc: 0.914135\tvalid_1's auc: 0.895276                                                               \n",
      "[14000]\ttraining's auc: 0.915671\tvalid_1's auc: 0.89615                                                                \n",
      "[15000]\ttraining's auc: 0.916956\tvalid_1's auc: 0.896814                                                               \n",
      "[16000]\ttraining's auc: 0.918184\tvalid_1's auc: 0.897356                                                               \n",
      "[17000]\ttraining's auc: 0.919262\tvalid_1's auc: 0.897769                                                               \n",
      "[18000]\ttraining's auc: 0.92025\tvalid_1's auc: 0.898104                                                                \n",
      "[19000]\ttraining's auc: 0.921211\tvalid_1's auc: 0.898321                                                               \n",
      "[20000]\ttraining's auc: 0.92209\tvalid_1's auc: 0.898474                                                                \n",
      "[21000]\ttraining's auc: 0.922961\tvalid_1's auc: 0.898596                                                               \n",
      "[22000]\ttraining's auc: 0.923746\tvalid_1's auc: 0.898696                                                               \n",
      "[23000]\ttraining's auc: 0.924502\tvalid_1's auc: 0.898706                                                               \n",
      "[24000]\ttraining's auc: 0.925292\tvalid_1's auc: 0.898718                                                               \n",
      "[25000]\ttraining's auc: 0.926063\tvalid_1's auc: 0.898789                                                               \n",
      "[26000]\ttraining's auc: 0.926798\tvalid_1's auc: 0.89874                                                                \n",
      "[27000]\ttraining's auc: 0.927508\tvalid_1's auc: 0.898685                                                               \n",
      "[28000]\ttraining's auc: 0.928195\tvalid_1's auc: 0.898634                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25278]\ttraining's auc: 0.92627\tvalid_1's auc: 0.898813\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.830422\tvalid_1's auc: 0.809354                                                                \n",
      "[2000]\ttraining's auc: 0.856063\tvalid_1's auc: 0.834601                                                                \n",
      "[3000]\ttraining's auc: 0.87223\tvalid_1's auc: 0.849996                                                                 \n",
      "[4000]\ttraining's auc: 0.883974\tvalid_1's auc: 0.860463                                                                \n",
      "[5000]\ttraining's auc: 0.892175\tvalid_1's auc: 0.867686                                                                \n",
      "[6000]\ttraining's auc: 0.898201\tvalid_1's auc: 0.872925                                                                \n",
      "[7000]\ttraining's auc: 0.90272\tvalid_1's auc: 0.876912                                                                 \n",
      "[8000]\ttraining's auc: 0.906381\tvalid_1's auc: 0.879891                                                                \n",
      "[9000]\ttraining's auc: 0.909545\tvalid_1's auc: 0.882167                                                                \n",
      "[10000]\ttraining's auc: 0.912148\tvalid_1's auc: 0.884139                                                               \n",
      "[11000]\ttraining's auc: 0.91417\tvalid_1's auc: 0.885624                                                                \n",
      "[12000]\ttraining's auc: 0.916113\tvalid_1's auc: 0.886952                                                               \n",
      "[13000]\ttraining's auc: 0.917696\tvalid_1's auc: 0.887924                                                               \n",
      "[14000]\ttraining's auc: 0.919167\tvalid_1's auc: 0.888851                                                               \n",
      "[15000]\ttraining's auc: 0.92049\tvalid_1's auc: 0.889442                                                                \n",
      "[16000]\ttraining's auc: 0.921662\tvalid_1's auc: 0.889989                                                               \n",
      "[17000]\ttraining's auc: 0.922768\tvalid_1's auc: 0.890359                                                               \n",
      "[18000]\ttraining's auc: 0.923766\tvalid_1's auc: 0.890657                                                               \n",
      "[19000]\ttraining's auc: 0.924689\tvalid_1's auc: 0.890871                                                               \n",
      "[20000]\ttraining's auc: 0.925524\tvalid_1's auc: 0.89111                                                                \n",
      "[21000]\ttraining's auc: 0.926388\tvalid_1's auc: 0.89123                                                                \n",
      "[22000]\ttraining's auc: 0.927143\tvalid_1's auc: 0.891353                                                               \n",
      "[23000]\ttraining's auc: 0.92789\tvalid_1's auc: 0.891418                                                                \n",
      "[24000]\ttraining's auc: 0.928624\tvalid_1's auc: 0.891406                                                               \n",
      "[25000]\ttraining's auc: 0.929326\tvalid_1's auc: 0.891339                                                               \n",
      "[26000]\ttraining's auc: 0.930041\tvalid_1's auc: 0.891358                                                               \n",
      "[27000]\ttraining's auc: 0.930716\tvalid_1's auc: 0.891313                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24261]\ttraining's auc: 0.928786\tvalid_1's auc: 0.891444\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.82895\tvalid_1's auc: 0.816413                                                                 \n",
      "[2000]\ttraining's auc: 0.855169\tvalid_1's auc: 0.841598                                                                \n",
      "[3000]\ttraining's auc: 0.870781\tvalid_1's auc: 0.85616                                                                 \n",
      "[4000]\ttraining's auc: 0.881738\tvalid_1's auc: 0.866241                                                                \n",
      "[5000]\ttraining's auc: 0.8896\tvalid_1's auc: 0.873671                                                                  \n",
      "[6000]\ttraining's auc: 0.895513\tvalid_1's auc: 0.878791                                                                \n",
      "[7000]\ttraining's auc: 0.900183\tvalid_1's auc: 0.882774                                                                \n",
      "[8000]\ttraining's auc: 0.903888\tvalid_1's auc: 0.885824                                                                \n",
      "[9000]\ttraining's auc: 0.906994\tvalid_1's auc: 0.888322                                                                \n",
      "[10000]\ttraining's auc: 0.909499\tvalid_1's auc: 0.890075                                                               \n",
      "[11000]\ttraining's auc: 0.911671\tvalid_1's auc: 0.891757                                                               \n",
      "[12000]\ttraining's auc: 0.913589\tvalid_1's auc: 0.893268                                                               \n",
      "[13000]\ttraining's auc: 0.915177\tvalid_1's auc: 0.894418                                                               \n",
      "[14000]\ttraining's auc: 0.916613\tvalid_1's auc: 0.895295                                                               \n",
      "[15000]\ttraining's auc: 0.917885\tvalid_1's auc: 0.895972                                                               \n",
      "[16000]\ttraining's auc: 0.919001\tvalid_1's auc: 0.896615                                                               \n",
      "[17000]\ttraining's auc: 0.920033\tvalid_1's auc: 0.897272                                                               \n",
      "[18000]\ttraining's auc: 0.920983\tvalid_1's auc: 0.897574                                                               \n",
      "[19000]\ttraining's auc: 0.921913\tvalid_1's auc: 0.898007                                                               \n",
      "[20000]\ttraining's auc: 0.922817\tvalid_1's auc: 0.898363                                                               \n",
      "[21000]\ttraining's auc: 0.923683\tvalid_1's auc: 0.898664                                                               \n",
      "[22000]\ttraining's auc: 0.924471\tvalid_1's auc: 0.898885                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23000]\ttraining's auc: 0.925245\tvalid_1's auc: 0.899126                                                               \n",
      "[24000]\ttraining's auc: 0.926022\tvalid_1's auc: 0.899267                                                               \n",
      "[25000]\ttraining's auc: 0.926752\tvalid_1's auc: 0.899392                                                               \n",
      "[26000]\ttraining's auc: 0.927512\tvalid_1's auc: 0.899461                                                               \n",
      "[27000]\ttraining's auc: 0.928203\tvalid_1's auc: 0.899503                                                               \n",
      "[28000]\ttraining's auc: 0.928883\tvalid_1's auc: 0.899439                                                               \n",
      "[29000]\ttraining's auc: 0.929542\tvalid_1's auc: 0.899436                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26666]\ttraining's auc: 0.927987\tvalid_1's auc: 0.899534\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.827741\tvalid_1's auc: 0.815006                                                                \n",
      "[2000]\ttraining's auc: 0.856081\tvalid_1's auc: 0.840477                                                                \n",
      "[3000]\ttraining's auc: 0.871697\tvalid_1's auc: 0.854618                                                                \n",
      "[4000]\ttraining's auc: 0.883092\tvalid_1's auc: 0.86526                                                                 \n",
      "[5000]\ttraining's auc: 0.890841\tvalid_1's auc: 0.871695                                                                \n",
      "[6000]\ttraining's auc: 0.896522\tvalid_1's auc: 0.876686                                                                \n",
      "[7000]\ttraining's auc: 0.901066\tvalid_1's auc: 0.880479                                                                \n",
      "[8000]\ttraining's auc: 0.904754\tvalid_1's auc: 0.883466                                                                \n",
      "[9000]\ttraining's auc: 0.907821\tvalid_1's auc: 0.885748                                                                \n",
      "[10000]\ttraining's auc: 0.910523\tvalid_1's auc: 0.887961                                                               \n",
      "[11000]\ttraining's auc: 0.912737\tvalid_1's auc: 0.889608                                                               \n",
      "[12000]\ttraining's auc: 0.914719\tvalid_1's auc: 0.891063                                                               \n",
      "[13000]\ttraining's auc: 0.916338\tvalid_1's auc: 0.892059                                                               \n",
      "[14000]\ttraining's auc: 0.917814\tvalid_1's auc: 0.892927                                                               \n",
      "[15000]\ttraining's auc: 0.919166\tvalid_1's auc: 0.89368                                                                \n",
      "[16000]\ttraining's auc: 0.920344\tvalid_1's auc: 0.894333                                                               \n",
      "[17000]\ttraining's auc: 0.921415\tvalid_1's auc: 0.894739                                                               \n",
      "[18000]\ttraining's auc: 0.922428\tvalid_1's auc: 0.895024                                                               \n",
      "[19000]\ttraining's auc: 0.923414\tvalid_1's auc: 0.895261                                                               \n",
      "[20000]\ttraining's auc: 0.924348\tvalid_1's auc: 0.895395                                                               \n",
      "[21000]\ttraining's auc: 0.925197\tvalid_1's auc: 0.895675                                                               \n",
      "[22000]\ttraining's auc: 0.92601\tvalid_1's auc: 0.895829                                                                \n",
      "[23000]\ttraining's auc: 0.926771\tvalid_1's auc: 0.895991                                                               \n",
      "[24000]\ttraining's auc: 0.927512\tvalid_1's auc: 0.896109                                                               \n",
      "[25000]\ttraining's auc: 0.928255\tvalid_1's auc: 0.896114                                                               \n",
      "[26000]\ttraining's auc: 0.928965\tvalid_1's auc: 0.896126                                                               \n",
      "[27000]\ttraining's auc: 0.929694\tvalid_1's auc: 0.896117                                                               \n",
      "[28000]\ttraining's auc: 0.930408\tvalid_1's auc: 0.896148                                                               \n",
      "[29000]\ttraining's auc: 0.931093\tvalid_1's auc: 0.896236                                                               \n",
      "[30000]\ttraining's auc: 0.931759\tvalid_1's auc: 0.896217                                                               \n",
      "[31000]\ttraining's auc: 0.932417\tvalid_1's auc: 0.896156                                                               \n",
      "[32000]\ttraining's auc: 0.933086\tvalid_1's auc: 0.896129                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[29542]\ttraining's auc: 0.931446\tvalid_1's auc: 0.896277\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.809543\tvalid_1's auc: 0.797208                                                                \n",
      "[2000]\ttraining's auc: 0.82267\tvalid_1's auc: 0.810507                                                                 \n",
      "[3000]\ttraining's auc: 0.834809\tvalid_1's auc: 0.822088                                                                \n",
      "[4000]\ttraining's auc: 0.845723\tvalid_1's auc: 0.832682                                                                \n",
      "[5000]\ttraining's auc: 0.855132\tvalid_1's auc: 0.841556                                                                \n",
      "[6000]\ttraining's auc: 0.862816\tvalid_1's auc: 0.848734                                                                \n",
      "[7000]\ttraining's auc: 0.869284\tvalid_1's auc: 0.85457                                                                 \n",
      "[8000]\ttraining's auc: 0.874685\tvalid_1's auc: 0.859304                                                                \n",
      "[9000]\ttraining's auc: 0.879337\tvalid_1's auc: 0.863422                                                                \n",
      "[10000]\ttraining's auc: 0.883428\tvalid_1's auc: 0.867262                                                               \n",
      "[11000]\ttraining's auc: 0.886843\tvalid_1's auc: 0.870104                                                               \n",
      "[12000]\ttraining's auc: 0.889909\tvalid_1's auc: 0.87286                                                                \n",
      "[13000]\ttraining's auc: 0.892728\tvalid_1's auc: 0.875189                                                               \n",
      "[14000]\ttraining's auc: 0.895262\tvalid_1's auc: 0.877297                                                               \n",
      "[15000]\ttraining's auc: 0.897596\tvalid_1's auc: 0.879176                                                               \n",
      "[16000]\ttraining's auc: 0.899662\tvalid_1's auc: 0.880896                                                               \n",
      "[17000]\ttraining's auc: 0.901476\tvalid_1's auc: 0.882339                                                               \n",
      "[18000]\ttraining's auc: 0.90318\tvalid_1's auc: 0.883642                                                                \n",
      "[19000]\ttraining's auc: 0.904751\tvalid_1's auc: 0.884893                                                               \n",
      "[20000]\ttraining's auc: 0.906174\tvalid_1's auc: 0.885855                                                               \n",
      "[21000]\ttraining's auc: 0.907481\tvalid_1's auc: 0.886809                                                               \n",
      "[22000]\ttraining's auc: 0.908737\tvalid_1's auc: 0.887752                                                               \n",
      "[23000]\ttraining's auc: 0.90994\tvalid_1's auc: 0.888669                                                                \n",
      "[24000]\ttraining's auc: 0.911012\tvalid_1's auc: 0.889392                                                               \n",
      "[25000]\ttraining's auc: 0.912047\tvalid_1's auc: 0.890123                                                               \n",
      "[26000]\ttraining's auc: 0.913004\tvalid_1's auc: 0.89076                                                                \n",
      "[27000]\ttraining's auc: 0.913937\tvalid_1's auc: 0.891359                                                               \n",
      "[28000]\ttraining's auc: 0.914762\tvalid_1's auc: 0.891877                                                               \n",
      "[29000]\ttraining's auc: 0.915587\tvalid_1's auc: 0.892365                                                               \n",
      "[30000]\ttraining's auc: 0.916388\tvalid_1's auc: 0.892868                                                               \n",
      "[31000]\ttraining's auc: 0.917148\tvalid_1's auc: 0.89336                                                                \n",
      "[32000]\ttraining's auc: 0.917858\tvalid_1's auc: 0.893727                                                               \n",
      "[33000]\ttraining's auc: 0.918542\tvalid_1's auc: 0.89408                                                                \n",
      "[34000]\ttraining's auc: 0.91917\tvalid_1's auc: 0.894401                                                                \n",
      "[35000]\ttraining's auc: 0.919803\tvalid_1's auc: 0.894703                                                               \n",
      "[36000]\ttraining's auc: 0.920421\tvalid_1's auc: 0.895                                                                  \n",
      "[37000]\ttraining's auc: 0.921012\tvalid_1's auc: 0.895274                                                               \n",
      "[38000]\ttraining's auc: 0.921588\tvalid_1's auc: 0.895559                                                               \n",
      "[39000]\ttraining's auc: 0.922149\tvalid_1's auc: 0.895768                                                               \n",
      "[40000]\ttraining's auc: 0.922662\tvalid_1's auc: 0.895925                                                               \n",
      "[41000]\ttraining's auc: 0.923173\tvalid_1's auc: 0.896148                                                               \n",
      "[42000]\ttraining's auc: 0.92368\tvalid_1's auc: 0.896349                                                                \n",
      "[43000]\ttraining's auc: 0.924179\tvalid_1's auc: 0.896502                                                               \n",
      "[44000]\ttraining's auc: 0.924632\tvalid_1's auc: 0.89661                                                                \n",
      "[45000]\ttraining's auc: 0.925108\tvalid_1's auc: 0.896741                                                               \n",
      "[46000]\ttraining's auc: 0.925564\tvalid_1's auc: 0.896843                                                               \n",
      "[47000]\ttraining's auc: 0.926\tvalid_1's auc: 0.896864                                                                  \n",
      "[48000]\ttraining's auc: 0.926435\tvalid_1's auc: 0.896969                                                               \n",
      "[49000]\ttraining's auc: 0.926869\tvalid_1's auc: 0.89701                                                                \n",
      "[50000]\ttraining's auc: 0.927299\tvalid_1's auc: 0.897054                                                               \n",
      "[51000]\ttraining's auc: 0.927716\tvalid_1's auc: 0.897116                                                               \n",
      "[52000]\ttraining's auc: 0.928143\tvalid_1's auc: 0.897145                                                               \n",
      "[53000]\ttraining's auc: 0.928561\tvalid_1's auc: 0.897186                                                               \n",
      "[54000]\ttraining's auc: 0.928944\tvalid_1's auc: 0.897205                                                               \n",
      "[55000]\ttraining's auc: 0.929323\tvalid_1's auc: 0.897237                                                               \n",
      "[56000]\ttraining's auc: 0.929713\tvalid_1's auc: 0.897307                                                               \n",
      "[57000]\ttraining's auc: 0.930086\tvalid_1's auc: 0.897366                                                               \n",
      "[58000]\ttraining's auc: 0.930451\tvalid_1's auc: 0.897363                                                               \n",
      "[59000]\ttraining's auc: 0.930814\tvalid_1's auc: 0.897368                                                               \n",
      "[60000]\ttraining's auc: 0.931179\tvalid_1's auc: 0.897361                                                               \n",
      "[61000]\ttraining's auc: 0.931546\tvalid_1's auc: 0.897381                                                               \n",
      "[62000]\ttraining's auc: 0.931914\tvalid_1's auc: 0.897397                                                               \n",
      "[63000]\ttraining's auc: 0.932285\tvalid_1's auc: 0.897384                                                               \n",
      "[64000]\ttraining's auc: 0.932654\tvalid_1's auc: 0.897374                                                               \n",
      "[65000]\ttraining's auc: 0.933008\tvalid_1's auc: 0.897332                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[62063]\ttraining's auc: 0.931937\tvalid_1's auc: 0.897407\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.811516\tvalid_1's auc: 0.792465                                                                \n",
      "[2000]\ttraining's auc: 0.823915\tvalid_1's auc: 0.803729                                                                \n",
      "[3000]\ttraining's auc: 0.836281\tvalid_1's auc: 0.815635                                                                \n",
      "[4000]\ttraining's auc: 0.848296\tvalid_1's auc: 0.826877                                                                \n",
      "[5000]\ttraining's auc: 0.857524\tvalid_1's auc: 0.835269                                                                \n",
      "[6000]\ttraining's auc: 0.865689\tvalid_1's auc: 0.842999                                                                \n",
      "[7000]\ttraining's auc: 0.872228\tvalid_1's auc: 0.848848                                                                \n",
      "[8000]\ttraining's auc: 0.877604\tvalid_1's auc: 0.853483                                                                \n",
      "[9000]\ttraining's auc: 0.882311\tvalid_1's auc: 0.857504                                                                \n",
      "[10000]\ttraining's auc: 0.886596\tvalid_1's auc: 0.861211                                                               \n",
      "[11000]\ttraining's auc: 0.889985\tvalid_1's auc: 0.864122                                                               \n",
      "[12000]\ttraining's auc: 0.89319\tvalid_1's auc: 0.866742                                                                \n",
      "[13000]\ttraining's auc: 0.896027\tvalid_1's auc: 0.869022                                                               \n",
      "[14000]\ttraining's auc: 0.898576\tvalid_1's auc: 0.871064                                                               \n",
      "[15000]\ttraining's auc: 0.900874\tvalid_1's auc: 0.872914                                                               \n",
      "[16000]\ttraining's auc: 0.90299\tvalid_1's auc: 0.874627                                                                \n",
      "[17000]\ttraining's auc: 0.904856\tvalid_1's auc: 0.87608                                                                \n",
      "[18000]\ttraining's auc: 0.906566\tvalid_1's auc: 0.877295                                                               \n",
      "[19000]\ttraining's auc: 0.908122\tvalid_1's auc: 0.878476                                                               \n",
      "[20000]\ttraining's auc: 0.909604\tvalid_1's auc: 0.87954                                                                \n",
      "[21000]\ttraining's auc: 0.911018\tvalid_1's auc: 0.880547                                                               \n",
      "[22000]\ttraining's auc: 0.91227\tvalid_1's auc: 0.881446                                                                \n",
      "[23000]\ttraining's auc: 0.913403\tvalid_1's auc: 0.882213                                                               \n",
      "[24000]\ttraining's auc: 0.914488\tvalid_1's auc: 0.88295                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25000]\ttraining's auc: 0.915495\tvalid_1's auc: 0.883575                                                               \n",
      "[26000]\ttraining's auc: 0.916487\tvalid_1's auc: 0.884209                                                               \n",
      "[27000]\ttraining's auc: 0.917446\tvalid_1's auc: 0.88481                                                                \n",
      "[28000]\ttraining's auc: 0.918243\tvalid_1's auc: 0.885269                                                               \n",
      "[29000]\ttraining's auc: 0.919044\tvalid_1's auc: 0.885737                                                               \n",
      "[30000]\ttraining's auc: 0.919807\tvalid_1's auc: 0.8862                                                                 \n",
      "[31000]\ttraining's auc: 0.920538\tvalid_1's auc: 0.88653                                                                \n",
      "[32000]\ttraining's auc: 0.921234\tvalid_1's auc: 0.886916                                                               \n",
      "[33000]\ttraining's auc: 0.92192\tvalid_1's auc: 0.887254                                                                \n",
      "[34000]\ttraining's auc: 0.922557\tvalid_1's auc: 0.887534                                                               \n",
      "[35000]\ttraining's auc: 0.923149\tvalid_1's auc: 0.887794                                                               \n",
      "[36000]\ttraining's auc: 0.923737\tvalid_1's auc: 0.888007                                                               \n",
      "[37000]\ttraining's auc: 0.924317\tvalid_1's auc: 0.888213                                                               \n",
      "[38000]\ttraining's auc: 0.92486\tvalid_1's auc: 0.888427                                                                \n",
      "[39000]\ttraining's auc: 0.925408\tvalid_1's auc: 0.888619                                                               \n",
      "[40000]\ttraining's auc: 0.925914\tvalid_1's auc: 0.888794                                                               \n",
      "[41000]\ttraining's auc: 0.92641\tvalid_1's auc: 0.889008                                                                \n",
      "[42000]\ttraining's auc: 0.926876\tvalid_1's auc: 0.889149                                                               \n",
      "[43000]\ttraining's auc: 0.927351\tvalid_1's auc: 0.889305                                                               \n",
      "[44000]\ttraining's auc: 0.927814\tvalid_1's auc: 0.889423                                                               \n",
      "[45000]\ttraining's auc: 0.928277\tvalid_1's auc: 0.889532                                                               \n",
      "[46000]\ttraining's auc: 0.928725\tvalid_1's auc: 0.889665                                                               \n",
      "[47000]\ttraining's auc: 0.929147\tvalid_1's auc: 0.889756                                                               \n",
      "[48000]\ttraining's auc: 0.929566\tvalid_1's auc: 0.889839                                                               \n",
      "[49000]\ttraining's auc: 0.929979\tvalid_1's auc: 0.889878                                                               \n",
      "[50000]\ttraining's auc: 0.930396\tvalid_1's auc: 0.889955                                                               \n",
      "[51000]\ttraining's auc: 0.930777\tvalid_1's auc: 0.890017                                                               \n",
      "[52000]\ttraining's auc: 0.931165\tvalid_1's auc: 0.890049                                                               \n",
      "[53000]\ttraining's auc: 0.931557\tvalid_1's auc: 0.890045                                                               \n",
      "[54000]\ttraining's auc: 0.931945\tvalid_1's auc: 0.890103                                                               \n",
      "[55000]\ttraining's auc: 0.932313\tvalid_1's auc: 0.890155                                                               \n",
      "[56000]\ttraining's auc: 0.932685\tvalid_1's auc: 0.890124                                                               \n",
      "[57000]\ttraining's auc: 0.933054\tvalid_1's auc: 0.890156                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54816]\ttraining's auc: 0.932243\tvalid_1's auc: 0.890169\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.809249\tvalid_1's auc: 0.794777                                                                \n",
      "[2000]\ttraining's auc: 0.822656\tvalid_1's auc: 0.808097                                                                \n",
      "[3000]\ttraining's auc: 0.835695\tvalid_1's auc: 0.820373                                                                \n",
      "[4000]\ttraining's auc: 0.846946\tvalid_1's auc: 0.83127                                                                 \n",
      "[5000]\ttraining's auc: 0.856135\tvalid_1's auc: 0.839793                                                                \n",
      "[6000]\ttraining's auc: 0.86387\tvalid_1's auc: 0.847117                                                                 \n",
      "[7000]\ttraining's auc: 0.870397\tvalid_1's auc: 0.853236                                                                \n",
      "[8000]\ttraining's auc: 0.875702\tvalid_1's auc: 0.858115                                                                \n",
      "[9000]\ttraining's auc: 0.880346\tvalid_1's auc: 0.862361                                                                \n",
      "[10000]\ttraining's auc: 0.884445\tvalid_1's auc: 0.865896                                                               \n",
      "[11000]\ttraining's auc: 0.888068\tvalid_1's auc: 0.869069                                                               \n",
      "[12000]\ttraining's auc: 0.891137\tvalid_1's auc: 0.871756                                                               \n",
      "[13000]\ttraining's auc: 0.893932\tvalid_1's auc: 0.874293                                                               \n",
      "[14000]\ttraining's auc: 0.896467\tvalid_1's auc: 0.876433                                                               \n",
      "[15000]\ttraining's auc: 0.898823\tvalid_1's auc: 0.878368                                                               \n",
      "[16000]\ttraining's auc: 0.900856\tvalid_1's auc: 0.880045                                                               \n",
      "[17000]\ttraining's auc: 0.902691\tvalid_1's auc: 0.881552                                                               \n",
      "[18000]\ttraining's auc: 0.904405\tvalid_1's auc: 0.88297                                                                \n",
      "[19000]\ttraining's auc: 0.905945\tvalid_1's auc: 0.884175                                                               \n",
      "[20000]\ttraining's auc: 0.907336\tvalid_1's auc: 0.885217                                                               \n",
      "[21000]\ttraining's auc: 0.908666\tvalid_1's auc: 0.886179                                                               \n",
      "[22000]\ttraining's auc: 0.909833\tvalid_1's auc: 0.887083                                                               \n",
      "[23000]\ttraining's auc: 0.910926\tvalid_1's auc: 0.887841                                                               \n",
      "[24000]\ttraining's auc: 0.912022\tvalid_1's auc: 0.888583                                                               \n",
      "[25000]\ttraining's auc: 0.913035\tvalid_1's auc: 0.889327                                                               \n",
      "[26000]\ttraining's auc: 0.913988\tvalid_1's auc: 0.889969                                                               \n",
      "[27000]\ttraining's auc: 0.914887\tvalid_1's auc: 0.890646                                                               \n",
      "[28000]\ttraining's auc: 0.915702\tvalid_1's auc: 0.891138                                                               \n",
      "[29000]\ttraining's auc: 0.916499\tvalid_1's auc: 0.891672                                                               \n",
      "[30000]\ttraining's auc: 0.917292\tvalid_1's auc: 0.892205                                                               \n",
      "[31000]\ttraining's auc: 0.918022\tvalid_1's auc: 0.8927                                                                 \n",
      "[32000]\ttraining's auc: 0.91867\tvalid_1's auc: 0.893091                                                                \n",
      "[33000]\ttraining's auc: 0.919335\tvalid_1's auc: 0.893534                                                               \n",
      "[34000]\ttraining's auc: 0.919954\tvalid_1's auc: 0.893878                                                               \n",
      "[35000]\ttraining's auc: 0.920565\tvalid_1's auc: 0.894222                                                               \n",
      "[36000]\ttraining's auc: 0.92115\tvalid_1's auc: 0.894563                                                                \n",
      "[37000]\ttraining's auc: 0.92172\tvalid_1's auc: 0.894829                                                                \n",
      "[38000]\ttraining's auc: 0.922278\tvalid_1's auc: 0.895098                                                               \n",
      "[39000]\ttraining's auc: 0.922815\tvalid_1's auc: 0.895361                                                               \n",
      "[40000]\ttraining's auc: 0.923323\tvalid_1's auc: 0.895568                                                               \n",
      "[41000]\ttraining's auc: 0.923841\tvalid_1's auc: 0.895771                                                               \n",
      "[42000]\ttraining's auc: 0.924333\tvalid_1's auc: 0.895948                                                               \n",
      "[43000]\ttraining's auc: 0.924805\tvalid_1's auc: 0.896139                                                               \n",
      "[44000]\ttraining's auc: 0.92524\tvalid_1's auc: 0.896319                                                                \n",
      "[45000]\ttraining's auc: 0.925709\tvalid_1's auc: 0.896518                                                               \n",
      "[46000]\ttraining's auc: 0.92616\tvalid_1's auc: 0.896683                                                                \n",
      "[47000]\ttraining's auc: 0.92659\tvalid_1's auc: 0.896821                                                                \n",
      "[48000]\ttraining's auc: 0.927003\tvalid_1's auc: 0.896921                                                               \n",
      "[49000]\ttraining's auc: 0.927408\tvalid_1's auc: 0.897065                                                               \n",
      "[50000]\ttraining's auc: 0.927837\tvalid_1's auc: 0.89714                                                                \n",
      "[51000]\ttraining's auc: 0.928252\tvalid_1's auc: 0.89721                                                                \n",
      "[52000]\ttraining's auc: 0.928658\tvalid_1's auc: 0.897327                                                               \n",
      "[53000]\ttraining's auc: 0.929053\tvalid_1's auc: 0.897428                                                               \n",
      "[54000]\ttraining's auc: 0.929454\tvalid_1's auc: 0.897508                                                               \n",
      "[55000]\ttraining's auc: 0.929839\tvalid_1's auc: 0.897602                                                               \n",
      "[56000]\ttraining's auc: 0.930212\tvalid_1's auc: 0.897664                                                               \n",
      "[57000]\ttraining's auc: 0.930581\tvalid_1's auc: 0.897694                                                               \n",
      "[58000]\ttraining's auc: 0.930959\tvalid_1's auc: 0.897723                                                               \n",
      "[59000]\ttraining's auc: 0.931324\tvalid_1's auc: 0.897789                                                               \n",
      "[60000]\ttraining's auc: 0.931693\tvalid_1's auc: 0.897844                                                               \n",
      "[61000]\ttraining's auc: 0.932046\tvalid_1's auc: 0.897863                                                               \n",
      "[62000]\ttraining's auc: 0.932396\tvalid_1's auc: 0.89789                                                                \n",
      "[63000]\ttraining's auc: 0.932762\tvalid_1's auc: 0.897916                                                               \n",
      "[64000]\ttraining's auc: 0.933105\tvalid_1's auc: 0.897927                                                               \n",
      "[65000]\ttraining's auc: 0.933449\tvalid_1's auc: 0.897961                                                               \n",
      "[66000]\ttraining's auc: 0.933802\tvalid_1's auc: 0.897966                                                               \n",
      "[67000]\ttraining's auc: 0.934139\tvalid_1's auc: 0.897976                                                               \n",
      "[68000]\ttraining's auc: 0.934498\tvalid_1's auc: 0.897978                                                               \n",
      "[69000]\ttraining's auc: 0.934842\tvalid_1's auc: 0.897983                                                               \n",
      "[70000]\ttraining's auc: 0.935176\tvalid_1's auc: 0.89801                                                                \n",
      "[71000]\ttraining's auc: 0.935512\tvalid_1's auc: 0.898044                                                               \n",
      "[72000]\ttraining's auc: 0.935846\tvalid_1's auc: 0.898056                                                               \n",
      "[73000]\ttraining's auc: 0.936177\tvalid_1's auc: 0.898066                                                               \n",
      "[74000]\ttraining's auc: 0.936509\tvalid_1's auc: 0.898079                                                               \n",
      "[75000]\ttraining's auc: 0.936845\tvalid_1's auc: 0.898056                                                               \n",
      "[76000]\ttraining's auc: 0.937173\tvalid_1's auc: 0.898048                                                               \n",
      "[77000]\ttraining's auc: 0.937501\tvalid_1's auc: 0.898043                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[74065]\ttraining's auc: 0.936532\tvalid_1's auc: 0.898087\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.808454\tvalid_1's auc: 0.795097                                                                \n",
      "[2000]\ttraining's auc: 0.8229\tvalid_1's auc: 0.809081                                                                  \n",
      "[3000]\ttraining's auc: 0.835965\tvalid_1's auc: 0.820856                                                                \n",
      "[4000]\ttraining's auc: 0.847991\tvalid_1's auc: 0.831488                                                                \n",
      "[5000]\ttraining's auc: 0.857445\tvalid_1's auc: 0.83991                                                                 \n",
      "[6000]\ttraining's auc: 0.865315\tvalid_1's auc: 0.846923                                                                \n",
      "[7000]\ttraining's auc: 0.871408\tvalid_1's auc: 0.852373                                                                \n",
      "[8000]\ttraining's auc: 0.876966\tvalid_1's auc: 0.85728                                                                 \n",
      "[9000]\ttraining's auc: 0.881451\tvalid_1's auc: 0.86133                                                                 \n",
      "[10000]\ttraining's auc: 0.885336\tvalid_1's auc: 0.864744                                                               \n",
      "[11000]\ttraining's auc: 0.888713\tvalid_1's auc: 0.867417                                                               \n",
      "[12000]\ttraining's auc: 0.891748\tvalid_1's auc: 0.87007                                                                \n",
      "[13000]\ttraining's auc: 0.894453\tvalid_1's auc: 0.872351                                                               \n",
      "[14000]\ttraining's auc: 0.89694\tvalid_1's auc: 0.874357                                                                \n",
      "[15000]\ttraining's auc: 0.899207\tvalid_1's auc: 0.876271                                                               \n",
      "[16000]\ttraining's auc: 0.901247\tvalid_1's auc: 0.87789                                                                \n",
      "[17000]\ttraining's auc: 0.903112\tvalid_1's auc: 0.879334                                                               \n",
      "[18000]\ttraining's auc: 0.90479\tvalid_1's auc: 0.880669                                                                \n",
      "[19000]\ttraining's auc: 0.906335\tvalid_1's auc: 0.881855                                                               \n",
      "[20000]\ttraining's auc: 0.907783\tvalid_1's auc: 0.882938                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21000]\ttraining's auc: 0.909162\tvalid_1's auc: 0.883975                                                               \n",
      "[22000]\ttraining's auc: 0.910416\tvalid_1's auc: 0.884862                                                               \n",
      "[23000]\ttraining's auc: 0.911588\tvalid_1's auc: 0.885644                                                               \n",
      "[24000]\ttraining's auc: 0.912715\tvalid_1's auc: 0.8864                                                                 \n",
      "[25000]\ttraining's auc: 0.913741\tvalid_1's auc: 0.887095                                                               \n",
      "[26000]\ttraining's auc: 0.914702\tvalid_1's auc: 0.887742                                                               \n",
      "[27000]\ttraining's auc: 0.915661\tvalid_1's auc: 0.888366                                                               \n",
      "[28000]\ttraining's auc: 0.916551\tvalid_1's auc: 0.888848                                                               \n",
      "[29000]\ttraining's auc: 0.917398\tvalid_1's auc: 0.889379                                                               \n",
      "[30000]\ttraining's auc: 0.91822\tvalid_1's auc: 0.889847                                                                \n",
      "[31000]\ttraining's auc: 0.919006\tvalid_1's auc: 0.890291                                                               \n",
      "[32000]\ttraining's auc: 0.919737\tvalid_1's auc: 0.890668                                                               \n",
      "[33000]\ttraining's auc: 0.920439\tvalid_1's auc: 0.891041                                                               \n",
      "[34000]\ttraining's auc: 0.92113\tvalid_1's auc: 0.891377                                                                \n",
      "[35000]\ttraining's auc: 0.921776\tvalid_1's auc: 0.8917                                                                 \n",
      "[36000]\ttraining's auc: 0.922375\tvalid_1's auc: 0.892052                                                               \n",
      "[37000]\ttraining's auc: 0.922996\tvalid_1's auc: 0.892297                                                               \n",
      "[38000]\ttraining's auc: 0.923559\tvalid_1's auc: 0.892522                                                               \n",
      "[39000]\ttraining's auc: 0.924094\tvalid_1's auc: 0.892732                                                               \n",
      "[40000]\ttraining's auc: 0.924627\tvalid_1's auc: 0.892947                                                               \n",
      "[41000]\ttraining's auc: 0.925147\tvalid_1's auc: 0.893163                                                               \n",
      "[42000]\ttraining's auc: 0.92564\tvalid_1's auc: 0.893365                                                                \n",
      "[43000]\ttraining's auc: 0.926143\tvalid_1's auc: 0.89359                                                                \n",
      "[44000]\ttraining's auc: 0.926607\tvalid_1's auc: 0.893767                                                               \n",
      "[45000]\ttraining's auc: 0.927078\tvalid_1's auc: 0.893895                                                               \n",
      "[46000]\ttraining's auc: 0.927532\tvalid_1's auc: 0.894035                                                               \n",
      "[47000]\ttraining's auc: 0.927972\tvalid_1's auc: 0.894171                                                               \n",
      "[48000]\ttraining's auc: 0.928406\tvalid_1's auc: 0.894292                                                               \n",
      "[49000]\ttraining's auc: 0.928838\tvalid_1's auc: 0.894393                                                               \n",
      "[50000]\ttraining's auc: 0.92925\tvalid_1's auc: 0.894533                                                                \n",
      "[51000]\ttraining's auc: 0.929665\tvalid_1's auc: 0.894602                                                               \n",
      "[52000]\ttraining's auc: 0.93008\tvalid_1's auc: 0.894694                                                                \n",
      "[53000]\ttraining's auc: 0.930488\tvalid_1's auc: 0.894765                                                               \n",
      "[54000]\ttraining's auc: 0.930875\tvalid_1's auc: 0.894849                                                               \n",
      "[55000]\ttraining's auc: 0.931266\tvalid_1's auc: 0.894881                                                               \n",
      "[56000]\ttraining's auc: 0.93165\tvalid_1's auc: 0.89491                                                                 \n",
      "[57000]\ttraining's auc: 0.932038\tvalid_1's auc: 0.894968                                                               \n",
      "[58000]\ttraining's auc: 0.932409\tvalid_1's auc: 0.89499                                                                \n",
      "[59000]\ttraining's auc: 0.932771\tvalid_1's auc: 0.895015                                                               \n",
      "[60000]\ttraining's auc: 0.933123\tvalid_1's auc: 0.895055                                                               \n",
      "[61000]\ttraining's auc: 0.933482\tvalid_1's auc: 0.895078                                                               \n",
      "[62000]\ttraining's auc: 0.933831\tvalid_1's auc: 0.895082                                                               \n",
      "[63000]\ttraining's auc: 0.934172\tvalid_1's auc: 0.895106                                                               \n",
      "[64000]\ttraining's auc: 0.934526\tvalid_1's auc: 0.895144                                                               \n",
      "[65000]\ttraining's auc: 0.934864\tvalid_1's auc: 0.895151                                                               \n",
      "[66000]\ttraining's auc: 0.935208\tvalid_1's auc: 0.895146                                                               \n",
      "[67000]\ttraining's auc: 0.935544\tvalid_1's auc: 0.895117                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[64563]\ttraining's auc: 0.934721\tvalid_1's auc: 0.895163\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.810076\tvalid_1's auc: 0.798841                                                                \n",
      "[2000]\ttraining's auc: 0.841434\tvalid_1's auc: 0.829243                                                                \n",
      "[3000]\ttraining's auc: 0.859166\tvalid_1's auc: 0.846238                                                                \n",
      "[4000]\ttraining's auc: 0.871314\tvalid_1's auc: 0.857426                                                                \n",
      "[5000]\ttraining's auc: 0.880067\tvalid_1's auc: 0.865356                                                                \n",
      "[6000]\ttraining's auc: 0.88703\tvalid_1's auc: 0.87157                                                                  \n",
      "[7000]\ttraining's auc: 0.89234\tvalid_1's auc: 0.876086                                                                 \n",
      "[8000]\ttraining's auc: 0.896808\tvalid_1's auc: 0.879842                                                                \n",
      "[9000]\ttraining's auc: 0.90036\tvalid_1's auc: 0.882934                                                                 \n",
      "[10000]\ttraining's auc: 0.903435\tvalid_1's auc: 0.885639                                                               \n",
      "[11000]\ttraining's auc: 0.905973\tvalid_1's auc: 0.887606                                                               \n",
      "[12000]\ttraining's auc: 0.908245\tvalid_1's auc: 0.889364                                                               \n",
      "[13000]\ttraining's auc: 0.910271\tvalid_1's auc: 0.890813                                                               \n",
      "[14000]\ttraining's auc: 0.912086\tvalid_1's auc: 0.892086                                                               \n",
      "[15000]\ttraining's auc: 0.913678\tvalid_1's auc: 0.893247                                                               \n",
      "[16000]\ttraining's auc: 0.915108\tvalid_1's auc: 0.894223                                                               \n",
      "[17000]\ttraining's auc: 0.916439\tvalid_1's auc: 0.895067                                                               \n",
      "[18000]\ttraining's auc: 0.917619\tvalid_1's auc: 0.895767                                                               \n",
      "[19000]\ttraining's auc: 0.918695\tvalid_1's auc: 0.896323                                                               \n",
      "[20000]\ttraining's auc: 0.919691\tvalid_1's auc: 0.896821                                                               \n",
      "[21000]\ttraining's auc: 0.920608\tvalid_1's auc: 0.897171                                                               \n",
      "[22000]\ttraining's auc: 0.921485\tvalid_1's auc: 0.89751                                                                \n",
      "[23000]\ttraining's auc: 0.922315\tvalid_1's auc: 0.897792                                                               \n",
      "[24000]\ttraining's auc: 0.923118\tvalid_1's auc: 0.897992                                                               \n",
      "[25000]\ttraining's auc: 0.923875\tvalid_1's auc: 0.898124                                                               \n",
      "[26000]\ttraining's auc: 0.924582\tvalid_1's auc: 0.898277                                                               \n",
      "[27000]\ttraining's auc: 0.925296\tvalid_1's auc: 0.898437                                                               \n",
      "[28000]\ttraining's auc: 0.925974\tvalid_1's auc: 0.89847                                                                \n",
      "[29000]\ttraining's auc: 0.926644\tvalid_1's auc: 0.898546                                                               \n",
      "[30000]\ttraining's auc: 0.927287\tvalid_1's auc: 0.898561                                                               \n",
      "[31000]\ttraining's auc: 0.927938\tvalid_1's auc: 0.898631                                                               \n",
      "[32000]\ttraining's auc: 0.92854\tvalid_1's auc: 0.898672                                                                \n",
      "[33000]\ttraining's auc: 0.929149\tvalid_1's auc: 0.898763                                                               \n",
      "[34000]\ttraining's auc: 0.929752\tvalid_1's auc: 0.898751                                                               \n",
      "[35000]\ttraining's auc: 0.93037\tvalid_1's auc: 0.898763                                                                \n",
      "[36000]\ttraining's auc: 0.930968\tvalid_1's auc: 0.898676                                                               \n",
      "[37000]\ttraining's auc: 0.931534\tvalid_1's auc: 0.898685                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34815]\ttraining's auc: 0.930263\tvalid_1's auc: 0.898773\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.809331\tvalid_1's auc: 0.787571                                                                \n",
      "[2000]\ttraining's auc: 0.843367\tvalid_1's auc: 0.821214                                                                \n",
      "[3000]\ttraining's auc: 0.861877\tvalid_1's auc: 0.838992                                                                \n",
      "[4000]\ttraining's auc: 0.874233\tvalid_1's auc: 0.850123                                                                \n",
      "[5000]\ttraining's auc: 0.883382\tvalid_1's auc: 0.858317                                                                \n",
      "[6000]\ttraining's auc: 0.890118\tvalid_1's auc: 0.864102                                                                \n",
      "[7000]\ttraining's auc: 0.895796\tvalid_1's auc: 0.868916                                                                \n",
      "[8000]\ttraining's auc: 0.900278\tvalid_1's auc: 0.872577                                                                \n",
      "[9000]\ttraining's auc: 0.903913\tvalid_1's auc: 0.87558                                                                 \n",
      "[10000]\ttraining's auc: 0.906884\tvalid_1's auc: 0.878032                                                               \n",
      "[11000]\ttraining's auc: 0.909557\tvalid_1's auc: 0.880186                                                               \n",
      "[12000]\ttraining's auc: 0.911894\tvalid_1's auc: 0.881987                                                               \n",
      "[13000]\ttraining's auc: 0.913913\tvalid_1's auc: 0.883412                                                               \n",
      "[14000]\ttraining's auc: 0.915622\tvalid_1's auc: 0.884685                                                               \n",
      "[15000]\ttraining's auc: 0.917253\tvalid_1's auc: 0.885796                                                               \n",
      "[16000]\ttraining's auc: 0.918661\tvalid_1's auc: 0.886725                                                               \n",
      "[17000]\ttraining's auc: 0.919903\tvalid_1's auc: 0.887569                                                               \n",
      "[18000]\ttraining's auc: 0.921078\tvalid_1's auc: 0.888218                                                               \n",
      "[19000]\ttraining's auc: 0.922132\tvalid_1's auc: 0.888726                                                               \n",
      "[20000]\ttraining's auc: 0.923126\tvalid_1's auc: 0.889262                                                               \n",
      "[21000]\ttraining's auc: 0.924013\tvalid_1's auc: 0.88954                                                                \n",
      "[22000]\ttraining's auc: 0.924885\tvalid_1's auc: 0.889935                                                               \n",
      "[23000]\ttraining's auc: 0.925696\tvalid_1's auc: 0.890185                                                               \n",
      "[24000]\ttraining's auc: 0.926452\tvalid_1's auc: 0.89038                                                                \n",
      "[25000]\ttraining's auc: 0.927204\tvalid_1's auc: 0.890615                                                               \n",
      "[26000]\ttraining's auc: 0.92791\tvalid_1's auc: 0.890693                                                                \n",
      "[27000]\ttraining's auc: 0.928596\tvalid_1's auc: 0.890865                                                               \n",
      "[28000]\ttraining's auc: 0.92924\tvalid_1's auc: 0.890972                                                                \n",
      "[29000]\ttraining's auc: 0.929873\tvalid_1's auc: 0.891123                                                               \n",
      "[30000]\ttraining's auc: 0.930511\tvalid_1's auc: 0.891177                                                               \n",
      "[31000]\ttraining's auc: 0.931157\tvalid_1's auc: 0.891271                                                               \n",
      "[32000]\ttraining's auc: 0.931746\tvalid_1's auc: 0.891305                                                               \n",
      "[33000]\ttraining's auc: 0.932333\tvalid_1's auc: 0.891275                                                               \n",
      "[34000]\ttraining's auc: 0.932907\tvalid_1's auc: 0.891292                                                               \n",
      "[35000]\ttraining's auc: 0.933474\tvalid_1's auc: 0.89131                                                                \n",
      "[36000]\ttraining's auc: 0.934015\tvalid_1's auc: 0.891261                                                               \n",
      "[37000]\ttraining's auc: 0.93457\tvalid_1's auc: 0.891224                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[34528]\ttraining's auc: 0.933212\tvalid_1's auc: 0.891344\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.810146\tvalid_1's auc: 0.796241                                                                \n",
      "[2000]\ttraining's auc: 0.842248\tvalid_1's auc: 0.827341                                                                \n",
      "[3000]\ttraining's auc: 0.860713\tvalid_1's auc: 0.844792                                                                \n",
      "[4000]\ttraining's auc: 0.872137\tvalid_1's auc: 0.855452                                                                \n",
      "[5000]\ttraining's auc: 0.880865\tvalid_1's auc: 0.863536                                                                \n",
      "[6000]\ttraining's auc: 0.887827\tvalid_1's auc: 0.869946                                                                \n",
      "[7000]\ttraining's auc: 0.893262\tvalid_1's auc: 0.874619                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000]\ttraining's auc: 0.8977\tvalid_1's auc: 0.87832                                                                   \n",
      "[9000]\ttraining's auc: 0.901503\tvalid_1's auc: 0.88158                                                                 \n",
      "[10000]\ttraining's auc: 0.904475\tvalid_1's auc: 0.884202                                                               \n",
      "[11000]\ttraining's auc: 0.907196\tvalid_1's auc: 0.886542                                                               \n",
      "[12000]\ttraining's auc: 0.909432\tvalid_1's auc: 0.888251                                                               \n",
      "[13000]\ttraining's auc: 0.911409\tvalid_1's auc: 0.889707                                                               \n",
      "[14000]\ttraining's auc: 0.913141\tvalid_1's auc: 0.891099                                                               \n",
      "[15000]\ttraining's auc: 0.914732\tvalid_1's auc: 0.892277                                                               \n",
      "[16000]\ttraining's auc: 0.916157\tvalid_1's auc: 0.893277                                                               \n",
      "[17000]\ttraining's auc: 0.917383\tvalid_1's auc: 0.89415                                                                \n",
      "[18000]\ttraining's auc: 0.918543\tvalid_1's auc: 0.894882                                                               \n",
      "[19000]\ttraining's auc: 0.919598\tvalid_1's auc: 0.895467                                                               \n",
      "[20000]\ttraining's auc: 0.920604\tvalid_1's auc: 0.896122                                                               \n",
      "[21000]\ttraining's auc: 0.921501\tvalid_1's auc: 0.896547                                                               \n",
      "[22000]\ttraining's auc: 0.922404\tvalid_1's auc: 0.897023                                                               \n",
      "[23000]\ttraining's auc: 0.923202\tvalid_1's auc: 0.897421                                                               \n",
      "[24000]\ttraining's auc: 0.923998\tvalid_1's auc: 0.897767                                                               \n",
      "[25000]\ttraining's auc: 0.924728\tvalid_1's auc: 0.898051                                                               \n",
      "[26000]\ttraining's auc: 0.925461\tvalid_1's auc: 0.898407                                                               \n",
      "[27000]\ttraining's auc: 0.926158\tvalid_1's auc: 0.898599                                                               \n",
      "[28000]\ttraining's auc: 0.926832\tvalid_1's auc: 0.898799                                                               \n",
      "[29000]\ttraining's auc: 0.927477\tvalid_1's auc: 0.89896                                                                \n",
      "[30000]\ttraining's auc: 0.92813\tvalid_1's auc: 0.899103                                                                \n",
      "[31000]\ttraining's auc: 0.928772\tvalid_1's auc: 0.899217                                                               \n",
      "[32000]\ttraining's auc: 0.929403\tvalid_1's auc: 0.899297                                                               \n",
      "[33000]\ttraining's auc: 0.930012\tvalid_1's auc: 0.899338                                                               \n",
      "[34000]\ttraining's auc: 0.9306\tvalid_1's auc: 0.899407                                                                 \n",
      "[35000]\ttraining's auc: 0.931176\tvalid_1's auc: 0.899462                                                               \n",
      "[36000]\ttraining's auc: 0.931772\tvalid_1's auc: 0.899402                                                               \n",
      "[37000]\ttraining's auc: 0.932345\tvalid_1's auc: 0.899451                                                               \n",
      "[38000]\ttraining's auc: 0.932923\tvalid_1's auc: 0.8995                                                                 \n",
      "[39000]\ttraining's auc: 0.933483\tvalid_1's auc: 0.899527                                                               \n",
      "[40000]\ttraining's auc: 0.934037\tvalid_1's auc: 0.899532                                                               \n",
      "[41000]\ttraining's auc: 0.934582\tvalid_1's auc: 0.899549                                                               \n",
      "[42000]\ttraining's auc: 0.935118\tvalid_1's auc: 0.899593                                                               \n",
      "[43000]\ttraining's auc: 0.935673\tvalid_1's auc: 0.899575                                                               \n",
      "[44000]\ttraining's auc: 0.936202\tvalid_1's auc: 0.899475                                                               \n",
      "[45000]\ttraining's auc: 0.936737\tvalid_1's auc: 0.899441                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42289]\ttraining's auc: 0.935277\tvalid_1's auc: 0.899604\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.808035\tvalid_1's auc: 0.795425                                                                \n",
      "[2000]\ttraining's auc: 0.843326\tvalid_1's auc: 0.827593                                                                \n",
      "[3000]\ttraining's auc: 0.861854\tvalid_1's auc: 0.844054                                                                \n",
      "[4000]\ttraining's auc: 0.873772\tvalid_1's auc: 0.854819                                                                \n",
      "[5000]\ttraining's auc: 0.88274\tvalid_1's auc: 0.863178                                                                 \n",
      "[6000]\ttraining's auc: 0.88948\tvalid_1's auc: 0.868812                                                                 \n",
      "[7000]\ttraining's auc: 0.894666\tvalid_1's auc: 0.873089                                                                \n",
      "[8000]\ttraining's auc: 0.898807\tvalid_1's auc: 0.876611                                                                \n",
      "[9000]\ttraining's auc: 0.902263\tvalid_1's auc: 0.879351                                                                \n",
      "[10000]\ttraining's auc: 0.905279\tvalid_1's auc: 0.881883                                                               \n",
      "[11000]\ttraining's auc: 0.90805\tvalid_1's auc: 0.884014                                                                \n",
      "[12000]\ttraining's auc: 0.910361\tvalid_1's auc: 0.885861                                                               \n",
      "[13000]\ttraining's auc: 0.912424\tvalid_1's auc: 0.887316                                                               \n",
      "[14000]\ttraining's auc: 0.914271\tvalid_1's auc: 0.888614                                                               \n",
      "[15000]\ttraining's auc: 0.915885\tvalid_1's auc: 0.889719                                                               \n",
      "[16000]\ttraining's auc: 0.917395\tvalid_1's auc: 0.890647                                                               \n",
      "[17000]\ttraining's auc: 0.918727\tvalid_1's auc: 0.891502                                                               \n",
      "[18000]\ttraining's auc: 0.919899\tvalid_1's auc: 0.892151                                                               \n",
      "[19000]\ttraining's auc: 0.921013\tvalid_1's auc: 0.892761                                                               \n",
      "[20000]\ttraining's auc: 0.922042\tvalid_1's auc: 0.893305                                                               \n",
      "[21000]\ttraining's auc: 0.92299\tvalid_1's auc: 0.893773                                                                \n",
      "[22000]\ttraining's auc: 0.923877\tvalid_1's auc: 0.894173                                                               \n",
      "[23000]\ttraining's auc: 0.924686\tvalid_1's auc: 0.894472                                                               \n",
      "[24000]\ttraining's auc: 0.925491\tvalid_1's auc: 0.894812                                                               \n",
      "[25000]\ttraining's auc: 0.926234\tvalid_1's auc: 0.894995                                                               \n",
      "[26000]\ttraining's auc: 0.926946\tvalid_1's auc: 0.895187                                                               \n",
      "[27000]\ttraining's auc: 0.927662\tvalid_1's auc: 0.895403                                                               \n",
      "[28000]\ttraining's auc: 0.928336\tvalid_1's auc: 0.895572                                                               \n",
      "[29000]\ttraining's auc: 0.92898\tvalid_1's auc: 0.895707                                                                \n",
      "[30000]\ttraining's auc: 0.929623\tvalid_1's auc: 0.895788                                                               \n",
      "[31000]\ttraining's auc: 0.930257\tvalid_1's auc: 0.895939                                                               \n",
      "[32000]\ttraining's auc: 0.930863\tvalid_1's auc: 0.895965                                                               \n",
      "[33000]\ttraining's auc: 0.931438\tvalid_1's auc: 0.895985                                                               \n",
      "[34000]\ttraining's auc: 0.932039\tvalid_1's auc: 0.896021                                                               \n",
      "[35000]\ttraining's auc: 0.93262\tvalid_1's auc: 0.896059                                                                \n",
      "[36000]\ttraining's auc: 0.933189\tvalid_1's auc: 0.896089                                                               \n",
      "[37000]\ttraining's auc: 0.933735\tvalid_1's auc: 0.896123                                                               \n",
      "[38000]\ttraining's auc: 0.93429\tvalid_1's auc: 0.896162                                                                \n",
      "[39000]\ttraining's auc: 0.934827\tvalid_1's auc: 0.896158                                                               \n",
      "[40000]\ttraining's auc: 0.935352\tvalid_1's auc: 0.896116                                                               \n",
      "[41000]\ttraining's auc: 0.935883\tvalid_1's auc: 0.896091                                                               \n",
      "[42000]\ttraining's auc: 0.936416\tvalid_1's auc: 0.896076                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[39242]\ttraining's auc: 0.934954\tvalid_1's auc: 0.896179\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.827461\tvalid_1's auc: 0.816027                                                                \n",
      "[2000]\ttraining's auc: 0.848138\tvalid_1's auc: 0.836315                                                                \n",
      "[3000]\ttraining's auc: 0.864359\tvalid_1's auc: 0.851272                                                                \n",
      "[4000]\ttraining's auc: 0.875861\tvalid_1's auc: 0.861684                                                                \n",
      "[5000]\ttraining's auc: 0.884258\tvalid_1's auc: 0.869108                                                                \n",
      "[6000]\ttraining's auc: 0.890564\tvalid_1's auc: 0.874831                                                                \n",
      "[7000]\ttraining's auc: 0.895799\tvalid_1's auc: 0.879328                                                                \n",
      "[8000]\ttraining's auc: 0.899844\tvalid_1's auc: 0.882441                                                                \n",
      "[9000]\ttraining's auc: 0.903268\tvalid_1's auc: 0.885163                                                                \n",
      "[10000]\ttraining's auc: 0.906192\tvalid_1's auc: 0.887416                                                               \n",
      "[11000]\ttraining's auc: 0.908666\tvalid_1's auc: 0.889155                                                               \n",
      "[12000]\ttraining's auc: 0.91077\tvalid_1's auc: 0.890666                                                                \n",
      "[13000]\ttraining's auc: 0.912723\tvalid_1's auc: 0.89202                                                                \n",
      "[14000]\ttraining's auc: 0.914437\tvalid_1's auc: 0.893137                                                               \n",
      "[15000]\ttraining's auc: 0.91599\tvalid_1's auc: 0.893835                                                                \n",
      "[16000]\ttraining's auc: 0.917389\tvalid_1's auc: 0.894675                                                               \n",
      "[17000]\ttraining's auc: 0.918714\tvalid_1's auc: 0.895228                                                               \n",
      "[18000]\ttraining's auc: 0.919883\tvalid_1's auc: 0.895725                                                               \n",
      "[19000]\ttraining's auc: 0.920962\tvalid_1's auc: 0.896157                                                               \n",
      "[20000]\ttraining's auc: 0.921972\tvalid_1's auc: 0.896467                                                               \n",
      "[21000]\ttraining's auc: 0.922942\tvalid_1's auc: 0.896765                                                               \n",
      "[22000]\ttraining's auc: 0.923875\tvalid_1's auc: 0.896945                                                               \n",
      "[23000]\ttraining's auc: 0.924766\tvalid_1's auc: 0.897102                                                               \n",
      "[24000]\ttraining's auc: 0.92565\tvalid_1's auc: 0.897227                                                                \n",
      "[25000]\ttraining's auc: 0.926478\tvalid_1's auc: 0.897363                                                               \n",
      "[26000]\ttraining's auc: 0.927275\tvalid_1's auc: 0.897386                                                               \n",
      "[27000]\ttraining's auc: 0.928087\tvalid_1's auc: 0.897462                                                               \n",
      "[28000]\ttraining's auc: 0.92885\tvalid_1's auc: 0.897412                                                                \n",
      "[29000]\ttraining's auc: 0.929606\tvalid_1's auc: 0.897364                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26975]\ttraining's auc: 0.928064\tvalid_1's auc: 0.897468\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.827835\tvalid_1's auc: 0.808914                                                                \n",
      "[2000]\ttraining's auc: 0.850834\tvalid_1's auc: 0.830613                                                                \n",
      "[3000]\ttraining's auc: 0.866387\tvalid_1's auc: 0.844974                                                                \n",
      "[4000]\ttraining's auc: 0.878568\tvalid_1's auc: 0.855816                                                                \n",
      "[5000]\ttraining's auc: 0.887096\tvalid_1's auc: 0.863043                                                                \n",
      "[6000]\ttraining's auc: 0.893914\tvalid_1's auc: 0.868688                                                                \n",
      "[7000]\ttraining's auc: 0.899054\tvalid_1's auc: 0.87312                                                                 \n",
      "[8000]\ttraining's auc: 0.903241\tvalid_1's auc: 0.876434                                                                \n",
      "[9000]\ttraining's auc: 0.906684\tvalid_1's auc: 0.879127                                                                \n",
      "[10000]\ttraining's auc: 0.909632\tvalid_1's auc: 0.881374                                                               \n",
      "[11000]\ttraining's auc: 0.912004\tvalid_1's auc: 0.883128                                                               \n",
      "[12000]\ttraining's auc: 0.914301\tvalid_1's auc: 0.884521                                                               \n",
      "[13000]\ttraining's auc: 0.916162\tvalid_1's auc: 0.885656                                                               \n",
      "[14000]\ttraining's auc: 0.917943\tvalid_1's auc: 0.886786                                                               \n",
      "[15000]\ttraining's auc: 0.91946\tvalid_1's auc: 0.887555                                                                \n",
      "[16000]\ttraining's auc: 0.920884\tvalid_1's auc: 0.888249                                                               \n",
      "[17000]\ttraining's auc: 0.922117\tvalid_1's auc: 0.888805                                                               \n",
      "[18000]\ttraining's auc: 0.923255\tvalid_1's auc: 0.889231                                                               \n",
      "[19000]\ttraining's auc: 0.924301\tvalid_1's auc: 0.889571                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20000]\ttraining's auc: 0.925294\tvalid_1's auc: 0.889917                                                               \n",
      "[21000]\ttraining's auc: 0.926231\tvalid_1's auc: 0.890138                                                               \n",
      "[22000]\ttraining's auc: 0.927156\tvalid_1's auc: 0.890233                                                               \n",
      "[23000]\ttraining's auc: 0.928023\tvalid_1's auc: 0.890363                                                               \n",
      "[24000]\ttraining's auc: 0.928829\tvalid_1's auc: 0.890575                                                               \n",
      "[25000]\ttraining's auc: 0.92961\tvalid_1's auc: 0.890643                                                                \n",
      "[26000]\ttraining's auc: 0.930364\tvalid_1's auc: 0.890728                                                               \n",
      "[27000]\ttraining's auc: 0.931098\tvalid_1's auc: 0.89078                                                                \n",
      "[28000]\ttraining's auc: 0.931799\tvalid_1's auc: 0.890769                                                               \n",
      "[29000]\ttraining's auc: 0.932489\tvalid_1's auc: 0.890713                                                               \n",
      "[30000]\ttraining's auc: 0.933181\tvalid_1's auc: 0.890731                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[27385]\ttraining's auc: 0.931384\tvalid_1's auc: 0.890819\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.826251\tvalid_1's auc: 0.811991                                                                \n",
      "[2000]\ttraining's auc: 0.84878\tvalid_1's auc: 0.83409                                                                  \n",
      "[3000]\ttraining's auc: 0.865019\tvalid_1's auc: 0.849222                                                                \n",
      "[4000]\ttraining's auc: 0.876379\tvalid_1's auc: 0.859549                                                                \n",
      "[5000]\ttraining's auc: 0.884764\tvalid_1's auc: 0.867343                                                                \n",
      "[6000]\ttraining's auc: 0.891518\tvalid_1's auc: 0.87339                                                                 \n",
      "[7000]\ttraining's auc: 0.896808\tvalid_1's auc: 0.877859                                                                \n",
      "[8000]\ttraining's auc: 0.900953\tvalid_1's auc: 0.881385                                                                \n",
      "[9000]\ttraining's auc: 0.90421\tvalid_1's auc: 0.88411                                                                  \n",
      "[10000]\ttraining's auc: 0.907138\tvalid_1's auc: 0.886395                                                               \n",
      "[11000]\ttraining's auc: 0.90967\tvalid_1's auc: 0.888268                                                                \n",
      "[12000]\ttraining's auc: 0.911888\tvalid_1's auc: 0.889876                                                               \n",
      "[13000]\ttraining's auc: 0.913729\tvalid_1's auc: 0.891199                                                               \n",
      "[14000]\ttraining's auc: 0.91538\tvalid_1's auc: 0.89234                                                                 \n",
      "[15000]\ttraining's auc: 0.916895\tvalid_1's auc: 0.893158                                                               \n",
      "[16000]\ttraining's auc: 0.918216\tvalid_1's auc: 0.893978                                                               \n",
      "[17000]\ttraining's auc: 0.919413\tvalid_1's auc: 0.894677                                                               \n",
      "[18000]\ttraining's auc: 0.920603\tvalid_1's auc: 0.895189                                                               \n",
      "[19000]\ttraining's auc: 0.921668\tvalid_1's auc: 0.895597                                                               \n",
      "[20000]\ttraining's auc: 0.922676\tvalid_1's auc: 0.896016                                                               \n",
      "[21000]\ttraining's auc: 0.923654\tvalid_1's auc: 0.896337                                                               \n",
      "[22000]\ttraining's auc: 0.924547\tvalid_1's auc: 0.896675                                                               \n",
      "[23000]\ttraining's auc: 0.92543\tvalid_1's auc: 0.897008                                                                \n",
      "[24000]\ttraining's auc: 0.926272\tvalid_1's auc: 0.897229                                                               \n",
      "[25000]\ttraining's auc: 0.927081\tvalid_1's auc: 0.89741                                                                \n",
      "[26000]\ttraining's auc: 0.927888\tvalid_1's auc: 0.897542                                                               \n",
      "[27000]\ttraining's auc: 0.928717\tvalid_1's auc: 0.897731                                                               \n",
      "[28000]\ttraining's auc: 0.929462\tvalid_1's auc: 0.897817                                                               \n",
      "[29000]\ttraining's auc: 0.9302\tvalid_1's auc: 0.897821                                                                 \n",
      "[30000]\ttraining's auc: 0.930935\tvalid_1's auc: 0.897867                                                               \n",
      "[31000]\ttraining's auc: 0.931662\tvalid_1's auc: 0.897879                                                               \n",
      "[32000]\ttraining's auc: 0.932351\tvalid_1's auc: 0.89788                                                                \n",
      "[33000]\ttraining's auc: 0.933042\tvalid_1's auc: 0.89795                                                                \n",
      "[34000]\ttraining's auc: 0.933708\tvalid_1's auc: 0.897975                                                               \n",
      "[35000]\ttraining's auc: 0.934387\tvalid_1's auc: 0.897933                                                               \n",
      "[36000]\ttraining's auc: 0.935051\tvalid_1's auc: 0.897999                                                               \n",
      "[37000]\ttraining's auc: 0.935714\tvalid_1's auc: 0.897941                                                               \n",
      "[38000]\ttraining's auc: 0.936357\tvalid_1's auc: 0.897934                                                               \n",
      "[39000]\ttraining's auc: 0.937008\tvalid_1's auc: 0.897976                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[36192]\ttraining's auc: 0.935179\tvalid_1's auc: 0.898018\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.827497\tvalid_1's auc: 0.81362                                                                 \n",
      "[2000]\ttraining's auc: 0.850564\tvalid_1's auc: 0.834255                                                                \n",
      "[3000]\ttraining's auc: 0.866547\tvalid_1's auc: 0.848918                                                                \n",
      "[4000]\ttraining's auc: 0.878118\tvalid_1's auc: 0.859539                                                                \n",
      "[5000]\ttraining's auc: 0.886047\tvalid_1's auc: 0.866427                                                                \n",
      "[6000]\ttraining's auc: 0.892282\tvalid_1's auc: 0.871622                                                                \n",
      "[7000]\ttraining's auc: 0.89719\tvalid_1's auc: 0.875807                                                                 \n",
      "[8000]\ttraining's auc: 0.901341\tvalid_1's auc: 0.879036                                                                \n",
      "[9000]\ttraining's auc: 0.904804\tvalid_1's auc: 0.88176                                                                 \n",
      "[10000]\ttraining's auc: 0.90774\tvalid_1's auc: 0.884123                                                                \n",
      "[11000]\ttraining's auc: 0.91034\tvalid_1's auc: 0.885876                                                                \n",
      "[12000]\ttraining's auc: 0.912563\tvalid_1's auc: 0.887469                                                               \n",
      "[13000]\ttraining's auc: 0.914494\tvalid_1's auc: 0.888734                                                               \n",
      "[14000]\ttraining's auc: 0.916281\tvalid_1's auc: 0.889884                                                               \n",
      "[15000]\ttraining's auc: 0.917863\tvalid_1's auc: 0.890935                                                               \n",
      "[16000]\ttraining's auc: 0.919275\tvalid_1's auc: 0.891685                                                               \n",
      "[17000]\ttraining's auc: 0.920613\tvalid_1's auc: 0.892233                                                               \n",
      "[18000]\ttraining's auc: 0.921755\tvalid_1's auc: 0.892806                                                               \n",
      "[19000]\ttraining's auc: 0.922867\tvalid_1's auc: 0.893338                                                               \n",
      "[20000]\ttraining's auc: 0.923937\tvalid_1's auc: 0.893746                                                               \n",
      "[21000]\ttraining's auc: 0.924929\tvalid_1's auc: 0.894018                                                               \n",
      "[22000]\ttraining's auc: 0.925863\tvalid_1's auc: 0.894376                                                               \n",
      "[23000]\ttraining's auc: 0.926725\tvalid_1's auc: 0.894635                                                               \n",
      "[24000]\ttraining's auc: 0.927583\tvalid_1's auc: 0.894794                                                               \n",
      "[25000]\ttraining's auc: 0.928394\tvalid_1's auc: 0.894831                                                               \n",
      "[26000]\ttraining's auc: 0.929183\tvalid_1's auc: 0.89496                                                                \n",
      "[27000]\ttraining's auc: 0.929936\tvalid_1's auc: 0.895057                                                               \n",
      "[28000]\ttraining's auc: 0.930712\tvalid_1's auc: 0.895137                                                               \n",
      "[29000]\ttraining's auc: 0.931443\tvalid_1's auc: 0.895173                                                               \n",
      "[30000]\ttraining's auc: 0.932181\tvalid_1's auc: 0.895173                                                               \n",
      "[31000]\ttraining's auc: 0.93286\tvalid_1's auc: 0.895163                                                                \n",
      "[32000]\ttraining's auc: 0.933535\tvalid_1's auc: 0.895199                                                               \n",
      "[33000]\ttraining's auc: 0.934216\tvalid_1's auc: 0.895118                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[30738]\ttraining's auc: 0.932672\tvalid_1's auc: 0.895213\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.800783\tvalid_1's auc: 0.791714                                                                \n",
      "[2000]\ttraining's auc: 0.821351\tvalid_1's auc: 0.811562                                                                \n",
      "[3000]\ttraining's auc: 0.838142\tvalid_1's auc: 0.827481                                                                \n",
      "[4000]\ttraining's auc: 0.850813\tvalid_1's auc: 0.839739                                                                \n",
      "[5000]\ttraining's auc: 0.859792\tvalid_1's auc: 0.84828                                                                 \n",
      "[6000]\ttraining's auc: 0.867291\tvalid_1's auc: 0.855205                                                                \n",
      "[7000]\ttraining's auc: 0.873414\tvalid_1's auc: 0.860914                                                                \n",
      "[8000]\ttraining's auc: 0.878606\tvalid_1's auc: 0.865772                                                                \n",
      "[9000]\ttraining's auc: 0.882937\tvalid_1's auc: 0.869621                                                                \n",
      "[10000]\ttraining's auc: 0.886683\tvalid_1's auc: 0.872842                                                               \n",
      "[11000]\ttraining's auc: 0.889717\tvalid_1's auc: 0.875519                                                               \n",
      "[12000]\ttraining's auc: 0.89273\tvalid_1's auc: 0.878127                                                                \n",
      "[13000]\ttraining's auc: 0.89525\tvalid_1's auc: 0.880333                                                                \n",
      "[14000]\ttraining's auc: 0.897613\tvalid_1's auc: 0.882303                                                               \n",
      "[15000]\ttraining's auc: 0.899581\tvalid_1's auc: 0.88391                                                                \n",
      "[16000]\ttraining's auc: 0.901528\tvalid_1's auc: 0.885464                                                               \n",
      "[17000]\ttraining's auc: 0.903173\tvalid_1's auc: 0.886821                                                               \n",
      "[18000]\ttraining's auc: 0.904642\tvalid_1's auc: 0.888022                                                               \n",
      "[19000]\ttraining's auc: 0.906099\tvalid_1's auc: 0.889229                                                               \n",
      "[20000]\ttraining's auc: 0.907359\tvalid_1's auc: 0.890174                                                               \n",
      "[21000]\ttraining's auc: 0.908505\tvalid_1's auc: 0.891015                                                               \n",
      "[22000]\ttraining's auc: 0.909616\tvalid_1's auc: 0.891876                                                               \n",
      "[23000]\ttraining's auc: 0.910657\tvalid_1's auc: 0.892605                                                               \n",
      "[24000]\ttraining's auc: 0.911629\tvalid_1's auc: 0.893268                                                               \n",
      "[25000]\ttraining's auc: 0.91255\tvalid_1's auc: 0.893892                                                                \n",
      "[26000]\ttraining's auc: 0.91336\tvalid_1's auc: 0.894364                                                                \n",
      "[27000]\ttraining's auc: 0.914173\tvalid_1's auc: 0.894844                                                               \n",
      "[28000]\ttraining's auc: 0.914944\tvalid_1's auc: 0.895337                                                               \n",
      "[29000]\ttraining's auc: 0.915655\tvalid_1's auc: 0.895767                                                               \n",
      "[30000]\ttraining's auc: 0.91637\tvalid_1's auc: 0.896178                                                                \n",
      "[31000]\ttraining's auc: 0.916991\tvalid_1's auc: 0.896557                                                               \n",
      "[32000]\ttraining's auc: 0.917602\tvalid_1's auc: 0.896894                                                               \n",
      "[33000]\ttraining's auc: 0.918207\tvalid_1's auc: 0.897126                                                               \n",
      "[34000]\ttraining's auc: 0.918765\tvalid_1's auc: 0.897418                                                               \n",
      "[35000]\ttraining's auc: 0.919302\tvalid_1's auc: 0.897678                                                               \n",
      "[36000]\ttraining's auc: 0.919813\tvalid_1's auc: 0.897869                                                               \n",
      "[37000]\ttraining's auc: 0.92031\tvalid_1's auc: 0.898066                                                                \n",
      "[38000]\ttraining's auc: 0.920786\tvalid_1's auc: 0.898241                                                               \n",
      "[39000]\ttraining's auc: 0.921253\tvalid_1's auc: 0.898408                                                               \n",
      "[40000]\ttraining's auc: 0.92171\tvalid_1's auc: 0.89853                                                                 \n",
      "[41000]\ttraining's auc: 0.922135\tvalid_1's auc: 0.898582                                                               \n",
      "[42000]\ttraining's auc: 0.922581\tvalid_1's auc: 0.898672                                                               \n",
      "[43000]\ttraining's auc: 0.922996\tvalid_1's auc: 0.898789                                                               \n",
      "[44000]\ttraining's auc: 0.923422\tvalid_1's auc: 0.898836                                                               \n",
      "[45000]\ttraining's auc: 0.923815\tvalid_1's auc: 0.898871                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46000]\ttraining's auc: 0.924206\tvalid_1's auc: 0.898895                                                               \n",
      "[47000]\ttraining's auc: 0.924583\tvalid_1's auc: 0.898937                                                               \n",
      "[48000]\ttraining's auc: 0.924933\tvalid_1's auc: 0.898981                                                               \n",
      "[49000]\ttraining's auc: 0.925299\tvalid_1's auc: 0.899048                                                               \n",
      "[50000]\ttraining's auc: 0.925675\tvalid_1's auc: 0.899084                                                               \n",
      "[51000]\ttraining's auc: 0.926008\tvalid_1's auc: 0.899076                                                               \n",
      "[52000]\ttraining's auc: 0.926384\tvalid_1's auc: 0.899082                                                               \n",
      "[53000]\ttraining's auc: 0.926751\tvalid_1's auc: 0.899128                                                               \n",
      "[54000]\ttraining's auc: 0.927101\tvalid_1's auc: 0.899126                                                               \n",
      "[55000]\ttraining's auc: 0.927446\tvalid_1's auc: 0.899092                                                               \n",
      "[56000]\ttraining's auc: 0.927779\tvalid_1's auc: 0.899049                                                               \n",
      "[57000]\ttraining's auc: 0.928116\tvalid_1's auc: 0.899003                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54132]\ttraining's auc: 0.927139\tvalid_1's auc: 0.899135\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.801753\tvalid_1's auc: 0.780097                                                                \n",
      "[2000]\ttraining's auc: 0.822981\tvalid_1's auc: 0.802331                                                                \n",
      "[3000]\ttraining's auc: 0.84018\tvalid_1's auc: 0.819605                                                                 \n",
      "[4000]\ttraining's auc: 0.852764\tvalid_1's auc: 0.83196                                                                 \n",
      "[5000]\ttraining's auc: 0.862092\tvalid_1's auc: 0.840887                                                                \n",
      "[6000]\ttraining's auc: 0.869689\tvalid_1's auc: 0.847497                                                                \n",
      "[7000]\ttraining's auc: 0.876034\tvalid_1's auc: 0.853339                                                                \n",
      "[8000]\ttraining's auc: 0.881278\tvalid_1's auc: 0.858071                                                                \n",
      "[9000]\ttraining's auc: 0.885852\tvalid_1's auc: 0.861981                                                                \n",
      "[10000]\ttraining's auc: 0.889913\tvalid_1's auc: 0.865525                                                               \n",
      "[11000]\ttraining's auc: 0.893321\tvalid_1's auc: 0.86859                                                                \n",
      "[12000]\ttraining's auc: 0.896271\tvalid_1's auc: 0.871034                                                               \n",
      "[13000]\ttraining's auc: 0.89883\tvalid_1's auc: 0.873326                                                                \n",
      "[14000]\ttraining's auc: 0.901207\tvalid_1's auc: 0.875254                                                               \n",
      "[15000]\ttraining's auc: 0.903223\tvalid_1's auc: 0.876923                                                               \n",
      "[16000]\ttraining's auc: 0.905156\tvalid_1's auc: 0.878448                                                               \n",
      "[17000]\ttraining's auc: 0.9068\tvalid_1's auc: 0.879718                                                                 \n",
      "[18000]\ttraining's auc: 0.908354\tvalid_1's auc: 0.880869                                                               \n",
      "[19000]\ttraining's auc: 0.909763\tvalid_1's auc: 0.881934                                                               \n",
      "[20000]\ttraining's auc: 0.911038\tvalid_1's auc: 0.882938                                                               \n",
      "[21000]\ttraining's auc: 0.912224\tvalid_1's auc: 0.883861                                                               \n",
      "[22000]\ttraining's auc: 0.913295\tvalid_1's auc: 0.884619                                                               \n",
      "[23000]\ttraining's auc: 0.914317\tvalid_1's auc: 0.88543                                                                \n",
      "[24000]\ttraining's auc: 0.915279\tvalid_1's auc: 0.886079                                                               \n",
      "[25000]\ttraining's auc: 0.916236\tvalid_1's auc: 0.886648                                                               \n",
      "[26000]\ttraining's auc: 0.917039\tvalid_1's auc: 0.887186                                                               \n",
      "[27000]\ttraining's auc: 0.917796\tvalid_1's auc: 0.887652                                                               \n",
      "[28000]\ttraining's auc: 0.918531\tvalid_1's auc: 0.888153                                                               \n",
      "[29000]\ttraining's auc: 0.919224\tvalid_1's auc: 0.888557                                                               \n",
      "[30000]\ttraining's auc: 0.919906\tvalid_1's auc: 0.888877                                                               \n",
      "[31000]\ttraining's auc: 0.920517\tvalid_1's auc: 0.889223                                                               \n",
      "[32000]\ttraining's auc: 0.921103\tvalid_1's auc: 0.889578                                                               \n",
      "[33000]\ttraining's auc: 0.921662\tvalid_1's auc: 0.88981                                                                \n",
      "[34000]\ttraining's auc: 0.922237\tvalid_1's auc: 0.890068                                                               \n",
      "[35000]\ttraining's auc: 0.92277\tvalid_1's auc: 0.890251                                                                \n",
      "[36000]\ttraining's auc: 0.923271\tvalid_1's auc: 0.890383                                                               \n",
      "[37000]\ttraining's auc: 0.923745\tvalid_1's auc: 0.890599                                                               \n",
      "[38000]\ttraining's auc: 0.924209\tvalid_1's auc: 0.890769                                                               \n",
      "[39000]\ttraining's auc: 0.924637\tvalid_1's auc: 0.890951                                                               \n",
      "[40000]\ttraining's auc: 0.925079\tvalid_1's auc: 0.891066                                                               \n",
      "[41000]\ttraining's auc: 0.925506\tvalid_1's auc: 0.891148                                                               \n",
      "[42000]\ttraining's auc: 0.925926\tvalid_1's auc: 0.891236                                                               \n",
      "[43000]\ttraining's auc: 0.926335\tvalid_1's auc: 0.891325                                                               \n",
      "[44000]\ttraining's auc: 0.926728\tvalid_1's auc: 0.89139                                                                \n",
      "[45000]\ttraining's auc: 0.92712\tvalid_1's auc: 0.891431                                                                \n",
      "[46000]\ttraining's auc: 0.927502\tvalid_1's auc: 0.89149                                                                \n",
      "[47000]\ttraining's auc: 0.927845\tvalid_1's auc: 0.89154                                                                \n",
      "[48000]\ttraining's auc: 0.928195\tvalid_1's auc: 0.89162                                                                \n",
      "[49000]\ttraining's auc: 0.928583\tvalid_1's auc: 0.891659                                                               \n",
      "[50000]\ttraining's auc: 0.928947\tvalid_1's auc: 0.891681                                                               \n",
      "[51000]\ttraining's auc: 0.929289\tvalid_1's auc: 0.891695                                                               \n",
      "[52000]\ttraining's auc: 0.929635\tvalid_1's auc: 0.891688                                                               \n",
      "[53000]\ttraining's auc: 0.930003\tvalid_1's auc: 0.891658                                                               \n",
      "[54000]\ttraining's auc: 0.930346\tvalid_1's auc: 0.891682                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51199]\ttraining's auc: 0.929359\tvalid_1's auc: 0.891707\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.800071\tvalid_1's auc: 0.788433                                                                \n",
      "[2000]\ttraining's auc: 0.822467\tvalid_1's auc: 0.809064                                                                \n",
      "[3000]\ttraining's auc: 0.839072\tvalid_1's auc: 0.824763                                                                \n",
      "[4000]\ttraining's auc: 0.851663\tvalid_1's auc: 0.837001                                                                \n",
      "[5000]\ttraining's auc: 0.860878\tvalid_1's auc: 0.845634                                                                \n",
      "[6000]\ttraining's auc: 0.868241\tvalid_1's auc: 0.852704                                                                \n",
      "[7000]\ttraining's auc: 0.874199\tvalid_1's auc: 0.858331                                                                \n",
      "[8000]\ttraining's auc: 0.879268\tvalid_1's auc: 0.86322                                                                 \n",
      "[9000]\ttraining's auc: 0.883792\tvalid_1's auc: 0.867485                                                                \n",
      "[10000]\ttraining's auc: 0.887547\tvalid_1's auc: 0.870788                                                               \n",
      "[11000]\ttraining's auc: 0.890946\tvalid_1's auc: 0.874032                                                               \n",
      "[12000]\ttraining's auc: 0.893939\tvalid_1's auc: 0.876719                                                               \n",
      "[13000]\ttraining's auc: 0.896478\tvalid_1's auc: 0.878928                                                               \n",
      "[14000]\ttraining's auc: 0.898716\tvalid_1's auc: 0.880888                                                               \n",
      "[15000]\ttraining's auc: 0.900828\tvalid_1's auc: 0.882806                                                               \n",
      "[16000]\ttraining's auc: 0.90275\tvalid_1's auc: 0.884519                                                                \n",
      "[17000]\ttraining's auc: 0.904409\tvalid_1's auc: 0.885911                                                               \n",
      "[18000]\ttraining's auc: 0.905917\tvalid_1's auc: 0.88714                                                                \n",
      "[19000]\ttraining's auc: 0.907262\tvalid_1's auc: 0.88829                                                                \n",
      "[20000]\ttraining's auc: 0.908566\tvalid_1's auc: 0.889338                                                               \n",
      "[21000]\ttraining's auc: 0.909697\tvalid_1's auc: 0.890217                                                               \n",
      "[22000]\ttraining's auc: 0.910753\tvalid_1's auc: 0.891046                                                               \n",
      "[23000]\ttraining's auc: 0.91176\tvalid_1's auc: 0.891896                                                                \n",
      "[24000]\ttraining's auc: 0.912693\tvalid_1's auc: 0.892663                                                               \n",
      "[25000]\ttraining's auc: 0.913555\tvalid_1's auc: 0.893288                                                               \n",
      "[26000]\ttraining's auc: 0.914394\tvalid_1's auc: 0.89388                                                                \n",
      "[27000]\ttraining's auc: 0.91517\tvalid_1's auc: 0.89438                                                                 \n",
      "[28000]\ttraining's auc: 0.915884\tvalid_1's auc: 0.894874                                                               \n",
      "[29000]\ttraining's auc: 0.916566\tvalid_1's auc: 0.89534                                                                \n",
      "[30000]\ttraining's auc: 0.91722\tvalid_1's auc: 0.895745                                                                \n",
      "[31000]\ttraining's auc: 0.91782\tvalid_1's auc: 0.896152                                                                \n",
      "[32000]\ttraining's auc: 0.918413\tvalid_1's auc: 0.896451                                                               \n",
      "[33000]\ttraining's auc: 0.918986\tvalid_1's auc: 0.896797                                                               \n",
      "[34000]\ttraining's auc: 0.919554\tvalid_1's auc: 0.897061                                                               \n",
      "[35000]\ttraining's auc: 0.920076\tvalid_1's auc: 0.897399                                                               \n",
      "[36000]\ttraining's auc: 0.920566\tvalid_1's auc: 0.897642                                                               \n",
      "[37000]\ttraining's auc: 0.921052\tvalid_1's auc: 0.897856                                                               \n",
      "[38000]\ttraining's auc: 0.921509\tvalid_1's auc: 0.898062                                                               \n",
      "[39000]\ttraining's auc: 0.921959\tvalid_1's auc: 0.898265                                                               \n",
      "[40000]\ttraining's auc: 0.922393\tvalid_1's auc: 0.898421                                                               \n",
      "[41000]\ttraining's auc: 0.922834\tvalid_1's auc: 0.898612                                                               \n",
      "[42000]\ttraining's auc: 0.923265\tvalid_1's auc: 0.898734                                                               \n",
      "[43000]\ttraining's auc: 0.923664\tvalid_1's auc: 0.898901                                                               \n",
      "[44000]\ttraining's auc: 0.924055\tvalid_1's auc: 0.899029                                                               \n",
      "[45000]\ttraining's auc: 0.924452\tvalid_1's auc: 0.89917                                                                \n",
      "[46000]\ttraining's auc: 0.924833\tvalid_1's auc: 0.899275                                                               \n",
      "[47000]\ttraining's auc: 0.925218\tvalid_1's auc: 0.899353                                                               \n",
      "[48000]\ttraining's auc: 0.925581\tvalid_1's auc: 0.899398                                                               \n",
      "[49000]\ttraining's auc: 0.925947\tvalid_1's auc: 0.899461                                                               \n",
      "[50000]\ttraining's auc: 0.926312\tvalid_1's auc: 0.899542                                                               \n",
      "[51000]\ttraining's auc: 0.926678\tvalid_1's auc: 0.899623                                                               \n",
      "[52000]\ttraining's auc: 0.927023\tvalid_1's auc: 0.899636                                                               \n",
      "[53000]\ttraining's auc: 0.927394\tvalid_1's auc: 0.899694                                                               \n",
      "[54000]\ttraining's auc: 0.927733\tvalid_1's auc: 0.899746                                                               \n",
      "[55000]\ttraining's auc: 0.928094\tvalid_1's auc: 0.899829                                                               \n",
      "[56000]\ttraining's auc: 0.928422\tvalid_1's auc: 0.899843                                                               \n",
      "[57000]\ttraining's auc: 0.928758\tvalid_1's auc: 0.899849                                                               \n",
      "[58000]\ttraining's auc: 0.929096\tvalid_1's auc: 0.899868                                                               \n",
      "[59000]\ttraining's auc: 0.929439\tvalid_1's auc: 0.8999                                                                 \n",
      "[60000]\ttraining's auc: 0.92975\tvalid_1's auc: 0.899844                                                                \n",
      "[61000]\ttraining's auc: 0.93007\tvalid_1's auc: 0.899847                                                                \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[58616]\ttraining's auc: 0.929314\tvalid_1's auc: 0.899924\n",
      "Training until validation scores don't improve for 3000 rounds.                                                        \n",
      "[1000]\ttraining's auc: 0.799283\tvalid_1's auc: 0.788268                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttraining's auc: 0.822053\tvalid_1's auc: 0.810039                                                                \n",
      "[3000]\ttraining's auc: 0.84036\tvalid_1's auc: 0.826188                                                                 \n",
      "[4000]\ttraining's auc: 0.852963\tvalid_1's auc: 0.83769                                                                 \n",
      "[5000]\ttraining's auc: 0.862164\tvalid_1's auc: 0.845965                                                                \n",
      "[6000]\ttraining's auc: 0.86973\tvalid_1's auc: 0.852882                                                                 \n",
      "[7000]\ttraining's auc: 0.875673\tvalid_1's auc: 0.858132                                                                \n",
      "[8000]\ttraining's auc: 0.880847\tvalid_1's auc: 0.862656                                                                \n",
      "[9000]\ttraining's auc: 0.885148\tvalid_1's auc: 0.866474                                                                \n",
      "[10000]\ttraining's auc: 0.888724\tvalid_1's auc: 0.869693                                                               \n",
      "[11000]\ttraining's auc: 0.891881\tvalid_1's auc: 0.872281                                                               \n",
      "[12000]\ttraining's auc: 0.894783\tvalid_1's auc: 0.874878                                                               \n",
      "[13000]\ttraining's auc: 0.897243\tvalid_1's auc: 0.876827                                                               \n",
      "[14000]\ttraining's auc: 0.899488\tvalid_1's auc: 0.878812                                                               \n",
      "[15000]\ttraining's auc: 0.901513\tvalid_1's auc: 0.880434                                                               \n",
      "[16000]\ttraining's auc: 0.903364\tvalid_1's auc: 0.881984                                                               \n",
      "[17000]\ttraining's auc: 0.905077\tvalid_1's auc: 0.883206                                                               \n",
      "[18000]\ttraining's auc: 0.906606\tvalid_1's auc: 0.884415                                                               \n",
      "[19000]\ttraining's auc: 0.908083\tvalid_1's auc: 0.885571                                                               \n",
      "[20000]\ttraining's auc: 0.909381\tvalid_1's auc: 0.886599                                                               \n",
      "[21000]\ttraining's auc: 0.910634\tvalid_1's auc: 0.887543                                                               \n",
      "[22000]\ttraining's auc: 0.911768\tvalid_1's auc: 0.888405                                                               \n",
      "[23000]\ttraining's auc: 0.912805\tvalid_1's auc: 0.889148                                                               \n",
      "[24000]\ttraining's auc: 0.913775\tvalid_1's auc: 0.88979                                                                \n",
      "[25000]\ttraining's auc: 0.914679\tvalid_1's auc: 0.890361                                                               \n",
      "[26000]\ttraining's auc: 0.915582\tvalid_1's auc: 0.89094                                                                \n",
      "[27000]\ttraining's auc: 0.916397\tvalid_1's auc: 0.8915                                                                 \n",
      "[28000]\ttraining's auc: 0.917157\tvalid_1's auc: 0.892002                                                               \n",
      "[29000]\ttraining's auc: 0.91788\tvalid_1's auc: 0.892488                                                                \n",
      "[30000]\ttraining's auc: 0.918584\tvalid_1's auc: 0.892848                                                               \n",
      "[31000]\ttraining's auc: 0.919249\tvalid_1's auc: 0.893259                                                               \n",
      "[32000]\ttraining's auc: 0.919855\tvalid_1's auc: 0.893603                                                               \n",
      "[33000]\ttraining's auc: 0.920434\tvalid_1's auc: 0.893899                                                               \n",
      "[34000]\ttraining's auc: 0.920982\tvalid_1's auc: 0.894258                                                               \n",
      "[35000]\ttraining's auc: 0.921539\tvalid_1's auc: 0.894441                                                               \n",
      "[36000]\ttraining's auc: 0.922057\tvalid_1's auc: 0.894684                                                               \n",
      "[37000]\ttraining's auc: 0.922562\tvalid_1's auc: 0.894848                                                               \n",
      "[38000]\ttraining's auc: 0.923035\tvalid_1's auc: 0.895056                                                               \n",
      "[39000]\ttraining's auc: 0.92349\tvalid_1's auc: 0.895213                                                                \n",
      "[40000]\ttraining's auc: 0.923956\tvalid_1's auc: 0.895296                                                               \n",
      "[41000]\ttraining's auc: 0.924407\tvalid_1's auc: 0.895425                                                               \n",
      "[42000]\ttraining's auc: 0.924821\tvalid_1's auc: 0.895507                                                               \n",
      "[43000]\ttraining's auc: 0.925236\tvalid_1's auc: 0.895639                                                               \n",
      "[44000]\ttraining's auc: 0.925631\tvalid_1's auc: 0.895719                                                               \n",
      "[45000]\ttraining's auc: 0.926033\tvalid_1's auc: 0.895754                                                               \n",
      "[46000]\ttraining's auc: 0.926422\tvalid_1's auc: 0.895823                                                               \n",
      "[47000]\ttraining's auc: 0.926792\tvalid_1's auc: 0.895906                                                               \n",
      "[48000]\ttraining's auc: 0.927174\tvalid_1's auc: 0.895954                                                               \n",
      "[49000]\ttraining's auc: 0.927548\tvalid_1's auc: 0.896013                                                               \n",
      "[50000]\ttraining's auc: 0.927899\tvalid_1's auc: 0.896063                                                               \n",
      "[51000]\ttraining's auc: 0.928244\tvalid_1's auc: 0.896155                                                               \n",
      "[52000]\ttraining's auc: 0.928603\tvalid_1's auc: 0.896198                                                               \n",
      "[53000]\ttraining's auc: 0.928952\tvalid_1's auc: 0.89617                                                                \n",
      "[54000]\ttraining's auc: 0.929301\tvalid_1's auc: 0.896205                                                               \n",
      "[55000]\ttraining's auc: 0.929632\tvalid_1's auc: 0.896245                                                               \n",
      "[56000]\ttraining's auc: 0.929954\tvalid_1's auc: 0.896274                                                               \n",
      "[57000]\ttraining's auc: 0.93029\tvalid_1's auc: 0.89625                                                                 \n",
      "[58000]\ttraining's auc: 0.930617\tvalid_1's auc: 0.896233                                                               \n",
      "[59000]\ttraining's auc: 0.930946\tvalid_1's auc: 0.896204                                                               \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[56017]\ttraining's auc: 0.929962\tvalid_1's auc: 0.896279\n",
      "100%|█████████████████████████████████████████████| 50/50 [23:26:36<00:00, 3296.63s/it, best loss: -0.8968215843151981]\n"
     ]
    }
   ],
   "source": [
    "best_cv5 = fmin(loss5, space4lgb, algo=tpe.suggest, max_evals=50, trials=trials5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bagging_freq\n",
      "1 bagging_fraction\n",
      "2 feature_fraction\n",
      "3 learning_rate\n",
      "4 max_depth\n",
      "5 metric\n",
      "6 min_data_in_leaf\n",
      "7 min_sum_hessian_in_leaf\n",
      "8 num_leaves\n",
      "9 tree_learner\n",
      "10 objective\n",
      "11 is_unbalance\n",
      "12 boost_from_average\n",
      "13 boost\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = ['bagging_freq', 'bagging_fraction', 'feature_fraction','learning_rate','max_depth','metric','min_data_in_leaf',\n",
    "             'min_sum_hessian_in_leaf','num_leaves','tree_learner','objective','is_unbalance','boost_from_average','boost']\n",
    "\n",
    "f, axes = plt.subplots(nrows=5, ncols=3, figsize=(15,10))\n",
    "cmap = plt.cm.jet\n",
    "\n",
    "for i, val in enumerate(parameters):\n",
    "    print (i, val)\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials5.trials]).ravel()\n",
    "    ys = [-t['result']['loss'] for t in trials5.trials]\n",
    "    xs, ys = zip(*sorted(zip(xs, ys)))\n",
    "    ys = np.array(ys)\n",
    "    axes[i//3,i%3].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.5, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i//3,i%3].set_title(val)\n",
    "    axes[i//3,i%3].set_ylim([0.89,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5 # Number of K-fold Splits\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True,random_state=1111).split(lgb_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param = {\n",
    "    # This one seems to be better than the lower one\n",
    "    #'bagging_freq': 5,\n",
    "        #'bagging_fraction': 0.4, \n",
    "        #'boost_from_average':'false',\n",
    "        'boost': 'gbdt',\n",
    "        #'feature_fraction': 0.8,\n",
    "        'learning_rate': 0.002,#0.0083\n",
    "        'max_depth': -1,  \n",
    "        'metric':'auc',\n",
    "        #'min_data_in_leaf': 80,\n",
    "        #'min_sum_hessian_in_leaf': 10.0,\n",
    "        #'num_leaves': 13, \n",
    "        #'num_threads': 8,\n",
    "        'tree_learner': 'serial',\n",
    "        'objective': 'binary', \n",
    "        'verbosity': 1,\n",
    "        #\"boost_from_average\": \"false\",\n",
    "        #'is_unbalance':True #new\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.904038\tvalid_1's auc: 0.897279\n",
      "[1000]\ttraining's auc: 0.905373\tvalid_1's auc: 0.89723\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's auc: 0.903791\tvalid_1's auc: 0.897316\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.90373\tvalid_1's auc: 0.898415\n",
      "[1000]\ttraining's auc: 0.904943\tvalid_1's auc: 0.898604\n",
      "[1500]\ttraining's auc: 0.9068\tvalid_1's auc: 0.898636\n",
      "[2000]\ttraining's auc: 0.908919\tvalid_1's auc: 0.898606\n",
      "[2500]\ttraining's auc: 0.910807\tvalid_1's auc: 0.89853\n",
      "Early stopping, best iteration is:\n",
      "[1583]\ttraining's auc: 0.90714\tvalid_1's auc: 0.898675\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.902642\tvalid_1's auc: 0.90247\n",
      "[1000]\ttraining's auc: 0.903932\tvalid_1's auc: 0.902559\n",
      "[1500]\ttraining's auc: 0.905553\tvalid_1's auc: 0.902487\n",
      "Early stopping, best iteration is:\n",
      "[830]\ttraining's auc: 0.903433\tvalid_1's auc: 0.90257\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.902716\tvalid_1's auc: 0.902291\n",
      "[1000]\ttraining's auc: 0.903969\tvalid_1's auc: 0.902276\n",
      "[1500]\ttraining's auc: 0.905761\tvalid_1's auc: 0.902304\n",
      "Early stopping, best iteration is:\n",
      "[824]\ttraining's auc: 0.903358\tvalid_1's auc: 0.902404\n",
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[500]\ttraining's auc: 0.902363\tvalid_1's auc: 0.903728\n",
      "[1000]\ttraining's auc: 0.903692\tvalid_1's auc: 0.903844\n",
      "[1500]\ttraining's auc: 0.905571\tvalid_1's auc: 0.903988\n",
      "[2000]\ttraining's auc: 0.907696\tvalid_1's auc: 0.90396\n",
      "Early stopping, best iteration is:\n",
      "[1373]\ttraining's auc: 0.904942\tvalid_1's auc: 0.903999\n",
      "0.8945345176037445\n"
     ]
    }
   ],
   "source": [
    "lgb_oof=np.zeros(len(lgb_train))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold, (train_idx, valid_idx) in enumerate(splits):  \n",
    "        X = np.array(lgb_train)\n",
    "        y = np.array(y)\n",
    "        X_train = X[train_idx.astype(int)]\n",
    "        y_train = y[train_idx.astype(int)]\n",
    "    \n",
    "        trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X[valid_idx.astype(int)], label=y[valid_idx.astype(int)])\n",
    "        watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "        lgb_clf = lgb.train(lgb_param,trn_data, 10000, valid_sets = [trn_data, val_data], early_stopping_rounds=1000, verbose_eval=500)\n",
    "        lgb_oof[valid_idx] = lgb_clf.predict(X[valid_idx], num_iteration=lgb_clf.best_iteration)\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = lgb_train.columns\n",
    "        fold_importance_df[\"importance\"] = lgb_clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "print (roc_auc_score(y, lgb_oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>et_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3626.4</td>\n",
       "      <td>2281.750052</td>\n",
       "      <td>966.0</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>2961.0</td>\n",
       "      <td>5566.0</td>\n",
       "      <td>6391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6959.2</td>\n",
       "      <td>3002.207305</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>5607.0</td>\n",
       "      <td>6014.0</td>\n",
       "      <td>8448.0</td>\n",
       "      <td>11287.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6091.6</td>\n",
       "      <td>2490.874806</td>\n",
       "      <td>2722.0</td>\n",
       "      <td>4907.0</td>\n",
       "      <td>5892.0</td>\n",
       "      <td>7868.0</td>\n",
       "      <td>9069.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4536.0</td>\n",
       "      <td>2084.851673</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>3851.0</td>\n",
       "      <td>4118.0</td>\n",
       "      <td>6466.0</td>\n",
       "      <td>6640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3324.4</td>\n",
       "      <td>2093.047611</td>\n",
       "      <td>938.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>2774.0</td>\n",
       "      <td>4920.0</td>\n",
       "      <td>6005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_rank</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5480.4</td>\n",
       "      <td>2553.171224</td>\n",
       "      <td>2119.0</td>\n",
       "      <td>4121.0</td>\n",
       "      <td>5142.0</td>\n",
       "      <td>7922.0</td>\n",
       "      <td>8098.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count    mean          std     min     25%     50%     75%      max\n",
       "feature                                                                      \n",
       "et_rank     5.0  3626.4  2281.750052   966.0  2248.0  2961.0  5566.0   6391.0\n",
       "knn_rank    5.0     0.0     0.000000     0.0     0.0     0.0     0.0      0.0\n",
       "lgb_rank    5.0  6959.2  3002.207305  3440.0  5607.0  6014.0  8448.0  11287.0\n",
       "nb_rank     5.0  6091.6  2490.874806  2722.0  4907.0  5892.0  7868.0   9069.0\n",
       "nn_rank     5.0  4536.0  2084.851673  1605.0  3851.0  4118.0  6466.0   6640.0\n",
       "rf_rank     5.0  3324.4  2093.047611   938.0  1985.0  2774.0  4920.0   6005.0\n",
       "xgb_rank    5.0  5480.4  2553.171224  2119.0  4121.0  5142.0  7922.0   8098.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.groupby('feature')['importance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013089524435733"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average=blend_train['lgb_rank']*3+blend_train['xgb_rank']*2.5+blend_train['nb_rank']*2.5+blend_train['nn_rank']*1.5+blend_train['et_rank']*0.9\n",
    "roc_auc_score(y,average)                                                                                                                                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
